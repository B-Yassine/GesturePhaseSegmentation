{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gesture Phase Detection using Unsupervised and Supervised Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import model_selection, metrics\n",
    "from sklearn import preprocessing\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>X10</th>\n",
       "      <th>...</th>\n",
       "      <th>X24</th>\n",
       "      <th>X25</th>\n",
       "      <th>X26</th>\n",
       "      <th>X27</th>\n",
       "      <th>X28</th>\n",
       "      <th>X29</th>\n",
       "      <th>X30</th>\n",
       "      <th>X31</th>\n",
       "      <th>X32</th>\n",
       "      <th>Phase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>-0.005009</td>\n",
       "      <td>-0.000964</td>\n",
       "      <td>0.000573</td>\n",
       "      <td>0.008623</td>\n",
       "      <td>0.005667</td>\n",
       "      <td>0.001302</td>\n",
       "      <td>-0.000631</td>\n",
       "      <td>0.000130</td>\n",
       "      <td>-0.000048</td>\n",
       "      <td>0.007762</td>\n",
       "      <td>...</td>\n",
       "      <td>1.880800e-04</td>\n",
       "      <td>0.005133</td>\n",
       "      <td>0.010400</td>\n",
       "      <td>0.000646</td>\n",
       "      <td>0.007871</td>\n",
       "      <td>0.004631</td>\n",
       "      <td>0.000963</td>\n",
       "      <td>0.000092</td>\n",
       "      <td>0.000438</td>\n",
       "      <td>'D'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.004905</td>\n",
       "      <td>0.001209</td>\n",
       "      <td>-0.000649</td>\n",
       "      <td>0.004737</td>\n",
       "      <td>0.003166</td>\n",
       "      <td>0.000819</td>\n",
       "      <td>-0.000572</td>\n",
       "      <td>-0.000015</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.002706</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.500000e-07</td>\n",
       "      <td>0.005093</td>\n",
       "      <td>0.005756</td>\n",
       "      <td>0.000573</td>\n",
       "      <td>0.003459</td>\n",
       "      <td>0.000730</td>\n",
       "      <td>0.000332</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000433</td>\n",
       "      <td>'D'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>-0.002393</td>\n",
       "      <td>-0.000216</td>\n",
       "      <td>0.000136</td>\n",
       "      <td>0.003028</td>\n",
       "      <td>0.001212</td>\n",
       "      <td>0.000336</td>\n",
       "      <td>-0.000449</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.002868</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.920000e-05</td>\n",
       "      <td>0.002406</td>\n",
       "      <td>0.003279</td>\n",
       "      <td>0.000452</td>\n",
       "      <td>0.003261</td>\n",
       "      <td>0.002412</td>\n",
       "      <td>0.000852</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000202</td>\n",
       "      <td>'D'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>-0.001394</td>\n",
       "      <td>-0.000242</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.001182</td>\n",
       "      <td>0.000575</td>\n",
       "      <td>0.000225</td>\n",
       "      <td>-0.000479</td>\n",
       "      <td>-0.000050</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>0.001171</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.184000e-05</td>\n",
       "      <td>0.001416</td>\n",
       "      <td>0.001334</td>\n",
       "      <td>0.000493</td>\n",
       "      <td>0.001358</td>\n",
       "      <td>0.000313</td>\n",
       "      <td>0.000611</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.000596</td>\n",
       "      <td>'D'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>-0.000156</td>\n",
       "      <td>-0.000004</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.001585</td>\n",
       "      <td>0.000630</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>-0.000303</td>\n",
       "      <td>0.000097</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>0.001579</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.015000e-05</td>\n",
       "      <td>0.000158</td>\n",
       "      <td>0.001709</td>\n",
       "      <td>0.000325</td>\n",
       "      <td>0.001714</td>\n",
       "      <td>0.000203</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>'D'</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         X1        X2        X3        X4        X5        X6        X7  \\\n",
       "0 -0.005009 -0.000964  0.000573  0.008623  0.005667  0.001302 -0.000631   \n",
       "1  0.004905  0.001209 -0.000649  0.004737  0.003166  0.000819 -0.000572   \n",
       "2 -0.002393 -0.000216  0.000136  0.003028  0.001212  0.000336 -0.000449   \n",
       "3 -0.001394 -0.000242  0.000056  0.001182  0.000575  0.000225 -0.000479   \n",
       "4 -0.000156 -0.000004  0.000023  0.001585  0.000630  0.000094 -0.000303   \n",
       "\n",
       "         X8        X9       X10  ...           X24       X25       X26  \\\n",
       "0  0.000130 -0.000048  0.007762  ...  1.880800e-04  0.005133  0.010400   \n",
       "1 -0.000015  0.000023  0.002706  ... -7.500000e-07  0.005093  0.005756   \n",
       "2  0.000017  0.000047  0.002868  ... -3.920000e-05  0.002406  0.003279   \n",
       "3 -0.000050  0.000104  0.001171  ... -3.184000e-05  0.001416  0.001334   \n",
       "4  0.000097  0.000065  0.001579  ... -2.015000e-05  0.000158  0.001709   \n",
       "\n",
       "        X27       X28       X29       X30       X31       X32  Phase  \n",
       "0  0.000646  0.007871  0.004631  0.000963  0.000092  0.000438    'D'  \n",
       "1  0.000573  0.003459  0.000730  0.000332  0.000012  0.000433    'D'  \n",
       "2  0.000452  0.003261  0.002412  0.000852  0.000042  0.000202    'D'  \n",
       "3  0.000493  0.001358  0.000313  0.000611  0.000029  0.000596    'D'  \n",
       "4  0.000325  0.001714  0.000203  0.000069  0.000038  0.000069    'D'  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9873, 33)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([\"'D'\", \"'P'\", \"'S'\", \"'H'\", \"'R'\"], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Phase.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the rows with label \"P\",\"D\",\"R\"\n",
    "# For label-based deletion, set the index first on the dataframe:\n",
    "df = df.set_index(\"Phase\")\n",
    "df = df.drop([\"'P'\", \"'D'\", \"'R'\"], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>X10</th>\n",
       "      <th>...</th>\n",
       "      <th>X23</th>\n",
       "      <th>X24</th>\n",
       "      <th>X25</th>\n",
       "      <th>X26</th>\n",
       "      <th>X27</th>\n",
       "      <th>X28</th>\n",
       "      <th>X29</th>\n",
       "      <th>X30</th>\n",
       "      <th>X31</th>\n",
       "      <th>X32</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Phase</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>'S'</td>\n",
       "      <td>-0.012755</td>\n",
       "      <td>0.016660</td>\n",
       "      <td>0.000505</td>\n",
       "      <td>0.009534</td>\n",
       "      <td>0.004022</td>\n",
       "      <td>-0.000355</td>\n",
       "      <td>-0.009288</td>\n",
       "      <td>0.013281</td>\n",
       "      <td>0.000577</td>\n",
       "      <td>0.009613</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001379</td>\n",
       "      <td>-0.000094</td>\n",
       "      <td>0.020988</td>\n",
       "      <td>0.010354</td>\n",
       "      <td>0.016217</td>\n",
       "      <td>0.010435</td>\n",
       "      <td>0.004264</td>\n",
       "      <td>0.001580</td>\n",
       "      <td>0.003233</td>\n",
       "      <td>0.001581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>'S'</td>\n",
       "      <td>-0.012634</td>\n",
       "      <td>0.014808</td>\n",
       "      <td>0.000632</td>\n",
       "      <td>-0.001678</td>\n",
       "      <td>0.003034</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>-0.009234</td>\n",
       "      <td>0.011821</td>\n",
       "      <td>0.000656</td>\n",
       "      <td>-0.001617</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000320</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.019476</td>\n",
       "      <td>0.003480</td>\n",
       "      <td>0.015015</td>\n",
       "      <td>0.003467</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.003637</td>\n",
       "      <td>0.000472</td>\n",
       "      <td>0.003643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>'S'</td>\n",
       "      <td>-0.008327</td>\n",
       "      <td>0.010399</td>\n",
       "      <td>0.000753</td>\n",
       "      <td>-0.001399</td>\n",
       "      <td>0.001153</td>\n",
       "      <td>0.000354</td>\n",
       "      <td>-0.005991</td>\n",
       "      <td>0.008461</td>\n",
       "      <td>0.000756</td>\n",
       "      <td>-0.001339</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000588</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.013344</td>\n",
       "      <td>0.001848</td>\n",
       "      <td>0.010395</td>\n",
       "      <td>0.001814</td>\n",
       "      <td>0.001926</td>\n",
       "      <td>0.000595</td>\n",
       "      <td>0.001460</td>\n",
       "      <td>0.000595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>'S'</td>\n",
       "      <td>0.004090</td>\n",
       "      <td>-0.005890</td>\n",
       "      <td>0.000244</td>\n",
       "      <td>-0.003479</td>\n",
       "      <td>0.003003</td>\n",
       "      <td>0.000916</td>\n",
       "      <td>0.003311</td>\n",
       "      <td>-0.003896</td>\n",
       "      <td>0.000351</td>\n",
       "      <td>-0.003446</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000594</td>\n",
       "      <td>0.000180</td>\n",
       "      <td>0.007175</td>\n",
       "      <td>0.004686</td>\n",
       "      <td>0.005124</td>\n",
       "      <td>0.004668</td>\n",
       "      <td>0.006609</td>\n",
       "      <td>0.000916</td>\n",
       "      <td>0.004991</td>\n",
       "      <td>0.000921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>'S'</td>\n",
       "      <td>0.004367</td>\n",
       "      <td>-0.006456</td>\n",
       "      <td>0.000629</td>\n",
       "      <td>-0.000758</td>\n",
       "      <td>-0.003468</td>\n",
       "      <td>0.000625</td>\n",
       "      <td>0.003456</td>\n",
       "      <td>-0.004509</td>\n",
       "      <td>0.000637</td>\n",
       "      <td>-0.000760</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002091</td>\n",
       "      <td>-0.000095</td>\n",
       "      <td>0.007819</td>\n",
       "      <td>0.003604</td>\n",
       "      <td>0.005717</td>\n",
       "      <td>0.003606</td>\n",
       "      <td>0.000238</td>\n",
       "      <td>0.002267</td>\n",
       "      <td>0.000224</td>\n",
       "      <td>0.002265</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             X1        X2        X3        X4        X5        X6        X7  \\\n",
       "Phase                                                                         \n",
       "'S'   -0.012755  0.016660  0.000505  0.009534  0.004022 -0.000355 -0.009288   \n",
       "'S'   -0.012634  0.014808  0.000632 -0.001678  0.003034  0.000300 -0.009234   \n",
       "'S'   -0.008327  0.010399  0.000753 -0.001399  0.001153  0.000354 -0.005991   \n",
       "'S'    0.004090 -0.005890  0.000244 -0.003479  0.003003  0.000916  0.003311   \n",
       "'S'    0.004367 -0.006456  0.000629 -0.000758 -0.003468  0.000625  0.003456   \n",
       "\n",
       "             X8        X9       X10  ...       X23       X24       X25  \\\n",
       "Phase                                ...                                 \n",
       "'S'    0.013281  0.000577  0.009613  ... -0.001379 -0.000094  0.020988   \n",
       "'S'    0.011821  0.000656 -0.001617  ... -0.000320  0.000211  0.019476   \n",
       "'S'    0.008461  0.000756 -0.001339  ... -0.000588  0.000017  0.013344   \n",
       "'S'   -0.003896  0.000351 -0.003446  ...  0.000594  0.000180  0.007175   \n",
       "'S'   -0.004509  0.000637 -0.000760  ... -0.002091 -0.000095  0.007819   \n",
       "\n",
       "            X26       X27       X28       X29       X30       X31       X32  \n",
       "Phase                                                                        \n",
       "'S'    0.010354  0.016217  0.010435  0.004264  0.001580  0.003233  0.001581  \n",
       "'S'    0.003480  0.015015  0.003467  0.000600  0.003637  0.000472  0.003643  \n",
       "'S'    0.001848  0.010395  0.001814  0.001926  0.000595  0.001460  0.000595  \n",
       "'S'    0.004686  0.005124  0.004668  0.006609  0.000916  0.004991  0.000921  \n",
       "'S'    0.003604  0.005717  0.003606  0.000238  0.002267  0.000224  0.002265  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'Phase': 'phase'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([\"'S'\", \"'H'\"], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.phase.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1e8c6304940>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['phase'].value_counts().plot(kind='bar')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "df['phase'] = le.fit_transform(df['phase'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0], dtype=int64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.phase.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phase</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>...</th>\n",
       "      <th>X23</th>\n",
       "      <th>X24</th>\n",
       "      <th>X25</th>\n",
       "      <th>X26</th>\n",
       "      <th>X27</th>\n",
       "      <th>X28</th>\n",
       "      <th>X29</th>\n",
       "      <th>X30</th>\n",
       "      <th>X31</th>\n",
       "      <th>X32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>3820</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000506</td>\n",
       "      <td>-0.014290</td>\n",
       "      <td>0.002058</td>\n",
       "      <td>0.003493</td>\n",
       "      <td>0.010186</td>\n",
       "      <td>-0.001849</td>\n",
       "      <td>0.000216</td>\n",
       "      <td>-0.013003</td>\n",
       "      <td>0.001810</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000370</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>0.014447</td>\n",
       "      <td>0.010926</td>\n",
       "      <td>0.013130</td>\n",
       "      <td>0.005971</td>\n",
       "      <td>0.003493</td>\n",
       "      <td>0.000930</td>\n",
       "      <td>0.002380</td>\n",
       "      <td>0.000387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3569</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.000369</td>\n",
       "      <td>0.007638</td>\n",
       "      <td>0.000249</td>\n",
       "      <td>0.010010</td>\n",
       "      <td>0.011837</td>\n",
       "      <td>0.003746</td>\n",
       "      <td>-0.000091</td>\n",
       "      <td>0.007414</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004592</td>\n",
       "      <td>0.000147</td>\n",
       "      <td>0.007651</td>\n",
       "      <td>0.015948</td>\n",
       "      <td>0.007414</td>\n",
       "      <td>0.012678</td>\n",
       "      <td>0.002080</td>\n",
       "      <td>0.003989</td>\n",
       "      <td>0.002063</td>\n",
       "      <td>0.004595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1904</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.005286</td>\n",
       "      <td>0.006858</td>\n",
       "      <td>0.001139</td>\n",
       "      <td>0.001329</td>\n",
       "      <td>-0.002390</td>\n",
       "      <td>-0.000143</td>\n",
       "      <td>-0.004316</td>\n",
       "      <td>0.003895</td>\n",
       "      <td>0.000953</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000163</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.008733</td>\n",
       "      <td>0.002738</td>\n",
       "      <td>0.005891</td>\n",
       "      <td>0.003218</td>\n",
       "      <td>0.000360</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000366</td>\n",
       "      <td>0.000176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2273</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.000934</td>\n",
       "      <td>0.000828</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>-0.000720</td>\n",
       "      <td>0.000272</td>\n",
       "      <td>-0.000046</td>\n",
       "      <td>-0.000487</td>\n",
       "      <td>-0.000006</td>\n",
       "      <td>-0.000057</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.001250</td>\n",
       "      <td>0.000771</td>\n",
       "      <td>0.000490</td>\n",
       "      <td>0.000413</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>0.000030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1487</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.018029</td>\n",
       "      <td>0.019607</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.012421</td>\n",
       "      <td>0.008324</td>\n",
       "      <td>0.002521</td>\n",
       "      <td>-0.016448</td>\n",
       "      <td>0.020643</td>\n",
       "      <td>0.001457</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000660</td>\n",
       "      <td>0.000354</td>\n",
       "      <td>0.026636</td>\n",
       "      <td>0.015164</td>\n",
       "      <td>0.026435</td>\n",
       "      <td>0.017882</td>\n",
       "      <td>0.001733</td>\n",
       "      <td>0.001249</td>\n",
       "      <td>0.002410</td>\n",
       "      <td>0.001172</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      phase        X1        X2        X3        X4        X5        X6  \\\n",
       "3820      1  0.000506 -0.014290  0.002058  0.003493  0.010186 -0.001849   \n",
       "3569      1 -0.000369  0.007638  0.000249  0.010010  0.011837  0.003746   \n",
       "1904      0 -0.005286  0.006858  0.001139  0.001329 -0.002390 -0.000143   \n",
       "2273      0 -0.000934  0.000828  0.000065 -0.000720  0.000272 -0.000046   \n",
       "1487      1 -0.018029  0.019607  0.000114  0.012421  0.008324  0.002521   \n",
       "\n",
       "            X7        X8        X9  ...       X23       X24       X25  \\\n",
       "3820  0.000216 -0.013003  0.001810  ... -0.000370  0.000086  0.014447   \n",
       "3569 -0.000091  0.007414  0.000052  ... -0.004592  0.000147  0.007651   \n",
       "1904 -0.004316  0.003895  0.000953  ... -0.000163  0.000023  0.008733   \n",
       "2273 -0.000487 -0.000006 -0.000057  ...  0.000012  0.000003  0.001250   \n",
       "1487 -0.016448  0.020643  0.001457  ... -0.000660  0.000354  0.026636   \n",
       "\n",
       "           X26       X27       X28       X29       X30       X31       X32  \n",
       "3820  0.010926  0.013130  0.005971  0.003493  0.000930  0.002380  0.000387  \n",
       "3569  0.015948  0.007414  0.012678  0.002080  0.003989  0.002063  0.004595  \n",
       "1904  0.002738  0.005891  0.003218  0.000360  0.000022  0.000366  0.000176  \n",
       "2273  0.000771  0.000490  0.000413  0.000013  0.000055  0.000059  0.000030  \n",
       "1487  0.015164  0.026435  0.017882  0.001733  0.001249  0.002410  0.001172  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "corr = df.corr()\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(corr,cmap='coolwarm', vmin=-0.9, vmax=0.9)\n",
    "fig.colorbar(cax)\n",
    "ticks = np.arange(0,len(df.columns),1)\n",
    "ax.set_xticks(ticks)\n",
    "plt.xticks(rotation=90)\n",
    "ax.set_yticks(ticks)\n",
    "ax.set_xticklabels(df.columns)\n",
    "ax.set_yticklabels(df.columns)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting the Feautre & Label Vector \n",
    "\n",
    "##### See the data analysis web based version (analysis.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = list(df.columns)\n",
    "features = cols\n",
    "features = [e for e in features if e not in {'phase', 'X27', 'X28', 'X4', 'X5', 'X8'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X9</th>\n",
       "      <th>X10</th>\n",
       "      <th>X11</th>\n",
       "      <th>X12</th>\n",
       "      <th>X13</th>\n",
       "      <th>...</th>\n",
       "      <th>X21</th>\n",
       "      <th>X22</th>\n",
       "      <th>X23</th>\n",
       "      <th>X24</th>\n",
       "      <th>X25</th>\n",
       "      <th>X26</th>\n",
       "      <th>X29</th>\n",
       "      <th>X30</th>\n",
       "      <th>X31</th>\n",
       "      <th>X32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>3820</td>\n",
       "      <td>0.000506</td>\n",
       "      <td>-0.014290</td>\n",
       "      <td>0.002058</td>\n",
       "      <td>-0.001849</td>\n",
       "      <td>0.000216</td>\n",
       "      <td>0.001810</td>\n",
       "      <td>0.001850</td>\n",
       "      <td>0.005564</td>\n",
       "      <td>-0.001127</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000632</td>\n",
       "      <td>0.000074</td>\n",
       "      <td>-0.000370</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>0.014447</td>\n",
       "      <td>0.010926</td>\n",
       "      <td>0.003493</td>\n",
       "      <td>0.000930</td>\n",
       "      <td>0.002380</td>\n",
       "      <td>0.000387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3569</td>\n",
       "      <td>-0.000369</td>\n",
       "      <td>0.007638</td>\n",
       "      <td>0.000249</td>\n",
       "      <td>0.003746</td>\n",
       "      <td>-0.000091</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.006865</td>\n",
       "      <td>0.010088</td>\n",
       "      <td>0.003441</td>\n",
       "      <td>0.001683</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000366</td>\n",
       "      <td>-0.000034</td>\n",
       "      <td>-0.004592</td>\n",
       "      <td>0.000147</td>\n",
       "      <td>0.007651</td>\n",
       "      <td>0.015948</td>\n",
       "      <td>0.002080</td>\n",
       "      <td>0.003989</td>\n",
       "      <td>0.002063</td>\n",
       "      <td>0.004595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1904</td>\n",
       "      <td>-0.005286</td>\n",
       "      <td>0.006858</td>\n",
       "      <td>0.001139</td>\n",
       "      <td>-0.000143</td>\n",
       "      <td>-0.004316</td>\n",
       "      <td>0.000953</td>\n",
       "      <td>0.001524</td>\n",
       "      <td>-0.002829</td>\n",
       "      <td>0.000156</td>\n",
       "      <td>0.000307</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000089</td>\n",
       "      <td>0.000062</td>\n",
       "      <td>-0.000163</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.008733</td>\n",
       "      <td>0.002738</td>\n",
       "      <td>0.000360</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000366</td>\n",
       "      <td>0.000176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2273</td>\n",
       "      <td>-0.000934</td>\n",
       "      <td>0.000828</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>-0.000046</td>\n",
       "      <td>-0.000487</td>\n",
       "      <td>-0.000057</td>\n",
       "      <td>-0.000395</td>\n",
       "      <td>-0.000098</td>\n",
       "      <td>-0.000069</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.001250</td>\n",
       "      <td>0.000771</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>0.000030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1487</td>\n",
       "      <td>-0.018029</td>\n",
       "      <td>0.019607</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.002521</td>\n",
       "      <td>-0.016448</td>\n",
       "      <td>0.001457</td>\n",
       "      <td>0.013647</td>\n",
       "      <td>0.011104</td>\n",
       "      <td>0.003198</td>\n",
       "      <td>-0.001651</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>0.000902</td>\n",
       "      <td>-0.000660</td>\n",
       "      <td>0.000354</td>\n",
       "      <td>0.026636</td>\n",
       "      <td>0.015164</td>\n",
       "      <td>0.001733</td>\n",
       "      <td>0.001249</td>\n",
       "      <td>0.002410</td>\n",
       "      <td>0.001172</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            X1        X2        X3        X6        X7        X9       X10  \\\n",
       "3820  0.000506 -0.014290  0.002058 -0.001849  0.000216  0.001810  0.001850   \n",
       "3569 -0.000369  0.007638  0.000249  0.003746 -0.000091  0.000052  0.006865   \n",
       "1904 -0.005286  0.006858  0.001139 -0.000143 -0.004316  0.000953  0.001524   \n",
       "2273 -0.000934  0.000828  0.000065 -0.000046 -0.000487 -0.000057 -0.000395   \n",
       "1487 -0.018029  0.019607  0.000114  0.002521 -0.016448  0.001457  0.013647   \n",
       "\n",
       "           X11       X12       X13  ...       X21       X22       X23  \\\n",
       "3820  0.005564 -0.001127  0.000070  ...  0.000632  0.000074 -0.000370   \n",
       "3569  0.010088  0.003441  0.001683  ... -0.000366 -0.000034 -0.004592   \n",
       "1904 -0.002829  0.000156  0.000307  ... -0.000089  0.000062 -0.000163   \n",
       "2273 -0.000098 -0.000069  0.000008  ...  0.000027  0.000028  0.000012   \n",
       "1487  0.011104  0.003198 -0.001651  ... -0.000002  0.000902 -0.000660   \n",
       "\n",
       "           X24       X25       X26       X29       X30       X31       X32  \n",
       "3820  0.000086  0.014447  0.010926  0.003493  0.000930  0.002380  0.000387  \n",
       "3569  0.000147  0.007651  0.015948  0.002080  0.003989  0.002063  0.004595  \n",
       "1904  0.000023  0.008733  0.002738  0.000360  0.000022  0.000366  0.000176  \n",
       "2273  0.000003  0.001250  0.000771  0.000013  0.000055  0.000059  0.000030  \n",
       "1487  0.000354  0.026636  0.015164  0.001733  0.001249  0.002410  0.001172  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df[features]\n",
    "y = df['phase']\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Imbalanced Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform under-sampling by generating centroids based on clustering methods. Method that under samples the majority class by replacing a cluster of majority samples by the cluster centroid of a KMeans algorithm. This algorithm keeps N majority samples by fitting the KMeans algorithm with N cluster to the majority class and using the coordinates of the N cluster centroids as the new majority samples.\n",
    "\n",
    "### here we will resample only the majority class to be equal to the minority class which contains 998 samples.\n",
    "\n",
    "### Therefore we got 998 cluster which means 998 sample in the majority class.\n",
    "\n",
    "### Finally we got: 998 * 2 = 1996 total sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\Yassine\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Yassine\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Yassine\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Yassine\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Yassine\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Yassine\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1996, 27)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.under_sampling import ClusterCentroids\n",
    "cc = ClusterCentroids()\n",
    "X, y = cc.fit_sample(X, y)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting into Test & Train (75:25)\n",
    "\n",
    "### Since we are using cross validation, we don't need to divide our data into training and test sets. We want all of the data in the training set so that we can apply cross validation on that. The simplest way to do this is to set the value for the test_size parameter to 0. This will return all the data in the training set as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizing the Dataset for Easier Parameter Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = StandardScaler().fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1497, 27) (1497,)\n",
      "(499, 27) (499,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(copy=True, iterated_power='auto', n_components=27, random_state=None,\n",
       "    svd_solver='auto', tol=0.0, whiten=False)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply PCA with the same number of dimensions as variables in the dataset\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=27)\n",
    "\n",
    "pca.fit(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(list(pca.explained_variance_ratio_),'-o')\n",
    "plt.title('Explained variance ratio as function of PCA components')\n",
    "plt.ylabel('Explained variance ratio')\n",
    "plt.xlabel('Component')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create 'reduced_data' - a Feature Dataframe containing PCA components explaining Maximum Variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We reduce the data to twenty dimensions using PCA\n",
    "pca = PCA(n_components=17)\n",
    "X_train = pca.fit_transform(X_train)\n",
    "X_test = pca.transform(X_test)\n",
    "#print(reduced_data[:10])  # print upto 10 elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1497, 17)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yassine\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Yassine\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Yassine\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Yassine\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Yassine\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.88333333 0.89333333 0.89966555 0.91973244 0.92976589]\n",
      "0.9051661092530658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yassine\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Fitting SVM to the Training set\n",
    "from sklearn.svm import SVC\n",
    "SVM = SVC(kernel = 'rbf', random_state = 0)\n",
    "SVM.fit(X_train, y_train)\n",
    "\n",
    "# Train accuracy\n",
    "scores = model_selection.cross_val_score(SVM, X_train, y_train, cv=5)\n",
    "print (scores)\n",
    "print (scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross result========\n",
      "Acurracy:  0.9298597194388778\n",
      "\n",
      "\n",
      "time elapsed:  0.014960765838623047\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = SVM.predict(X_test)\n",
    "\n",
    "tt0=time()\n",
    "\n",
    "print (\"cross result========\")\n",
    "#scores = model_selection.cross_val_score(SVM, X_test, y_test, cv=3)\n",
    "#print(scores)\n",
    "#print (scores.mean())\n",
    "#print (scores.std())\n",
    "\n",
    "print (\"Acurracy: \", SVM.score(X_test,y_test) )\n",
    "\n",
    "\n",
    "tt1=time()\n",
    "print (\"\\n\")\n",
    "print (\"time elapsed: \", tt1-tt0)\n",
    "print (\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 10, 'gamma': 0.15, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "# Applying Grid Search to find the best model and the best parameters\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = [{'C': [1, 10, 50, 75, 100], 'kernel': ['linear']},\n",
    "              {'C': [1, 10, 50, 75, 100], 'kernel': ['rbf'], 'gamma': [0.05, 0.06, 0.07, 0.08, 0.09,0.1, 0.15, 0.2, 0.3]}]\n",
    "grid_search = GridSearchCV(estimator = SVM,\n",
    "                           param_grid = parameters,\n",
    "                           scoring = 'accuracy',\n",
    "                           cv = 5,\n",
    "                           n_jobs = -1)\n",
    "grid_search = grid_search.fit(X_train, y_train)\n",
    "best_accuracy = grid_search.best_score_\n",
    "best_parameters = grid_search.best_params_\n",
    "print(best_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.90333333 0.91333333 0.91638796 0.9264214  0.94983278]\n",
      "0.9218617614269788\n"
     ]
    }
   ],
   "source": [
    "# Fitting SVM to the best parameters\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "SVM = SVC(kernel = 'rbf', C=10, gamma=0.15)\n",
    "SVM.fit(X_train, y_train)\n",
    "scores = model_selection.cross_val_score(SVM, X_train, y_train, cv=5)\n",
    "print (scores)\n",
    "print (scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurracy:  0.9318637274549099\n"
     ]
    }
   ],
   "source": [
    "# Testing our best SVM\n",
    "\n",
    "print (\"Acurracy: \", SVM.score(X_test,y_test) )\n",
    "\n",
    "#scores = model_selection.cross_val_score(SVM, X_test, y_test, cv=3)\n",
    "#print(scores)\n",
    "#print (scores.mean())\n",
    "#print (scores.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.86       0.89666667 0.90301003 0.91304348 0.92976589]\n",
      "0.9004972129319956\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(n_estimators = 10, criterion = 'entropy')\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Train accuracy\n",
    "scores = model_selection.cross_val_score(rf, X_train, y_train, cv=5)\n",
    "print (scores)\n",
    "print (scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurracy:  0.9118236472945892\n",
      "\n",
      "\n",
      "time elapsed:  0.003990650177001953\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Predicting the Test set results\n",
    "#y_pred = rf.predict(X_test)\n",
    "\n",
    "tt0=time()\n",
    "\n",
    "print (\"Acurracy: \", rf.score(X_test,y_test) )\n",
    "\n",
    "#print (\"cross result========\")\n",
    "#scores = model_selection.cross_val_score(rf, X_test, y_test, cv=3)\n",
    "#print(scores)\n",
    "#print (scores.mean())\n",
    "#print (scores.std())\n",
    "\n",
    "tt1=time()\n",
    "print (\"\\n\")\n",
    "print (\"time elapsed: \", tt1-tt0)\n",
    "print (\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bootstrap': False, 'criterion': 'entropy', 'n_estimators': 1000}\n"
     ]
    }
   ],
   "source": [
    "# Grid Search for best parameters\n",
    "parameters = {\n",
    "    'n_estimators': [10, 50, 100, 300, 500, 1000],\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator = rf,\n",
    "                           param_grid = parameters,\n",
    "                           scoring = 'accuracy',\n",
    "                           cv = 5,\n",
    "                           n_jobs = -1)\n",
    "grid_search = grid_search.fit(X_train, y_train)\n",
    "best_accuracy = grid_search.best_score_\n",
    "best_parameters = grid_search.best_params_\n",
    "print(best_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9        0.90666667 0.89297659 0.91304348 0.92976589]\n",
      "0.9084905239687849\n"
     ]
    }
   ],
   "source": [
    "# Fitting R.F. to the best parameters\n",
    "# 100 entro false\n",
    "rf = RandomForestClassifier(n_estimators = 1000, criterion = 'entropy', bootstrap = False)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "scores = model_selection.cross_val_score(rf, X_train, y_train, cv=5)\n",
    "print (scores)\n",
    "print (scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurracy:  0.9178356713426854\n"
     ]
    }
   ],
   "source": [
    "# Testing our best R.F.\n",
    "\n",
    "print (\"Acurracy: \", rf.score(X_test,y_test))\n",
    "\n",
    "\n",
    "#scores = model_selection.cross_val_score(rf, X_test, y_test, cv=3)\n",
    "#print(scores)\n",
    "#print (scores.mean())\n",
    "#print (scores.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the Keras libraries and packages\n",
    "import numpy as np\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "# Create function returning a compiled network\n",
    "def create_network():\n",
    "    \n",
    "    # Start neural network\n",
    "    network = models.Sequential()\n",
    "\n",
    "    # Add fully connected layer with a ReLU activation function\n",
    "    network.add(layers.Dense(units=16, activation='relu', input_dim = 17))\n",
    "\n",
    "    # Add fully connected layer with a ReLU activation function\n",
    "    network.add(layers.Dense(units=16, activation='relu'))\n",
    "\n",
    "    # Add fully connected layer with a sigmoid activation function\n",
    "    network.add(layers.Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "    # Compile neural network\n",
    "    network.compile(loss='binary_crossentropy', # Cross-entropy\n",
    "                    optimizer='rmsprop', # Root Mean Square Propagation\n",
    "                    metrics=['accuracy']) # Accuracy performance metric\n",
    "    \n",
    "    # Return compiled network\n",
    "    return network\n",
    "\n",
    "# Wrap Keras model so it can be used by scikit-learn\n",
    "neural_network = KerasClassifier(build_fn=create_network, \n",
    "                                 epochs=64, \n",
    "                                 batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\kelusss\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\kelusss\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\kelusss\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\kelusss\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\kelusss\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\kelusss\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From c:\\users\\kelusss\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "Train on 1497 samples, validate on 499 samples\n",
      "Epoch 1/64\n",
      "1497/1497 [==============================] - 4s 3ms/step - loss: 0.4743 - acc: 0.8196 - val_loss: 0.4159 - val_acc: 0.8637\n",
      "Epoch 2/64\n",
      "1497/1497 [==============================] - 0s 294us/step - loss: 0.3259 - acc: 0.8871 - val_loss: 0.3541 - val_acc: 0.8758\n",
      "Epoch 3/64\n",
      "1497/1497 [==============================] - 0s 303us/step - loss: 0.2730 - acc: 0.8958 - val_loss: 0.3430 - val_acc: 0.8758\n",
      "Epoch 4/64\n",
      "1497/1497 [==============================] - 0s 273us/step - loss: 0.2525 - acc: 0.9051 - val_loss: 0.3367 - val_acc: 0.8778\n",
      "Epoch 5/64\n",
      "1497/1497 [==============================] - 0s 304us/step - loss: 0.2385 - acc: 0.9092 - val_loss: 0.3408 - val_acc: 0.8778\n",
      "Epoch 6/64\n",
      "1497/1497 [==============================] - 0s 301us/step - loss: 0.2301 - acc: 0.9105 - val_loss: 0.3312 - val_acc: 0.8838\n",
      "Epoch 7/64\n",
      "1497/1497 [==============================] - 0s 294us/step - loss: 0.2237 - acc: 0.9125 - val_loss: 0.3363 - val_acc: 0.8798\n",
      "Epoch 8/64\n",
      "1497/1497 [==============================] - 0s 306us/step - loss: 0.2185 - acc: 0.9125 - val_loss: 0.3351 - val_acc: 0.8838\n",
      "Epoch 9/64\n",
      "1497/1497 [==============================] - 0s 303us/step - loss: 0.2138 - acc: 0.9145 - val_loss: 0.3356 - val_acc: 0.8898\n",
      "Epoch 10/64\n",
      "1497/1497 [==============================] - 0s 305us/step - loss: 0.2098 - acc: 0.9172 - val_loss: 0.3341 - val_acc: 0.8918\n",
      "Epoch 11/64\n",
      "1497/1497 [==============================] - 0s 273us/step - loss: 0.2054 - acc: 0.9158 - val_loss: 0.3348 - val_acc: 0.8938\n",
      "Epoch 12/64\n",
      "1497/1497 [==============================] - 0s 278us/step - loss: 0.2028 - acc: 0.9198 - val_loss: 0.3310 - val_acc: 0.8978\n",
      "Epoch 13/64\n",
      "1497/1497 [==============================] - 0s 296us/step - loss: 0.2002 - acc: 0.9185 - val_loss: 0.3314 - val_acc: 0.9018\n",
      "Epoch 14/64\n",
      "1497/1497 [==============================] - 0s 294us/step - loss: 0.1964 - acc: 0.9232 - val_loss: 0.3343 - val_acc: 0.9018\n",
      "Epoch 15/64\n",
      "1497/1497 [==============================] - 0s 293us/step - loss: 0.1942 - acc: 0.9205 - val_loss: 0.3305 - val_acc: 0.9018\n",
      "Epoch 16/64\n",
      "1497/1497 [==============================] - 0s 294us/step - loss: 0.1909 - acc: 0.9225 - val_loss: 0.3322 - val_acc: 0.9018\n",
      "Epoch 17/64\n",
      "1497/1497 [==============================] - 0s 294us/step - loss: 0.1886 - acc: 0.9259 - val_loss: 0.3385 - val_acc: 0.8998\n",
      "Epoch 18/64\n",
      "1497/1497 [==============================] - 0s 270us/step - loss: 0.1866 - acc: 0.9245 - val_loss: 0.3396 - val_acc: 0.9018\n",
      "Epoch 19/64\n",
      "1497/1497 [==============================] - 0s 294us/step - loss: 0.1842 - acc: 0.9272 - val_loss: 0.3366 - val_acc: 0.9018\n",
      "Epoch 20/64\n",
      "1497/1497 [==============================] - 0s 285us/step - loss: 0.1824 - acc: 0.9232 - val_loss: 0.3371 - val_acc: 0.9038\n",
      "Epoch 21/64\n",
      "1497/1497 [==============================] - 0s 292us/step - loss: 0.1804 - acc: 0.9279 - val_loss: 0.3383 - val_acc: 0.9038\n",
      "Epoch 22/64\n",
      "1497/1497 [==============================] - 0s 283us/step - loss: 0.1782 - acc: 0.9238 - val_loss: 0.3351 - val_acc: 0.8998\n",
      "Epoch 23/64\n",
      "1497/1497 [==============================] - 0s 289us/step - loss: 0.1755 - acc: 0.9319 - val_loss: 0.3430 - val_acc: 0.9038\n",
      "Epoch 24/64\n",
      "1497/1497 [==============================] - 0s 275us/step - loss: 0.1746 - acc: 0.9305 - val_loss: 0.3383 - val_acc: 0.8978\n",
      "Epoch 25/64\n",
      "1497/1497 [==============================] - 0s 283us/step - loss: 0.1725 - acc: 0.9285 - val_loss: 0.3397 - val_acc: 0.9038\n",
      "Epoch 26/64\n",
      "1497/1497 [==============================] - 0s 293us/step - loss: 0.1704 - acc: 0.9319 - val_loss: 0.3418 - val_acc: 0.9038\n",
      "Epoch 27/64\n",
      "1497/1497 [==============================] - 0s 282us/step - loss: 0.1696 - acc: 0.9312 - val_loss: 0.3387 - val_acc: 0.9018\n",
      "Epoch 28/64\n",
      "1497/1497 [==============================] - 0s 291us/step - loss: 0.1663 - acc: 0.9345 - val_loss: 0.3450 - val_acc: 0.9038\n",
      "Epoch 29/64\n",
      "1497/1497 [==============================] - 0s 285us/step - loss: 0.1659 - acc: 0.9332 - val_loss: 0.3414 - val_acc: 0.9038\n",
      "Epoch 30/64\n",
      "1497/1497 [==============================] - 0s 282us/step - loss: 0.1645 - acc: 0.9325 - val_loss: 0.3466 - val_acc: 0.9038\n",
      "Epoch 31/64\n",
      "1497/1497 [==============================] - 0s 295us/step - loss: 0.1624 - acc: 0.9365 - val_loss: 0.3484 - val_acc: 0.9078\n",
      "Epoch 32/64\n",
      "1497/1497 [==============================] - 0s 283us/step - loss: 0.1611 - acc: 0.9359 - val_loss: 0.3464 - val_acc: 0.9058\n",
      "Epoch 33/64\n",
      "1497/1497 [==============================] - 0s 290us/step - loss: 0.1595 - acc: 0.9352 - val_loss: 0.3486 - val_acc: 0.9038\n",
      "Epoch 34/64\n",
      "1497/1497 [==============================] - 0s 283us/step - loss: 0.1579 - acc: 0.9352 - val_loss: 0.3480 - val_acc: 0.9018\n",
      "Epoch 35/64\n",
      "1497/1497 [==============================] - 0s 283us/step - loss: 0.1560 - acc: 0.9359 - val_loss: 0.3516 - val_acc: 0.9038\n",
      "Epoch 36/64\n",
      "1497/1497 [==============================] - 0s 283us/step - loss: 0.1548 - acc: 0.9379 - val_loss: 0.3555 - val_acc: 0.9038\n",
      "Epoch 37/64\n",
      "1497/1497 [==============================] - 0s 294us/step - loss: 0.1536 - acc: 0.9359 - val_loss: 0.3533 - val_acc: 0.9078\n",
      "Epoch 38/64\n",
      "1497/1497 [==============================] - 0s 280us/step - loss: 0.1520 - acc: 0.9359 - val_loss: 0.3522 - val_acc: 0.8998\n",
      "Epoch 39/64\n",
      "1497/1497 [==============================] - 0s 290us/step - loss: 0.1503 - acc: 0.9379 - val_loss: 0.3538 - val_acc: 0.9098\n",
      "Epoch 40/64\n",
      "1497/1497 [==============================] - 0s 254us/step - loss: 0.1482 - acc: 0.9399 - val_loss: 0.3555 - val_acc: 0.9078\n",
      "Epoch 41/64\n",
      "1497/1497 [==============================] - 0s 294us/step - loss: 0.1476 - acc: 0.9385 - val_loss: 0.3560 - val_acc: 0.9078\n",
      "Epoch 42/64\n",
      "1497/1497 [==============================] - 0s 314us/step - loss: 0.1465 - acc: 0.9419 - val_loss: 0.3561 - val_acc: 0.9098\n",
      "Epoch 43/64\n",
      "1497/1497 [==============================] - 0s 257us/step - loss: 0.1439 - acc: 0.9439 - val_loss: 0.3606 - val_acc: 0.9098\n",
      "Epoch 44/64\n",
      "1497/1497 [==============================] - 0s 255us/step - loss: 0.1425 - acc: 0.9426 - val_loss: 0.3591 - val_acc: 0.9078\n",
      "Epoch 45/64\n",
      "1497/1497 [==============================] - 0s 252us/step - loss: 0.1416 - acc: 0.9439 - val_loss: 0.3641 - val_acc: 0.9078\n",
      "Epoch 46/64\n",
      "1497/1497 [==============================] - 0s 272us/step - loss: 0.1403 - acc: 0.9466 - val_loss: 0.3578 - val_acc: 0.9018\n",
      "Epoch 47/64\n",
      "1497/1497 [==============================] - 0s 260us/step - loss: 0.1391 - acc: 0.9459 - val_loss: 0.3638 - val_acc: 0.9078\n",
      "Epoch 48/64\n",
      "1497/1497 [==============================] - 0s 264us/step - loss: 0.1364 - acc: 0.9472 - val_loss: 0.3645 - val_acc: 0.9058\n",
      "Epoch 49/64\n",
      "1497/1497 [==============================] - 0s 252us/step - loss: 0.1364 - acc: 0.9472 - val_loss: 0.3716 - val_acc: 0.9078\n",
      "Epoch 50/64\n",
      "1497/1497 [==============================] - 0s 262us/step - loss: 0.1357 - acc: 0.9486 - val_loss: 0.3657 - val_acc: 0.9038\n",
      "Epoch 51/64\n",
      "1497/1497 [==============================] - 0s 257us/step - loss: 0.1341 - acc: 0.9459 - val_loss: 0.3681 - val_acc: 0.9078\n",
      "Epoch 52/64\n",
      "1497/1497 [==============================] - ETA: 0s - loss: 0.1320 - acc: 0.951 - 0s 245us/step - loss: 0.1326 - acc: 0.9512 - val_loss: 0.3781 - val_acc: 0.9098\n",
      "Epoch 53/64\n",
      "1497/1497 [==============================] - 0s 251us/step - loss: 0.1320 - acc: 0.9486 - val_loss: 0.3768 - val_acc: 0.9038\n",
      "Epoch 54/64\n",
      "1497/1497 [==============================] - 0s 261us/step - loss: 0.1309 - acc: 0.9519 - val_loss: 0.3739 - val_acc: 0.9018\n",
      "Epoch 55/64\n",
      "1497/1497 [==============================] - 0s 251us/step - loss: 0.1297 - acc: 0.9506 - val_loss: 0.3814 - val_acc: 0.9058\n",
      "Epoch 56/64\n",
      "1497/1497 [==============================] - 0s 253us/step - loss: 0.1290 - acc: 0.9512 - val_loss: 0.3814 - val_acc: 0.9058\n",
      "Epoch 57/64\n",
      "1497/1497 [==============================] - 0s 251us/step - loss: 0.1267 - acc: 0.9532 - val_loss: 0.3778 - val_acc: 0.9098\n",
      "Epoch 58/64\n",
      "1497/1497 [==============================] - 0s 259us/step - loss: 0.1257 - acc: 0.9572 - val_loss: 0.3828 - val_acc: 0.9098\n",
      "Epoch 59/64\n",
      "1497/1497 [==============================] - 0s 243us/step - loss: 0.1252 - acc: 0.9539 - val_loss: 0.3862 - val_acc: 0.9078\n",
      "Epoch 60/64\n",
      "1497/1497 [==============================] - 0s 251us/step - loss: 0.1238 - acc: 0.9546 - val_loss: 0.3934 - val_acc: 0.9078\n",
      "Epoch 61/64\n",
      "1497/1497 [==============================] - 0s 252us/step - loss: 0.1224 - acc: 0.9539 - val_loss: 0.3874 - val_acc: 0.9098\n",
      "Epoch 62/64\n",
      "1497/1497 [==============================] - 0s 261us/step - loss: 0.1219 - acc: 0.9593 - val_loss: 0.3926 - val_acc: 0.9078\n",
      "Epoch 63/64\n",
      "1497/1497 [==============================] - 0s 262us/step - loss: 0.1202 - acc: 0.9572 - val_loss: 0.3870 - val_acc: 0.9058\n",
      "Epoch 64/64\n",
      "1497/1497 [==============================] - 0s 252us/step - loss: 0.1190 - acc: 0.9566 - val_loss: 0.3859 - val_acc: 0.9098\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 16)                288       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 577\n",
      "Trainable params: 577\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Evaluate neural network\n",
    "#neural_network.fit(X_train, y_train)\n",
    "\n",
    "history = neural_network.fit(X_train, y_train, validation_data=(X_test,y_test))\n",
    "neural_network.model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/64\n",
      "1197/1197 [==============================] - 1s 419us/step - loss: 0.5208 - acc: 0.7903\n",
      "Epoch 2/64\n",
      "1197/1197 [==============================] - 0s 241us/step - loss: 0.3838 - acc: 0.8538\n",
      "Epoch 3/64\n",
      "1197/1197 [==============================] - 0s 230us/step - loss: 0.3192 - acc: 0.8730\n",
      "Epoch 4/64\n",
      "1197/1197 [==============================] - 0s 250us/step - loss: 0.2882 - acc: 0.8789\n",
      "Epoch 5/64\n",
      "1197/1197 [==============================] - 0s 235us/step - loss: 0.2728 - acc: 0.8855\n",
      "Epoch 6/64\n",
      "1197/1197 [==============================] - 0s 249us/step - loss: 0.2603 - acc: 0.8881\n",
      "Epoch 7/64\n",
      "1197/1197 [==============================] - 0s 235us/step - loss: 0.2495 - acc: 0.8947\n",
      "Epoch 8/64\n",
      "1197/1197 [==============================] - 0s 224us/step - loss: 0.2412 - acc: 0.8989\n",
      "Epoch 9/64\n",
      "1197/1197 [==============================] - 0s 235us/step - loss: 0.2343 - acc: 0.9023\n",
      "Epoch 10/64\n",
      "1197/1197 [==============================] - 0s 236us/step - loss: 0.2272 - acc: 0.9031\n",
      "Epoch 11/64\n",
      "1197/1197 [==============================] - 0s 232us/step - loss: 0.2213 - acc: 0.9073\n",
      "Epoch 12/64\n",
      "1197/1197 [==============================] - 0s 226us/step - loss: 0.2168 - acc: 0.9148\n",
      "Epoch 13/64\n",
      "1197/1197 [==============================] - 0s 245us/step - loss: 0.2119 - acc: 0.9156\n",
      "Epoch 14/64\n",
      "1197/1197 [==============================] - 0s 266us/step - loss: 0.2083 - acc: 0.9148\n",
      "Epoch 15/64\n",
      "1197/1197 [==============================] - 0s 236us/step - loss: 0.2039 - acc: 0.9198\n",
      "Epoch 16/64\n",
      "1197/1197 [==============================] - 0s 235us/step - loss: 0.2000 - acc: 0.9231\n",
      "Epoch 17/64\n",
      "1197/1197 [==============================] - 0s 301us/step - loss: 0.1960 - acc: 0.9231\n",
      "Epoch 18/64\n",
      "1197/1197 [==============================] - 0s 238us/step - loss: 0.1936 - acc: 0.9240\n",
      "Epoch 19/64\n",
      "1197/1197 [==============================] - 0s 232us/step - loss: 0.1907 - acc: 0.9273\n",
      "Epoch 20/64\n",
      "1197/1197 [==============================] - 0s 245us/step - loss: 0.1877 - acc: 0.9282\n",
      "Epoch 21/64\n",
      "1197/1197 [==============================] - 0s 265us/step - loss: 0.1861 - acc: 0.9298\n",
      "Epoch 22/64\n",
      "1197/1197 [==============================] - 0s 250us/step - loss: 0.1830 - acc: 0.9315\n",
      "Epoch 23/64\n",
      "1197/1197 [==============================] - 0s 248us/step - loss: 0.1812 - acc: 0.9332\n",
      "Epoch 24/64\n",
      "1197/1197 [==============================] - 0s 236us/step - loss: 0.1788 - acc: 0.9323\n",
      "Epoch 25/64\n",
      "1197/1197 [==============================] - 0s 248us/step - loss: 0.1765 - acc: 0.9348\n",
      "Epoch 26/64\n",
      "1197/1197 [==============================] - 0s 250us/step - loss: 0.1743 - acc: 0.9357\n",
      "Epoch 27/64\n",
      "1197/1197 [==============================] - 0s 246us/step - loss: 0.1723 - acc: 0.9357\n",
      "Epoch 28/64\n",
      "1197/1197 [==============================] - 0s 266us/step - loss: 0.1702 - acc: 0.9340\n",
      "Epoch 29/64\n",
      "1197/1197 [==============================] - 0s 249us/step - loss: 0.1688 - acc: 0.9373\n",
      "Epoch 30/64\n",
      "1197/1197 [==============================] - 0s 248us/step - loss: 0.1666 - acc: 0.9365\n",
      "Epoch 31/64\n",
      "1197/1197 [==============================] - 0s 250us/step - loss: 0.1645 - acc: 0.9407\n",
      "Epoch 32/64\n",
      "1197/1197 [==============================] - 0s 248us/step - loss: 0.1634 - acc: 0.9415\n",
      "Epoch 33/64\n",
      "1197/1197 [==============================] - 0s 236us/step - loss: 0.1613 - acc: 0.9424\n",
      "Epoch 34/64\n",
      "1197/1197 [==============================] - 0s 222us/step - loss: 0.1603 - acc: 0.9390\n",
      "Epoch 35/64\n",
      "1197/1197 [==============================] - 0s 224us/step - loss: 0.1584 - acc: 0.9390\n",
      "Epoch 36/64\n",
      "1197/1197 [==============================] - 0s 248us/step - loss: 0.1568 - acc: 0.9424\n",
      "Epoch 37/64\n",
      "1197/1197 [==============================] - 0s 222us/step - loss: 0.1553 - acc: 0.9407\n",
      "Epoch 38/64\n",
      "1197/1197 [==============================] - 0s 233us/step - loss: 0.1542 - acc: 0.9415\n",
      "Epoch 39/64\n",
      "1197/1197 [==============================] - 0s 238us/step - loss: 0.1535 - acc: 0.9440\n",
      "Epoch 40/64\n",
      "1197/1197 [==============================] - 0s 261us/step - loss: 0.1520 - acc: 0.9415\n",
      "Epoch 41/64\n",
      "1197/1197 [==============================] - 0s 223us/step - loss: 0.1506 - acc: 0.9424\n",
      "Epoch 42/64\n",
      "1197/1197 [==============================] - 0s 237us/step - loss: 0.1495 - acc: 0.9449\n",
      "Epoch 43/64\n",
      "1197/1197 [==============================] - 0s 222us/step - loss: 0.1480 - acc: 0.9457\n",
      "Epoch 44/64\n",
      "1197/1197 [==============================] - 0s 223us/step - loss: 0.1466 - acc: 0.9465\n",
      "Epoch 45/64\n",
      "1197/1197 [==============================] - 0s 235us/step - loss: 0.1462 - acc: 0.9457\n",
      "Epoch 46/64\n",
      "1197/1197 [==============================] - 0s 250us/step - loss: 0.1447 - acc: 0.9474\n",
      "Epoch 47/64\n",
      "1197/1197 [==============================] - 0s 287us/step - loss: 0.1444 - acc: 0.9449\n",
      "Epoch 48/64\n",
      "1197/1197 [==============================] - 0s 237us/step - loss: 0.1428 - acc: 0.9457\n",
      "Epoch 49/64\n",
      "1197/1197 [==============================] - 0s 258us/step - loss: 0.1414 - acc: 0.9482\n",
      "Epoch 50/64\n",
      "1197/1197 [==============================] - 0s 214us/step - loss: 0.1400 - acc: 0.9507\n",
      "Epoch 51/64\n",
      "1197/1197 [==============================] - 0s 232us/step - loss: 0.1389 - acc: 0.9474\n",
      "Epoch 52/64\n",
      "1197/1197 [==============================] - 0s 252us/step - loss: 0.1388 - acc: 0.9474\n",
      "Epoch 53/64\n",
      "1197/1197 [==============================] - 0s 230us/step - loss: 0.1376 - acc: 0.9507\n",
      "Epoch 54/64\n",
      "1197/1197 [==============================] - 0s 213us/step - loss: 0.1356 - acc: 0.9524\n",
      "Epoch 55/64\n",
      "1197/1197 [==============================] - 0s 226us/step - loss: 0.1357 - acc: 0.9524\n",
      "Epoch 56/64\n",
      "1197/1197 [==============================] - 0s 218us/step - loss: 0.1338 - acc: 0.9515\n",
      "Epoch 57/64\n",
      "1197/1197 [==============================] - 0s 237us/step - loss: 0.1328 - acc: 0.9515\n",
      "Epoch 58/64\n",
      "1197/1197 [==============================] - 0s 235us/step - loss: 0.1319 - acc: 0.9515\n",
      "Epoch 59/64\n",
      "1197/1197 [==============================] - 0s 237us/step - loss: 0.1310 - acc: 0.9532\n",
      "Epoch 60/64\n",
      "1197/1197 [==============================] - 0s 248us/step - loss: 0.1301 - acc: 0.9532\n",
      "Epoch 61/64\n",
      "1197/1197 [==============================] - 0s 236us/step - loss: 0.1280 - acc: 0.9541\n",
      "Epoch 62/64\n",
      "1197/1197 [==============================] - 0s 222us/step - loss: 0.1282 - acc: 0.9524\n",
      "Epoch 63/64\n",
      "1197/1197 [==============================] - 0s 236us/step - loss: 0.1250 - acc: 0.9591\n",
      "Epoch 64/64\n",
      "1197/1197 [==============================] - 0s 222us/step - loss: 0.1267 - acc: 0.9532\n",
      "300/300 [==============================] - 0s 253us/step\n",
      "Epoch 1/64\n",
      "1197/1197 [==============================] - 1s 472us/step - loss: 0.5522 - acc: 0.7109\n",
      "Epoch 2/64\n",
      "1197/1197 [==============================] - 0s 224us/step - loss: 0.3832 - acc: 0.8814\n",
      "Epoch 3/64\n",
      "1197/1197 [==============================] - 0s 222us/step - loss: 0.3031 - acc: 0.8839\n",
      "Epoch 4/64\n",
      "1197/1197 [==============================] - 0s 236us/step - loss: 0.2709 - acc: 0.8914\n",
      "Epoch 5/64\n",
      "1197/1197 [==============================] - 0s 209us/step - loss: 0.2562 - acc: 0.9006\n",
      "Epoch 6/64\n",
      "1197/1197 [==============================] - 0s 223us/step - loss: 0.2463 - acc: 0.9014\n",
      "Epoch 7/64\n",
      "1197/1197 [==============================] - 0s 222us/step - loss: 0.2397 - acc: 0.9031\n",
      "Epoch 8/64\n",
      "1197/1197 [==============================] - 0s 224us/step - loss: 0.2327 - acc: 0.9064\n",
      "Epoch 9/64\n",
      "1197/1197 [==============================] - 0s 222us/step - loss: 0.2266 - acc: 0.9081\n",
      "Epoch 10/64\n",
      "1197/1197 [==============================] - 0s 223us/step - loss: 0.2233 - acc: 0.9089\n",
      "Epoch 11/64\n",
      "1197/1197 [==============================] - 0s 222us/step - loss: 0.2190 - acc: 0.9148\n",
      "Epoch 12/64\n",
      "1197/1197 [==============================] - 0s 223us/step - loss: 0.2148 - acc: 0.9140\n",
      "Epoch 13/64\n",
      "1197/1197 [==============================] - 0s 222us/step - loss: 0.2109 - acc: 0.9181\n",
      "Epoch 14/64\n",
      "1197/1197 [==============================] - 0s 223us/step - loss: 0.2076 - acc: 0.9198\n",
      "Epoch 15/64\n",
      "1197/1197 [==============================] - 0s 222us/step - loss: 0.2047 - acc: 0.9198\n",
      "Epoch 16/64\n",
      "1197/1197 [==============================] - 0s 224us/step - loss: 0.2031 - acc: 0.9198\n",
      "Epoch 17/64\n",
      "1197/1197 [==============================] - 0s 209us/step - loss: 0.1997 - acc: 0.9206\n",
      "Epoch 18/64\n",
      "1197/1197 [==============================] - 0s 223us/step - loss: 0.1970 - acc: 0.9215\n",
      "Epoch 19/64\n",
      "1197/1197 [==============================] - 0s 209us/step - loss: 0.1946 - acc: 0.9223\n",
      "Epoch 20/64\n",
      "1197/1197 [==============================] - 0s 211us/step - loss: 0.1929 - acc: 0.9240\n",
      "Epoch 21/64\n",
      "1197/1197 [==============================] - 0s 209us/step - loss: 0.1903 - acc: 0.9248\n",
      "Epoch 22/64\n",
      "1197/1197 [==============================] - 0s 210us/step - loss: 0.1890 - acc: 0.9248\n",
      "Epoch 23/64\n",
      "1197/1197 [==============================] - 0s 196us/step - loss: 0.1864 - acc: 0.9265\n",
      "Epoch 24/64\n",
      "1197/1197 [==============================] - 0s 210us/step - loss: 0.1842 - acc: 0.9290\n",
      "Epoch 25/64\n",
      "1197/1197 [==============================] - 0s 209us/step - loss: 0.1828 - acc: 0.9240\n",
      "Epoch 26/64\n",
      "1197/1197 [==============================] - 0s 223us/step - loss: 0.1805 - acc: 0.9282\n",
      "Epoch 27/64\n",
      "1197/1197 [==============================] - 0s 222us/step - loss: 0.1788 - acc: 0.9298\n",
      "Epoch 28/64\n",
      "1197/1197 [==============================] - 0s 223us/step - loss: 0.1771 - acc: 0.9332\n",
      "Epoch 29/64\n",
      "1197/1197 [==============================] - 0s 222us/step - loss: 0.1761 - acc: 0.9290\n",
      "Epoch 30/64\n",
      "1197/1197 [==============================] - 0s 219us/step - loss: 0.1738 - acc: 0.9307\n",
      "Epoch 31/64\n",
      "1197/1197 [==============================] - 0s 200us/step - loss: 0.1724 - acc: 0.9315\n",
      "Epoch 32/64\n",
      "1197/1197 [==============================] - 0s 231us/step - loss: 0.1716 - acc: 0.9332\n",
      "Epoch 33/64\n",
      "1197/1197 [==============================] - 0s 199us/step - loss: 0.1695 - acc: 0.9340\n",
      "Epoch 34/64\n",
      "1197/1197 [==============================] - 0s 212us/step - loss: 0.1679 - acc: 0.9348\n",
      "Epoch 35/64\n",
      "1197/1197 [==============================] - 0s 205us/step - loss: 0.1672 - acc: 0.9332\n",
      "Epoch 36/64\n",
      "1197/1197 [==============================] - 0s 220us/step - loss: 0.1650 - acc: 0.9348\n",
      "Epoch 37/64\n",
      "1197/1197 [==============================] - 0s 212us/step - loss: 0.1636 - acc: 0.9390\n",
      "Epoch 38/64\n",
      "1197/1197 [==============================] - 0s 207us/step - loss: 0.1628 - acc: 0.9365\n",
      "Epoch 39/64\n",
      "1197/1197 [==============================] - 0s 211us/step - loss: 0.1613 - acc: 0.9382\n",
      "Epoch 40/64\n",
      "1197/1197 [==============================] - 0s 222us/step - loss: 0.1601 - acc: 0.9382\n",
      "Epoch 41/64\n",
      "1197/1197 [==============================] - 0s 212us/step - loss: 0.1588 - acc: 0.9407\n",
      "Epoch 42/64\n",
      "1197/1197 [==============================] - 0s 218us/step - loss: 0.1569 - acc: 0.9415\n",
      "Epoch 43/64\n",
      "1197/1197 [==============================] - 0s 214us/step - loss: 0.1563 - acc: 0.9398\n",
      "Epoch 44/64\n",
      "1197/1197 [==============================] - 0s 217us/step - loss: 0.1546 - acc: 0.9432\n",
      "Epoch 45/64\n",
      "1197/1197 [==============================] - 0s 200us/step - loss: 0.1529 - acc: 0.9432\n",
      "Epoch 46/64\n",
      "1197/1197 [==============================] - 0s 209us/step - loss: 0.1517 - acc: 0.9449\n",
      "Epoch 47/64\n",
      "1197/1197 [==============================] - 0s 237us/step - loss: 0.1505 - acc: 0.9424\n",
      "Epoch 48/64\n",
      "1197/1197 [==============================] - 0s 234us/step - loss: 0.1487 - acc: 0.9457\n",
      "Epoch 49/64\n",
      "1197/1197 [==============================] - 0s 209us/step - loss: 0.1479 - acc: 0.9474\n",
      "Epoch 50/64\n",
      "1197/1197 [==============================] - 0s 209us/step - loss: 0.1467 - acc: 0.9449\n",
      "Epoch 51/64\n",
      "1197/1197 [==============================] - 0s 211us/step - loss: 0.1454 - acc: 0.9449\n",
      "Epoch 52/64\n",
      "1197/1197 [==============================] - 0s 222us/step - loss: 0.1438 - acc: 0.9457\n",
      "Epoch 53/64\n",
      "1197/1197 [==============================] - 0s 210us/step - loss: 0.1428 - acc: 0.9465\n",
      "Epoch 54/64\n",
      "1197/1197 [==============================] - 0s 209us/step - loss: 0.1408 - acc: 0.9465\n",
      "Epoch 55/64\n",
      "1197/1197 [==============================] - 0s 223us/step - loss: 0.1397 - acc: 0.9482\n",
      "Epoch 56/64\n",
      "1197/1197 [==============================] - 0s 222us/step - loss: 0.1384 - acc: 0.9515\n",
      "Epoch 57/64\n",
      "1197/1197 [==============================] - 0s 211us/step - loss: 0.1376 - acc: 0.9457\n",
      "Epoch 58/64\n",
      "1197/1197 [==============================] - 0s 209us/step - loss: 0.1364 - acc: 0.9482\n",
      "Epoch 59/64\n",
      "1197/1197 [==============================] - 0s 223us/step - loss: 0.1344 - acc: 0.9490\n",
      "Epoch 60/64\n",
      "1197/1197 [==============================] - 0s 209us/step - loss: 0.1333 - acc: 0.9499\n",
      "Epoch 61/64\n",
      "1197/1197 [==============================] - 0s 223us/step - loss: 0.1330 - acc: 0.9490\n",
      "Epoch 62/64\n",
      "1197/1197 [==============================] - 0s 235us/step - loss: 0.1310 - acc: 0.9524\n",
      "Epoch 63/64\n",
      "1197/1197 [==============================] - 0s 223us/step - loss: 0.1301 - acc: 0.9532\n",
      "Epoch 64/64\n",
      "1197/1197 [==============================] - 0s 222us/step - loss: 0.1287 - acc: 0.9507\n",
      "300/300 [==============================] - 0s 250us/step\n",
      "Epoch 1/64\n",
      "1198/1198 [==============================] - 1s 445us/step - loss: 0.6018 - acc: 0.6703\n",
      "Epoch 2/64\n",
      "1198/1198 [==============================] - 0s 220us/step - loss: 0.4819 - acc: 0.8581\n",
      "Epoch 3/64\n",
      "1198/1198 [==============================] - 0s 212us/step - loss: 0.3619 - acc: 0.8940\n",
      "Epoch 4/64\n",
      "1198/1198 [==============================] - 0s 207us/step - loss: 0.2921 - acc: 0.9007\n",
      "Epoch 5/64\n",
      "1198/1198 [==============================] - 0s 225us/step - loss: 0.2636 - acc: 0.9040\n",
      "Epoch 6/64\n",
      "1198/1198 [==============================] - 0s 219us/step - loss: 0.2497 - acc: 0.9065\n",
      "Epoch 7/64\n",
      "1198/1198 [==============================] - 0s 214us/step - loss: 0.2394 - acc: 0.9124\n",
      "Epoch 8/64\n",
      "1198/1198 [==============================] - 0s 217us/step - loss: 0.2311 - acc: 0.9115\n",
      "Epoch 9/64\n",
      "1198/1198 [==============================] - 0s 213us/step - loss: 0.2243 - acc: 0.9165\n",
      "Epoch 10/64\n",
      "1198/1198 [==============================] - 0s 220us/step - loss: 0.2177 - acc: 0.9190\n",
      "Epoch 11/64\n",
      "1198/1198 [==============================] - 0s 225us/step - loss: 0.2112 - acc: 0.9199\n",
      "Epoch 12/64\n",
      "1198/1198 [==============================] - 0s 220us/step - loss: 0.2059 - acc: 0.9282\n",
      "Epoch 13/64\n",
      "1198/1198 [==============================] - 0s 225us/step - loss: 0.2026 - acc: 0.9257\n",
      "Epoch 14/64\n",
      "1198/1198 [==============================] - 0s 233us/step - loss: 0.1988 - acc: 0.9257\n",
      "Epoch 15/64\n",
      "1198/1198 [==============================] - 0s 214us/step - loss: 0.1952 - acc: 0.9290\n",
      "Epoch 16/64\n",
      "1198/1198 [==============================] - 0s 217us/step - loss: 0.1914 - acc: 0.9307\n",
      "Epoch 17/64\n",
      "1198/1198 [==============================] - 0s 227us/step - loss: 0.1889 - acc: 0.9290\n",
      "Epoch 18/64\n",
      "1198/1198 [==============================] - 0s 223us/step - loss: 0.1858 - acc: 0.9316\n",
      "Epoch 19/64\n",
      "1198/1198 [==============================] - 0s 206us/step - loss: 0.1836 - acc: 0.9332\n",
      "Epoch 20/64\n",
      "1198/1198 [==============================] - 0s 220us/step - loss: 0.1805 - acc: 0.9316\n",
      "Epoch 21/64\n",
      "1198/1198 [==============================] - 0s 225us/step - loss: 0.1778 - acc: 0.9324\n",
      "Epoch 22/64\n",
      "1198/1198 [==============================] - 0s 220us/step - loss: 0.1757 - acc: 0.9316\n",
      "Epoch 23/64\n",
      "1198/1198 [==============================] - 0s 226us/step - loss: 0.1734 - acc: 0.9341\n",
      "Epoch 24/64\n",
      "1198/1198 [==============================] - 0s 207us/step - loss: 0.1715 - acc: 0.9341\n",
      "Epoch 25/64\n",
      "1198/1198 [==============================] - 0s 238us/step - loss: 0.1696 - acc: 0.9366\n",
      "Epoch 26/64\n",
      "1198/1198 [==============================] - 0s 206us/step - loss: 0.1678 - acc: 0.9349\n",
      "Epoch 27/64\n",
      "1198/1198 [==============================] - 0s 226us/step - loss: 0.1654 - acc: 0.9374\n",
      "Epoch 28/64\n",
      "1198/1198 [==============================] - 0s 219us/step - loss: 0.1650 - acc: 0.9391\n",
      "Epoch 29/64\n",
      "1198/1198 [==============================] - 0s 226us/step - loss: 0.1622 - acc: 0.9374\n",
      "Epoch 30/64\n",
      "1198/1198 [==============================] - 0s 206us/step - loss: 0.1610 - acc: 0.9391\n",
      "Epoch 31/64\n",
      "1198/1198 [==============================] - 0s 213us/step - loss: 0.1590 - acc: 0.9374\n",
      "Epoch 32/64\n",
      "1198/1198 [==============================] - 0s 220us/step - loss: 0.1576 - acc: 0.9382\n",
      "Epoch 33/64\n",
      "1198/1198 [==============================] - 0s 225us/step - loss: 0.1562 - acc: 0.9416\n",
      "Epoch 34/64\n",
      "1198/1198 [==============================] - 0s 220us/step - loss: 0.1542 - acc: 0.9407\n",
      "Epoch 35/64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1198/1198 [==============================] - 0s 225us/step - loss: 0.1520 - acc: 0.9424\n",
      "Epoch 36/64\n",
      "1198/1198 [==============================] - 0s 219us/step - loss: 0.1498 - acc: 0.9416\n",
      "Epoch 37/64\n",
      "1198/1198 [==============================] - 0s 226us/step - loss: 0.1491 - acc: 0.9441\n",
      "Epoch 38/64\n",
      "1198/1198 [==============================] - 0s 240us/step - loss: 0.1479 - acc: 0.9424\n",
      "Epoch 39/64\n",
      "1198/1198 [==============================] - 0s 204us/step - loss: 0.1457 - acc: 0.9457\n",
      "Epoch 40/64\n",
      "1198/1198 [==============================] - 0s 227us/step - loss: 0.1436 - acc: 0.9474\n",
      "Epoch 41/64\n",
      "1198/1198 [==============================] - 0s 217us/step - loss: 0.1426 - acc: 0.9466\n",
      "Epoch 42/64\n",
      "1198/1198 [==============================] - 0s 230us/step - loss: 0.1406 - acc: 0.9499\n",
      "Epoch 43/64\n",
      "1198/1198 [==============================] - 0s 213us/step - loss: 0.1401 - acc: 0.9482\n",
      "Epoch 44/64\n",
      "1198/1198 [==============================] - 0s 228us/step - loss: 0.1379 - acc: 0.9499\n",
      "Epoch 45/64\n",
      "1198/1198 [==============================] - 0s 217us/step - loss: 0.1367 - acc: 0.9482\n",
      "Epoch 46/64\n",
      "1198/1198 [==============================] - 0s 231us/step - loss: 0.1359 - acc: 0.9499\n",
      "Epoch 47/64\n",
      "1198/1198 [==============================] - 0s 212us/step - loss: 0.1332 - acc: 0.9499\n",
      "Epoch 48/64\n",
      "1198/1198 [==============================] - 0s 236us/step - loss: 0.1327 - acc: 0.9516\n",
      "Epoch 49/64\n",
      "1198/1198 [==============================] - 0s 222us/step - loss: 0.1311 - acc: 0.9524\n",
      "Epoch 50/64\n",
      "1198/1198 [==============================] - 0s 223us/step - loss: 0.1308 - acc: 0.9508\n",
      "Epoch 51/64\n",
      "1198/1198 [==============================] - 0s 209us/step - loss: 0.1292 - acc: 0.9516\n",
      "Epoch 52/64\n",
      "1198/1198 [==============================] - 0s 235us/step - loss: 0.1280 - acc: 0.9524\n",
      "Epoch 53/64\n",
      "1198/1198 [==============================] - 0s 222us/step - loss: 0.1271 - acc: 0.9524\n",
      "Epoch 54/64\n",
      "1198/1198 [==============================] - 0s 223us/step - loss: 0.1253 - acc: 0.9533\n",
      "Epoch 55/64\n",
      "1198/1198 [==============================] - 0s 222us/step - loss: 0.1240 - acc: 0.9533\n",
      "Epoch 56/64\n",
      "1198/1198 [==============================] - 0s 223us/step - loss: 0.1226 - acc: 0.9549\n",
      "Epoch 57/64\n",
      "1198/1198 [==============================] - 0s 222us/step - loss: 0.1222 - acc: 0.9549\n",
      "Epoch 58/64\n",
      "1198/1198 [==============================] - 0s 262us/step - loss: 0.1213 - acc: 0.9533\n",
      "Epoch 59/64\n",
      "1198/1198 [==============================] - 0s 287us/step - loss: 0.1191 - acc: 0.9558\n",
      "Epoch 60/64\n",
      "1198/1198 [==============================] - 0s 275us/step - loss: 0.1185 - acc: 0.9541\n",
      "Epoch 61/64\n",
      "1198/1198 [==============================] - 0s 264us/step - loss: 0.1174 - acc: 0.9549\n",
      "Epoch 62/64\n",
      "1198/1198 [==============================] - 0s 257us/step - loss: 0.1161 - acc: 0.9566\n",
      "Epoch 63/64\n",
      "1198/1198 [==============================] - 0s 263us/step - loss: 0.1149 - acc: 0.9583\n",
      "Epoch 64/64\n",
      "1198/1198 [==============================] - 0s 248us/step - loss: 0.1138 - acc: 0.9549\n",
      "299/299 [==============================] - 0s 304us/step\n",
      "Epoch 1/64\n",
      "1198/1198 [==============================] - 1s 505us/step - loss: 0.6312 - acc: 0.7220\n",
      "Epoch 2/64\n",
      "1198/1198 [==============================] - 0s 242us/step - loss: 0.4364 - acc: 0.8255\n",
      "Epoch 3/64\n",
      "1198/1198 [==============================] - 0s 265us/step - loss: 0.3421 - acc: 0.8673\n",
      "Epoch 4/64\n",
      "1198/1198 [==============================] - 0s 230us/step - loss: 0.3021 - acc: 0.8840\n",
      "Epoch 5/64\n",
      "1198/1198 [==============================] - 0s 262us/step - loss: 0.2824 - acc: 0.8865\n",
      "Epoch 6/64\n",
      "1198/1198 [==============================] - 0s 274us/step - loss: 0.2660 - acc: 0.8923\n",
      "Epoch 7/64\n",
      "1198/1198 [==============================] - 0s 263us/step - loss: 0.2547 - acc: 0.8990\n",
      "Epoch 8/64\n",
      "1198/1198 [==============================] - 0s 288us/step - loss: 0.2448 - acc: 0.9048\n",
      "Epoch 9/64\n",
      "1198/1198 [==============================] - 0s 246us/step - loss: 0.2382 - acc: 0.9082\n",
      "Epoch 10/64\n",
      "1198/1198 [==============================] - 0s 236us/step - loss: 0.2320 - acc: 0.9124\n",
      "Epoch 11/64\n",
      "1198/1198 [==============================] - 0s 274us/step - loss: 0.2260 - acc: 0.9165\n",
      "Epoch 12/64\n",
      "1198/1198 [==============================] - 0s 236us/step - loss: 0.2230 - acc: 0.9157\n",
      "Epoch 13/64\n",
      "1198/1198 [==============================] - 0s 235us/step - loss: 0.2176 - acc: 0.9190\n",
      "Epoch 14/64\n",
      "1198/1198 [==============================] - 0s 251us/step - loss: 0.2145 - acc: 0.9207\n",
      "Epoch 15/64\n",
      "1198/1198 [==============================] - 0s 270us/step - loss: 0.2102 - acc: 0.9199\n",
      "Epoch 16/64\n",
      "1198/1198 [==============================] - 0s 267us/step - loss: 0.2068 - acc: 0.9190\n",
      "Epoch 17/64\n",
      "1198/1198 [==============================] - 0s 275us/step - loss: 0.2047 - acc: 0.9240\n",
      "Epoch 18/64\n",
      "1198/1198 [==============================] - 0s 274us/step - loss: 0.2020 - acc: 0.9249\n",
      "Epoch 19/64\n",
      "1198/1198 [==============================] - 0s 275us/step - loss: 0.1996 - acc: 0.9249\n",
      "Epoch 20/64\n",
      "1198/1198 [==============================] - 0s 274us/step - loss: 0.1962 - acc: 0.9265\n",
      "Epoch 21/64\n",
      "1198/1198 [==============================] - 0s 247us/step - loss: 0.1942 - acc: 0.9265\n",
      "Epoch 22/64\n",
      "1198/1198 [==============================] - 0s 249us/step - loss: 0.1925 - acc: 0.9257\n",
      "Epoch 23/64\n",
      "1198/1198 [==============================] - 0s 235us/step - loss: 0.1903 - acc: 0.9265\n",
      "Epoch 24/64\n",
      "1198/1198 [==============================] - 0s 237us/step - loss: 0.1874 - acc: 0.9290\n",
      "Epoch 25/64\n",
      "1198/1198 [==============================] - 0s 222us/step - loss: 0.1858 - acc: 0.9265\n",
      "Epoch 26/64\n",
      "1198/1198 [==============================] - 0s 224us/step - loss: 0.1841 - acc: 0.9274\n",
      "Epoch 27/64\n",
      "1198/1198 [==============================] - 0s 222us/step - loss: 0.1818 - acc: 0.9324\n",
      "Epoch 28/64\n",
      "1198/1198 [==============================] - 0s 235us/step - loss: 0.1800 - acc: 0.9316\n",
      "Epoch 29/64\n",
      "1198/1198 [==============================] - 0s 222us/step - loss: 0.1772 - acc: 0.9316\n",
      "Epoch 30/64\n",
      "1198/1198 [==============================] - 0s 236us/step - loss: 0.1764 - acc: 0.9324\n",
      "Epoch 31/64\n",
      "1198/1198 [==============================] - 0s 222us/step - loss: 0.1748 - acc: 0.9316\n",
      "Epoch 32/64\n",
      "1198/1198 [==============================] - 0s 222us/step - loss: 0.1727 - acc: 0.9341\n",
      "Epoch 33/64\n",
      "1198/1198 [==============================] - 0s 225us/step - loss: 0.1700 - acc: 0.9357\n",
      "Epoch 34/64\n",
      "1198/1198 [==============================] - 0s 232us/step - loss: 0.1695 - acc: 0.9349\n",
      "Epoch 35/64\n",
      "1198/1198 [==============================] - 0s 219us/step - loss: 0.1669 - acc: 0.9357\n",
      "Epoch 36/64\n",
      "1198/1198 [==============================] - 0s 227us/step - loss: 0.1653 - acc: 0.9416\n",
      "Epoch 37/64\n",
      "1198/1198 [==============================] - 0s 231us/step - loss: 0.1653 - acc: 0.9407\n",
      "Epoch 38/64\n",
      "1198/1198 [==============================] - 0s 226us/step - loss: 0.1627 - acc: 0.9391\n",
      "Epoch 39/64\n",
      "1198/1198 [==============================] - 0s 255us/step - loss: 0.1603 - acc: 0.9432\n",
      "Epoch 40/64\n",
      "1198/1198 [==============================] - 0s 254us/step - loss: 0.1598 - acc: 0.9416\n",
      "Epoch 41/64\n",
      "1198/1198 [==============================] - 0s 236us/step - loss: 0.1576 - acc: 0.9432\n",
      "Epoch 42/64\n",
      "1198/1198 [==============================] - 0s 222us/step - loss: 0.1570 - acc: 0.9416\n",
      "Epoch 43/64\n",
      "1198/1198 [==============================] - 0s 237us/step - loss: 0.1550 - acc: 0.9416\n",
      "Epoch 44/64\n",
      "1198/1198 [==============================] - 0s 235us/step - loss: 0.1541 - acc: 0.9466\n",
      "Epoch 45/64\n",
      "1198/1198 [==============================] - 0s 236us/step - loss: 0.1526 - acc: 0.9457\n",
      "Epoch 46/64\n",
      "1198/1198 [==============================] - 0s 222us/step - loss: 0.1510 - acc: 0.9466\n",
      "Epoch 47/64\n",
      "1198/1198 [==============================] - 0s 235us/step - loss: 0.1493 - acc: 0.9466\n",
      "Epoch 48/64\n",
      "1198/1198 [==============================] - 0s 238us/step - loss: 0.1488 - acc: 0.9449\n",
      "Epoch 49/64\n",
      "1198/1198 [==============================] - 0s 218us/step - loss: 0.1467 - acc: 0.9482\n",
      "Epoch 50/64\n",
      "1198/1198 [==============================] - 0s 223us/step - loss: 0.1454 - acc: 0.9449\n",
      "Epoch 51/64\n",
      "1198/1198 [==============================] - 0s 221us/step - loss: 0.1444 - acc: 0.9491\n",
      "Epoch 52/64\n",
      "1198/1198 [==============================] - 0s 219us/step - loss: 0.1425 - acc: 0.9508\n",
      "Epoch 53/64\n",
      "1198/1198 [==============================] - 0s 226us/step - loss: 0.1417 - acc: 0.9499\n",
      "Epoch 54/64\n",
      "1198/1198 [==============================] - 0s 219us/step - loss: 0.1407 - acc: 0.9491\n",
      "Epoch 55/64\n",
      "1198/1198 [==============================] - 0s 227us/step - loss: 0.1393 - acc: 0.9508\n",
      "Epoch 56/64\n",
      "1198/1198 [==============================] - 0s 230us/step - loss: 0.1380 - acc: 0.9541\n",
      "Epoch 57/64\n",
      "1198/1198 [==============================] - 0s 239us/step - loss: 0.1354 - acc: 0.9549\n",
      "Epoch 58/64\n",
      "1198/1198 [==============================] - 0s 235us/step - loss: 0.1357 - acc: 0.9508\n",
      "Epoch 59/64\n",
      "1198/1198 [==============================] - 0s 222us/step - loss: 0.1345 - acc: 0.9524\n",
      "Epoch 60/64\n",
      "1198/1198 [==============================] - 0s 236us/step - loss: 0.1334 - acc: 0.9524\n",
      "Epoch 61/64\n",
      "1198/1198 [==============================] - 0s 222us/step - loss: 0.1327 - acc: 0.9533\n",
      "Epoch 62/64\n",
      "1198/1198 [==============================] - 0s 223us/step - loss: 0.1308 - acc: 0.9533\n",
      "Epoch 63/64\n",
      "1198/1198 [==============================] - 0s 235us/step - loss: 0.1288 - acc: 0.9533\n",
      "Epoch 64/64\n",
      "1198/1198 [==============================] - 0s 237us/step - loss: 0.1280 - acc: 0.9574\n",
      "299/299 [==============================] - 0s 366us/step\n",
      "Epoch 1/64\n",
      "1198/1198 [==============================] - 1s 513us/step - loss: 0.4918 - acc: 0.8573\n",
      "Epoch 2/64\n",
      "1198/1198 [==============================] - 0s 219us/step - loss: 0.3530 - acc: 0.8948\n",
      "Epoch 3/64\n",
      "1198/1198 [==============================] - 0s 227us/step - loss: 0.2855 - acc: 0.8998\n",
      "Epoch 4/64\n",
      "1198/1198 [==============================] - 0s 235us/step - loss: 0.2594 - acc: 0.8965\n",
      "Epoch 5/64\n",
      "1198/1198 [==============================] - 0s 223us/step - loss: 0.2471 - acc: 0.9082\n",
      "Epoch 6/64\n",
      "1198/1198 [==============================] - 0s 235us/step - loss: 0.2376 - acc: 0.9073\n",
      "Epoch 7/64\n",
      "1198/1198 [==============================] - 0s 223us/step - loss: 0.2298 - acc: 0.9098\n",
      "Epoch 8/64\n",
      "1198/1198 [==============================] - 0s 222us/step - loss: 0.2242 - acc: 0.9140\n",
      "Epoch 9/64\n",
      "1198/1198 [==============================] - 0s 236us/step - loss: 0.2190 - acc: 0.9190\n",
      "Epoch 10/64\n",
      "1198/1198 [==============================] - 0s 235us/step - loss: 0.2148 - acc: 0.9182\n",
      "Epoch 11/64\n",
      "1198/1198 [==============================] - 0s 223us/step - loss: 0.2108 - acc: 0.9224\n",
      "Epoch 12/64\n",
      "1198/1198 [==============================] - 0s 235us/step - loss: 0.2075 - acc: 0.9232\n",
      "Epoch 13/64\n",
      "1198/1198 [==============================] - 0s 238us/step - loss: 0.2048 - acc: 0.9232\n",
      "Epoch 14/64\n",
      "1198/1198 [==============================] - 0s 222us/step - loss: 0.2023 - acc: 0.9240\n",
      "Epoch 15/64\n",
      "1198/1198 [==============================] - 0s 236us/step - loss: 0.1992 - acc: 0.9257\n",
      "Epoch 16/64\n",
      "1198/1198 [==============================] - 0s 237us/step - loss: 0.1978 - acc: 0.9265\n",
      "Epoch 17/64\n",
      "1198/1198 [==============================] - 0s 221us/step - loss: 0.1954 - acc: 0.9265\n",
      "Epoch 18/64\n",
      "1198/1198 [==============================] - 0s 245us/step - loss: 0.1927 - acc: 0.9265\n",
      "Epoch 19/64\n",
      "1198/1198 [==============================] - 0s 252us/step - loss: 0.1907 - acc: 0.9265\n",
      "Epoch 20/64\n",
      "1198/1198 [==============================] - 0s 250us/step - loss: 0.1896 - acc: 0.9265\n",
      "Epoch 21/64\n",
      "1198/1198 [==============================] - 0s 248us/step - loss: 0.1873 - acc: 0.9265\n",
      "Epoch 22/64\n",
      "1198/1198 [==============================] - 0s 236us/step - loss: 0.1863 - acc: 0.9307\n",
      "Epoch 23/64\n",
      "1198/1198 [==============================] - 0s 235us/step - loss: 0.1838 - acc: 0.9324\n",
      "Epoch 24/64\n",
      "1198/1198 [==============================] - 0s 249us/step - loss: 0.1839 - acc: 0.9282\n",
      "Epoch 25/64\n",
      "1198/1198 [==============================] - 0s 235us/step - loss: 0.1813 - acc: 0.9316\n",
      "Epoch 26/64\n",
      "1198/1198 [==============================] - 0s 237us/step - loss: 0.1797 - acc: 0.9324\n",
      "Epoch 27/64\n",
      "1198/1198 [==============================] - 0s 244us/step - loss: 0.1779 - acc: 0.9316\n",
      "Epoch 28/64\n",
      "1198/1198 [==============================] - 0s 239us/step - loss: 0.1769 - acc: 0.9332\n",
      "Epoch 29/64\n",
      "1198/1198 [==============================] - 0s 233us/step - loss: 0.1755 - acc: 0.9349\n",
      "Epoch 30/64\n",
      "1198/1198 [==============================] - 0s 251us/step - loss: 0.1742 - acc: 0.9341\n",
      "Epoch 31/64\n",
      "1198/1198 [==============================] - 0s 262us/step - loss: 0.1737 - acc: 0.9366\n",
      "Epoch 32/64\n",
      "1198/1198 [==============================] - 0s 222us/step - loss: 0.1728 - acc: 0.9341\n",
      "Epoch 33/64\n",
      "1198/1198 [==============================] - 0s 249us/step - loss: 0.1714 - acc: 0.9349\n",
      "Epoch 34/64\n",
      "1198/1198 [==============================] - 0s 235us/step - loss: 0.1698 - acc: 0.9382\n",
      "Epoch 35/64\n",
      "1198/1198 [==============================] - 0s 237us/step - loss: 0.1688 - acc: 0.9374\n",
      "Epoch 36/64\n",
      "1198/1198 [==============================] - 0s 266us/step - loss: 0.1687 - acc: 0.9357\n",
      "Epoch 37/64\n",
      "1198/1198 [==============================] - 0s 256us/step - loss: 0.1674 - acc: 0.9366\n",
      "Epoch 38/64\n",
      "1198/1198 [==============================] - 0s 269us/step - loss: 0.1660 - acc: 0.9407\n",
      "Epoch 39/64\n",
      "1198/1198 [==============================] - 0s 254us/step - loss: 0.1651 - acc: 0.9382\n",
      "Epoch 40/64\n",
      "1198/1198 [==============================] - 0s 250us/step - loss: 0.1648 - acc: 0.9407\n",
      "Epoch 41/64\n",
      "1198/1198 [==============================] - 0s 274us/step - loss: 0.1633 - acc: 0.9407\n",
      "Epoch 42/64\n",
      "1198/1198 [==============================] - 0s 249us/step - loss: 0.1634 - acc: 0.9416\n",
      "Epoch 43/64\n",
      "1198/1198 [==============================] - 0s 232us/step - loss: 0.1617 - acc: 0.9432\n",
      "Epoch 44/64\n",
      "1198/1198 [==============================] - 0s 239us/step - loss: 0.1607 - acc: 0.9449\n",
      "Epoch 45/64\n",
      "1198/1198 [==============================] - 0s 254us/step - loss: 0.1605 - acc: 0.9424\n",
      "Epoch 46/64\n",
      "1198/1198 [==============================] - 0s 229us/step - loss: 0.1594 - acc: 0.9441\n",
      "Epoch 47/64\n",
      "1198/1198 [==============================] - 0s 236us/step - loss: 0.1585 - acc: 0.9474\n",
      "Epoch 48/64\n",
      "1198/1198 [==============================] - 0s 235us/step - loss: 0.1584 - acc: 0.9416\n",
      "Epoch 49/64\n",
      "1198/1198 [==============================] - 0s 275us/step - loss: 0.1573 - acc: 0.9474\n",
      "Epoch 50/64\n",
      "1198/1198 [==============================] - 0s 248us/step - loss: 0.1556 - acc: 0.9457\n",
      "Epoch 51/64\n",
      "1198/1198 [==============================] - 0s 236us/step - loss: 0.1554 - acc: 0.9474\n",
      "Epoch 52/64\n",
      "1198/1198 [==============================] - 0s 245us/step - loss: 0.1544 - acc: 0.9474\n",
      "Epoch 53/64\n",
      "1198/1198 [==============================] - 0s 240us/step - loss: 0.1533 - acc: 0.9482\n",
      "Epoch 54/64\n",
      "1198/1198 [==============================] - 0s 231us/step - loss: 0.1537 - acc: 0.9457\n",
      "Epoch 55/64\n",
      "1198/1198 [==============================] - 0s 252us/step - loss: 0.1524 - acc: 0.9482\n",
      "Epoch 56/64\n",
      "1198/1198 [==============================] - 0s 236us/step - loss: 0.1514 - acc: 0.9474\n",
      "Epoch 57/64\n",
      "1198/1198 [==============================] - 0s 235us/step - loss: 0.1510 - acc: 0.9499\n",
      "Epoch 58/64\n",
      "1198/1198 [==============================] - 0s 236us/step - loss: 0.1497 - acc: 0.9491\n",
      "Epoch 59/64\n",
      "1198/1198 [==============================] - 0s 248us/step - loss: 0.1499 - acc: 0.9516\n",
      "Epoch 60/64\n",
      "1198/1198 [==============================] - 0s 238us/step - loss: 0.1489 - acc: 0.9508\n",
      "Epoch 61/64\n",
      "1198/1198 [==============================] - 0s 235us/step - loss: 0.1463 - acc: 0.9499\n",
      "Epoch 62/64\n",
      "1198/1198 [==============================] - 0s 275us/step - loss: 0.1483 - acc: 0.9508\n",
      "Epoch 63/64\n",
      "1198/1198 [==============================] - 0s 245us/step - loss: 0.1465 - acc: 0.9508\n",
      "Epoch 64/64\n",
      "1198/1198 [==============================] - 0s 238us/step - loss: 0.1461 - acc: 0.9516\n",
      "299/299 [==============================] - 0s 418us/step\n",
      "[0.91       0.88333333 0.90301003 0.92976589 0.89632107]\n",
      "0.9044860653366932\n"
     ]
    }
   ],
   "source": [
    "# Evaluate neural network using 5-fold cross-validation before optimization\n",
    "score=cross_val_score(neural_network, X_train, y_train, cv=5)\n",
    "print(score)\n",
    "print(score.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "499/499 [==============================] - 0s 94us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8777555110220441"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Test Accuracy before optimization\n",
    "test_accuracy = neural_network.score(X_test, y_test)\n",
    "test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/32\n",
      "1197/1197 [==============================] - 1s 852us/step - loss: 0.5656 - acc: 0.8012\n",
      "Epoch 2/32\n",
      "1197/1197 [==============================] - 1s 498us/step - loss: 0.2777 - acc: 0.8906\n",
      "Epoch 3/32\n",
      "1197/1197 [==============================] - 1s 497us/step - loss: 0.2297 - acc: 0.9023\n",
      "Epoch 4/32\n",
      "1197/1197 [==============================] - 1s 524us/step - loss: 0.2150 - acc: 0.9098\n",
      "Epoch 5/32\n",
      "1197/1197 [==============================] - 1s 522us/step - loss: 0.2072 - acc: 0.9114\n",
      "Epoch 6/32\n",
      "1197/1197 [==============================] - 1s 515us/step - loss: 0.2006 - acc: 0.9140\n",
      "Epoch 7/32\n",
      "1197/1197 [==============================] - 1s 562us/step - loss: 0.1951 - acc: 0.9206\n",
      "Epoch 8/32\n",
      "1197/1197 [==============================] - 1s 498us/step - loss: 0.1889 - acc: 0.9198\n",
      "Epoch 9/32\n",
      "1197/1197 [==============================] - 1s 497us/step - loss: 0.1835 - acc: 0.9290\n",
      "Epoch 10/32\n",
      "1197/1197 [==============================] - 1s 498us/step - loss: 0.1801 - acc: 0.9265\n",
      "Epoch 11/32\n",
      "1197/1197 [==============================] - 1s 507us/step - loss: 0.1759 - acc: 0.9282\n",
      "Epoch 12/32\n",
      "1197/1197 [==============================] - 1s 489us/step - loss: 0.1722 - acc: 0.9315\n",
      "Epoch 13/32\n",
      "1197/1197 [==============================] - 1s 498us/step - loss: 0.1696 - acc: 0.9323\n",
      "Epoch 14/32\n",
      "1197/1197 [==============================] - 1s 485us/step - loss: 0.1668 - acc: 0.9340\n",
      "Epoch 15/32\n",
      "1197/1197 [==============================] - 1s 538us/step - loss: 0.1629 - acc: 0.9348\n",
      "Epoch 16/32\n",
      "1197/1197 [==============================] - 1s 561us/step - loss: 0.1618 - acc: 0.9348\n",
      "Epoch 17/32\n",
      "1197/1197 [==============================] - 1s 566us/step - loss: 0.1570 - acc: 0.9365\n",
      "Epoch 18/32\n",
      "1197/1197 [==============================] - 1s 510us/step - loss: 0.1552 - acc: 0.9365\n",
      "Epoch 19/32\n",
      "1197/1197 [==============================] - 1s 497us/step - loss: 0.1527 - acc: 0.9424\n",
      "Epoch 20/32\n",
      "1197/1197 [==============================] - 1s 497us/step - loss: 0.1511 - acc: 0.9432\n",
      "Epoch 21/32\n",
      "1197/1197 [==============================] - 1s 498us/step - loss: 0.1469 - acc: 0.9474\n",
      "Epoch 22/32\n",
      "1197/1197 [==============================] - 1s 511us/step - loss: 0.1459 - acc: 0.9415\n",
      "Epoch 23/32\n",
      "1197/1197 [==============================] - 1s 508us/step - loss: 0.1447 - acc: 0.9432\n",
      "Epoch 24/32\n",
      "1197/1197 [==============================] - 1s 502us/step - loss: 0.1407 - acc: 0.9474\n",
      "Epoch 25/32\n",
      "1197/1197 [==============================] - 1s 497us/step - loss: 0.1386 - acc: 0.9507\n",
      "Epoch 26/32\n",
      "1197/1197 [==============================] - 1s 497us/step - loss: 0.1363 - acc: 0.9507\n",
      "Epoch 27/32\n",
      "1197/1197 [==============================] - 1s 498us/step - loss: 0.1345 - acc: 0.9574\n",
      "Epoch 28/32\n",
      "1197/1197 [==============================] - 1s 498us/step - loss: 0.1300 - acc: 0.9499\n",
      "Epoch 29/32\n",
      "1197/1197 [==============================] - 1s 510us/step - loss: 0.1301 - acc: 0.9557\n",
      "Epoch 30/32\n",
      "1197/1197 [==============================] - 1s 517us/step - loss: 0.1257 - acc: 0.9532\n",
      "Epoch 31/32\n",
      "1197/1197 [==============================] - 1s 500us/step - loss: 0.1240 - acc: 0.9632\n",
      "Epoch 32/32\n",
      "1197/1197 [==============================] - 1s 501us/step - loss: 0.1203 - acc: 0.9549\n",
      "300/300 [==============================] - 0s 521us/step\n",
      "Epoch 1/32\n",
      "1197/1197 [==============================] - 1s 892us/step - loss: 0.5353 - acc: 0.8505\n",
      "Epoch 2/32\n",
      "1197/1197 [==============================] - 1s 498us/step - loss: 0.2621 - acc: 0.9064\n",
      "Epoch 3/32\n",
      "1197/1197 [==============================] - 1s 497us/step - loss: 0.2222 - acc: 0.9148\n",
      "Epoch 4/32\n",
      "1197/1197 [==============================] - 1s 497us/step - loss: 0.2095 - acc: 0.9123\n",
      "Epoch 5/32\n",
      "1197/1197 [==============================] - 1s 535us/step - loss: 0.2050 - acc: 0.9181\n",
      "Epoch 6/32\n",
      "1197/1197 [==============================] - 1s 498us/step - loss: 0.2011 - acc: 0.9198\n",
      "Epoch 7/32\n",
      "1197/1197 [==============================] - 1s 500us/step - loss: 0.1943 - acc: 0.9223\n",
      "Epoch 8/32\n",
      "1197/1197 [==============================] - 1s 497us/step - loss: 0.1889 - acc: 0.9265\n",
      "Epoch 9/32\n",
      "1197/1197 [==============================] - 1s 485us/step - loss: 0.1862 - acc: 0.9223\n",
      "Epoch 10/32\n",
      "1197/1197 [==============================] - 1s 498us/step - loss: 0.1826 - acc: 0.9248\n",
      "Epoch 11/32\n",
      "1197/1197 [==============================] - 1s 498us/step - loss: 0.1799 - acc: 0.9298\n",
      "Epoch 12/32\n",
      "1197/1197 [==============================] - 1s 511us/step - loss: 0.1760 - acc: 0.9348\n",
      "Epoch 13/32\n",
      "1197/1197 [==============================] - 1s 527us/step - loss: 0.1742 - acc: 0.9315\n",
      "Epoch 14/32\n",
      "1197/1197 [==============================] - 1s 508us/step - loss: 0.1705 - acc: 0.9332\n",
      "Epoch 15/32\n",
      "1197/1197 [==============================] - 1s 498us/step - loss: 0.1702 - acc: 0.9298\n",
      "Epoch 16/32\n",
      "1197/1197 [==============================] - 1s 511us/step - loss: 0.1672 - acc: 0.9398\n",
      "Epoch 17/32\n",
      "1197/1197 [==============================] - 1s 510us/step - loss: 0.1633 - acc: 0.9357\n",
      "Epoch 18/32\n",
      "1197/1197 [==============================] - 1s 511us/step - loss: 0.1613 - acc: 0.9382\n",
      "Epoch 19/32\n",
      "1197/1197 [==============================] - 1s 519us/step - loss: 0.1582 - acc: 0.9432\n",
      "Epoch 20/32\n",
      "1197/1197 [==============================] - 1s 517us/step - loss: 0.1570 - acc: 0.9440\n",
      "Epoch 21/32\n",
      "1197/1197 [==============================] - 1s 523us/step - loss: 0.1565 - acc: 0.9398\n",
      "Epoch 22/32\n",
      "1197/1197 [==============================] - 1s 498us/step - loss: 0.1547 - acc: 0.9424\n",
      "Epoch 23/32\n",
      "1197/1197 [==============================] - 1s 511us/step - loss: 0.1505 - acc: 0.9424\n",
      "Epoch 24/32\n",
      "1197/1197 [==============================] - 1s 569us/step - loss: 0.1505 - acc: 0.9415\n",
      "Epoch 25/32\n",
      "1197/1197 [==============================] - 1s 510us/step - loss: 0.1482 - acc: 0.9457\n",
      "Epoch 26/32\n",
      "1197/1197 [==============================] - 1s 506us/step - loss: 0.1455 - acc: 0.9440\n",
      "Epoch 27/32\n",
      "1197/1197 [==============================] - 1s 523us/step - loss: 0.1451 - acc: 0.9515\n",
      "Epoch 28/32\n",
      "1197/1197 [==============================] - 1s 497us/step - loss: 0.1445 - acc: 0.9482\n",
      "Epoch 29/32\n",
      "1197/1197 [==============================] - 1s 511us/step - loss: 0.1418 - acc: 0.9507\n",
      "Epoch 30/32\n",
      "1197/1197 [==============================] - 1s 497us/step - loss: 0.1402 - acc: 0.9474\n",
      "Epoch 31/32\n",
      "1197/1197 [==============================] - 1s 508us/step - loss: 0.1363 - acc: 0.9524\n",
      "Epoch 32/32\n",
      "1197/1197 [==============================] - 1s 515us/step - loss: 0.1382 - acc: 0.9524\n",
      "300/300 [==============================] - 0s 625us/step\n",
      "Epoch 1/32\n",
      "1198/1198 [==============================] - 1s 969us/step - loss: 0.5406 - acc: 0.8088\n",
      "Epoch 2/32\n",
      "1198/1198 [==============================] - 1s 535us/step - loss: 0.2751 - acc: 0.9040\n",
      "Epoch 3/32\n",
      "1198/1198 [==============================] - 1s 510us/step - loss: 0.2207 - acc: 0.9115\n",
      "Epoch 4/32\n",
      "1198/1198 [==============================] - 1s 534us/step - loss: 0.2048 - acc: 0.9174\n",
      "Epoch 5/32\n",
      "1198/1198 [==============================] - 1s 513us/step - loss: 0.1945 - acc: 0.9232\n",
      "Epoch 6/32\n",
      "1198/1198 [==============================] - 1s 525us/step - loss: 0.1883 - acc: 0.9282\n",
      "Epoch 7/32\n",
      "1198/1198 [==============================] - 1s 509us/step - loss: 0.1844 - acc: 0.9274\n",
      "Epoch 8/32\n",
      "1198/1198 [==============================] - 1s 523us/step - loss: 0.1819 - acc: 0.9290\n",
      "Epoch 9/32\n",
      "1198/1198 [==============================] - 1s 536us/step - loss: 0.1768 - acc: 0.9324\n",
      "Epoch 10/32\n",
      "1198/1198 [==============================] - 1s 521us/step - loss: 0.1773 - acc: 0.9307\n",
      "Epoch 11/32\n",
      "1198/1198 [==============================] - 1s 515us/step - loss: 0.1734 - acc: 0.9382\n",
      "Epoch 12/32\n",
      "1198/1198 [==============================] - 1s 522us/step - loss: 0.1702 - acc: 0.9366\n",
      "Epoch 13/32\n",
      "1198/1198 [==============================] - 1s 536us/step - loss: 0.1691 - acc: 0.9399\n",
      "Epoch 14/32\n",
      "1198/1198 [==============================] - 1s 522us/step - loss: 0.1683 - acc: 0.9424\n",
      "Epoch 15/32\n",
      "1198/1198 [==============================] - 1s 529us/step - loss: 0.1670 - acc: 0.9391\n",
      "Epoch 16/32\n",
      "1198/1198 [==============================] - 1s 511us/step - loss: 0.1645 - acc: 0.9432\n",
      "Epoch 17/32\n",
      "1198/1198 [==============================] - 1s 503us/step - loss: 0.1630 - acc: 0.9491\n",
      "Epoch 18/32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1198/1198 [==============================] - 1s 522us/step - loss: 0.1605 - acc: 0.9482\n",
      "Epoch 19/32\n",
      "1198/1198 [==============================] - 1s 510us/step - loss: 0.1578 - acc: 0.9466\n",
      "Epoch 20/32\n",
      "1198/1198 [==============================] - 1s 510us/step - loss: 0.1582 - acc: 0.9474\n",
      "Epoch 21/32\n",
      "1198/1198 [==============================] - 1s 512us/step - loss: 0.1566 - acc: 0.9482\n",
      "Epoch 22/32\n",
      "1198/1198 [==============================] - 1s 512us/step - loss: 0.1546 - acc: 0.9466\n",
      "Epoch 23/32\n",
      "1198/1198 [==============================] - 1s 507us/step - loss: 0.1534 - acc: 0.9466\n",
      "Epoch 24/32\n",
      "1198/1198 [==============================] - 1s 511us/step - loss: 0.1514 - acc: 0.9482\n",
      "Epoch 25/32\n",
      "1198/1198 [==============================] - 1s 523us/step - loss: 0.1494 - acc: 0.9474\n",
      "Epoch 26/32\n",
      "1198/1198 [==============================] - 1s 524us/step - loss: 0.1482 - acc: 0.9491\n",
      "Epoch 27/32\n",
      "1198/1198 [==============================] - 1s 525us/step - loss: 0.1459 - acc: 0.9449\n",
      "Epoch 28/32\n",
      "1198/1198 [==============================] - 1s 533us/step - loss: 0.1436 - acc: 0.9482\n",
      "Epoch 29/32\n",
      "1198/1198 [==============================] - 1s 525us/step - loss: 0.1430 - acc: 0.9499\n",
      "Epoch 30/32\n",
      "1198/1198 [==============================] - 1s 521us/step - loss: 0.1398 - acc: 0.9499\n",
      "Epoch 31/32\n",
      "1198/1198 [==============================] - 1s 524us/step - loss: 0.1379 - acc: 0.9516\n",
      "Epoch 32/32\n",
      "1198/1198 [==============================] - 1s 624us/step - loss: 0.1362 - acc: 0.9491\n",
      "299/299 [==============================] - 0s 635us/step\n",
      "Epoch 1/32\n",
      "1198/1198 [==============================] - 1s 941us/step - loss: 0.5413 - acc: 0.8381\n",
      "Epoch 2/32\n",
      "1198/1198 [==============================] - 1s 510us/step - loss: 0.2831 - acc: 0.8915\n",
      "Epoch 3/32\n",
      "1198/1198 [==============================] - 1s 524us/step - loss: 0.2386 - acc: 0.8990\n",
      "Epoch 4/32\n",
      "1198/1198 [==============================] - 1s 523us/step - loss: 0.2212 - acc: 0.9132\n",
      "Epoch 5/32\n",
      "1198/1198 [==============================] - 1s 534us/step - loss: 0.2088 - acc: 0.9165\n",
      "Epoch 6/32\n",
      "1198/1198 [==============================] - 1s 540us/step - loss: 0.2043 - acc: 0.9165\n",
      "Epoch 7/32\n",
      "1198/1198 [==============================] - 1s 588us/step - loss: 0.1981 - acc: 0.9224\n",
      "Epoch 8/32\n",
      "1198/1198 [==============================] - 1s 537us/step - loss: 0.1911 - acc: 0.9282\n",
      "Epoch 9/32\n",
      "1198/1198 [==============================] - 1s 547us/step - loss: 0.1895 - acc: 0.9299\n",
      "Epoch 10/32\n",
      "1198/1198 [==============================] - 1s 540us/step - loss: 0.1836 - acc: 0.9257\n",
      "Epoch 11/32\n",
      "1198/1198 [==============================] - 1s 524us/step - loss: 0.1801 - acc: 0.9357\n",
      "Epoch 12/32\n",
      "1198/1198 [==============================] - 1s 536us/step - loss: 0.1771 - acc: 0.9332\n",
      "Epoch 13/32\n",
      "1198/1198 [==============================] - 1s 549us/step - loss: 0.1773 - acc: 0.9341\n",
      "Epoch 14/32\n",
      "1198/1198 [==============================] - 1s 564us/step - loss: 0.1736 - acc: 0.9324\n",
      "Epoch 15/32\n",
      "1198/1198 [==============================] - 1s 536us/step - loss: 0.1695 - acc: 0.9399\n",
      "Epoch 16/32\n",
      "1198/1198 [==============================] - 1s 549us/step - loss: 0.1642 - acc: 0.9449\n",
      "Epoch 17/32\n",
      "1198/1198 [==============================] - 1s 538us/step - loss: 0.1652 - acc: 0.9391\n",
      "Epoch 18/32\n",
      "1198/1198 [==============================] - 1s 520us/step - loss: 0.1630 - acc: 0.9432\n",
      "Epoch 19/32\n",
      "1198/1198 [==============================] - 1s 527us/step - loss: 0.1589 - acc: 0.9424\n",
      "Epoch 20/32\n",
      "1198/1198 [==============================] - 1s 549us/step - loss: 0.1575 - acc: 0.9449\n",
      "Epoch 21/32\n",
      "1198/1198 [==============================] - 1s 525us/step - loss: 0.1562 - acc: 0.9424\n",
      "Epoch 22/32\n",
      "1198/1198 [==============================] - 1s 560us/step - loss: 0.1545 - acc: 0.9416\n",
      "Epoch 23/32\n",
      "1198/1198 [==============================] - 1s 552us/step - loss: 0.1533 - acc: 0.9407\n",
      "Epoch 24/32\n",
      "1198/1198 [==============================] - 1s 523us/step - loss: 0.1530 - acc: 0.9416\n",
      "Epoch 25/32\n",
      "1198/1198 [==============================] - 1s 536us/step - loss: 0.1475 - acc: 0.9432\n",
      "Epoch 26/32\n",
      "1198/1198 [==============================] - 1s 535us/step - loss: 0.1482 - acc: 0.9424\n",
      "Epoch 27/32\n",
      "1198/1198 [==============================] - 1s 583us/step - loss: 0.1479 - acc: 0.9432\n",
      "Epoch 28/32\n",
      "1198/1198 [==============================] - 1s 542us/step - loss: 0.1410 - acc: 0.9491\n",
      "Epoch 29/32\n",
      "1198/1198 [==============================] - 1s 523us/step - loss: 0.1411 - acc: 0.9508\n",
      "Epoch 30/32\n",
      "1198/1198 [==============================] - 1s 536us/step - loss: 0.1410 - acc: 0.9482\n",
      "Epoch 31/32\n",
      "1198/1198 [==============================] - 1s 537us/step - loss: 0.1373 - acc: 0.9533\n",
      "Epoch 32/32\n",
      "1198/1198 [==============================] - 1s 523us/step - loss: 0.1350 - acc: 0.9516\n",
      "299/299 [==============================] - 0s 784us/step\n",
      "Epoch 1/32\n",
      "1198/1198 [==============================] - 1s 1ms/step - loss: 0.5624 - acc: 0.8080\n",
      "Epoch 2/32\n",
      "1198/1198 [==============================] - 1s 541us/step - loss: 0.2932 - acc: 0.8990\n",
      "Epoch 3/32\n",
      "1198/1198 [==============================] - 1s 530us/step - loss: 0.2336 - acc: 0.9098\n",
      "Epoch 4/32\n",
      "1198/1198 [==============================] - 1s 523us/step - loss: 0.2195 - acc: 0.9140\n",
      "Epoch 5/32\n",
      "1198/1198 [==============================] - 1s 537us/step - loss: 0.2138 - acc: 0.9174\n",
      "Epoch 6/32\n",
      "1198/1198 [==============================] - 1s 549us/step - loss: 0.2096 - acc: 0.9182\n",
      "Epoch 7/32\n",
      "1198/1198 [==============================] - 1s 533us/step - loss: 0.2058 - acc: 0.9182\n",
      "Epoch 8/32\n",
      "1198/1198 [==============================] - 1s 553us/step - loss: 0.2025 - acc: 0.9240\n",
      "Epoch 9/32\n",
      "1198/1198 [==============================] - 1s 577us/step - loss: 0.1993 - acc: 0.9215\n",
      "Epoch 10/32\n",
      "1198/1198 [==============================] - 1s 613us/step - loss: 0.1972 - acc: 0.9240\n",
      "Epoch 11/32\n",
      "1198/1198 [==============================] - 1s 537us/step - loss: 0.1939 - acc: 0.9274\n",
      "Epoch 12/32\n",
      "1198/1198 [==============================] - 1s 549us/step - loss: 0.1906 - acc: 0.9282\n",
      "Epoch 13/32\n",
      "1198/1198 [==============================] - 1s 538us/step - loss: 0.1888 - acc: 0.9290\n",
      "Epoch 14/32\n",
      "1198/1198 [==============================] - 1s 561us/step - loss: 0.1869 - acc: 0.9307\n",
      "Epoch 15/32\n",
      "1198/1198 [==============================] - 1s 551us/step - loss: 0.1852 - acc: 0.9349\n",
      "Epoch 16/32\n",
      "1198/1198 [==============================] - 1s 536us/step - loss: 0.1810 - acc: 0.9290\n",
      "Epoch 17/32\n",
      "1198/1198 [==============================] - 1s 523us/step - loss: 0.1805 - acc: 0.9349\n",
      "Epoch 18/32\n",
      "1198/1198 [==============================] - 1s 523us/step - loss: 0.1786 - acc: 0.9332\n",
      "Epoch 19/32\n",
      "1198/1198 [==============================] - 1s 534us/step - loss: 0.1756 - acc: 0.9366\n",
      "Epoch 20/32\n",
      "1198/1198 [==============================] - 1s 606us/step - loss: 0.1740 - acc: 0.9374\n",
      "Epoch 21/32\n",
      "1198/1198 [==============================] - 1s 562us/step - loss: 0.1727 - acc: 0.9357\n",
      "Epoch 22/32\n",
      "1198/1198 [==============================] - 1s 536us/step - loss: 0.1707 - acc: 0.9374\n",
      "Epoch 23/32\n",
      "1198/1198 [==============================] - 1s 547us/step - loss: 0.1679 - acc: 0.9374\n",
      "Epoch 24/32\n",
      "1198/1198 [==============================] - 1s 527us/step - loss: 0.1672 - acc: 0.9407\n",
      "Epoch 25/32\n",
      "1198/1198 [==============================] - 1s 588us/step - loss: 0.1656 - acc: 0.9391\n",
      "Epoch 26/32\n",
      "1198/1198 [==============================] - 1s 589us/step - loss: 0.1644 - acc: 0.9416\n",
      "Epoch 27/32\n",
      "1198/1198 [==============================] - 1s 564us/step - loss: 0.1628 - acc: 0.9424\n",
      "Epoch 28/32\n",
      "1198/1198 [==============================] - 1s 588us/step - loss: 0.1597 - acc: 0.9424\n",
      "Epoch 29/32\n",
      "1198/1198 [==============================] - 1s 562us/step - loss: 0.1577 - acc: 0.9391\n",
      "Epoch 30/32\n",
      "1198/1198 [==============================] - 1s 522us/step - loss: 0.1548 - acc: 0.9432\n",
      "Epoch 31/32\n",
      "1198/1198 [==============================] - 1s 541us/step - loss: 0.1557 - acc: 0.9424\n",
      "Epoch 32/32\n",
      "1198/1198 [==============================] - 1s 548us/step - loss: 0.1527 - acc: 0.9482\n",
      "299/299 [==============================] - 0s 762us/step\n",
      "Epoch 1/32\n",
      "1197/1197 [==============================] - 1s 944us/step - loss: 0.5335 - acc: 0.8605\n",
      "Epoch 2/32\n",
      "1197/1197 [==============================] - 1s 498us/step - loss: 0.3230 - acc: 0.8947\n",
      "Epoch 3/32\n",
      "1197/1197 [==============================] - 1s 510us/step - loss: 0.2569 - acc: 0.8997\n",
      "Epoch 4/32\n",
      "1197/1197 [==============================] - 1s 483us/step - loss: 0.2356 - acc: 0.9031\n",
      "Epoch 5/32\n",
      "1197/1197 [==============================] - 1s 506us/step - loss: 0.2248 - acc: 0.9089\n",
      "Epoch 6/32\n",
      "1197/1197 [==============================] - 1s 507us/step - loss: 0.2191 - acc: 0.9098\n",
      "Epoch 7/32\n",
      "1197/1197 [==============================] - 1s 497us/step - loss: 0.2138 - acc: 0.9114\n",
      "Epoch 8/32\n",
      "1197/1197 [==============================] - 1s 497us/step - loss: 0.2087 - acc: 0.9106\n",
      "Epoch 9/32\n",
      "1197/1197 [==============================] - 1s 498us/step - loss: 0.2054 - acc: 0.9140\n",
      "Epoch 10/32\n",
      "1197/1197 [==============================] - 1s 484us/step - loss: 0.2016 - acc: 0.9140\n",
      "Epoch 11/32\n",
      "1197/1197 [==============================] - 1s 498us/step - loss: 0.1987 - acc: 0.9173\n",
      "Epoch 12/32\n",
      "1197/1197 [==============================] - 1s 525us/step - loss: 0.1983 - acc: 0.9165\n",
      "Epoch 13/32\n",
      "1197/1197 [==============================] - 1s 497us/step - loss: 0.1936 - acc: 0.9231\n",
      "Epoch 14/32\n",
      "1197/1197 [==============================] - 1s 498us/step - loss: 0.1914 - acc: 0.9181\n",
      "Epoch 15/32\n",
      "1197/1197 [==============================] - 1s 498us/step - loss: 0.1891 - acc: 0.9248\n",
      "Epoch 16/32\n",
      "1197/1197 [==============================] - 1s 498us/step - loss: 0.1858 - acc: 0.9256\n",
      "Epoch 17/32\n",
      "1197/1197 [==============================] - 1s 484us/step - loss: 0.1848 - acc: 0.9231\n",
      "Epoch 18/32\n",
      "1197/1197 [==============================] - 1s 511us/step - loss: 0.1822 - acc: 0.9307\n",
      "Epoch 19/32\n",
      "1197/1197 [==============================] - 1s 495us/step - loss: 0.1809 - acc: 0.9290\n",
      "Epoch 20/32\n",
      "1197/1197 [==============================] - 1s 506us/step - loss: 0.1791 - acc: 0.9315\n",
      "Epoch 21/32\n",
      "1197/1197 [==============================] - 1s 570us/step - loss: 0.1780 - acc: 0.9290\n",
      "Epoch 22/32\n",
      "1197/1197 [==============================] - 1s 511us/step - loss: 0.1747 - acc: 0.9307\n",
      "Epoch 23/32\n",
      "1197/1197 [==============================] - 1s 511us/step - loss: 0.1745 - acc: 0.9323\n",
      "Epoch 24/32\n",
      "1197/1197 [==============================] - 1s 524us/step - loss: 0.1723 - acc: 0.9332\n",
      "Epoch 25/32\n",
      "1197/1197 [==============================] - 1s 495us/step - loss: 0.1737 - acc: 0.9332\n",
      "Epoch 26/32\n",
      "1197/1197 [==============================] - 1s 515us/step - loss: 0.1706 - acc: 0.9332\n",
      "Epoch 27/32\n",
      "1197/1197 [==============================] - 1s 485us/step - loss: 0.1692 - acc: 0.9365\n",
      "Epoch 28/32\n",
      "1197/1197 [==============================] - 1s 498us/step - loss: 0.1676 - acc: 0.9373\n",
      "Epoch 29/32\n",
      "1197/1197 [==============================] - 1s 510us/step - loss: 0.1645 - acc: 0.9365\n",
      "Epoch 30/32\n",
      "1197/1197 [==============================] - 1s 497us/step - loss: 0.1658 - acc: 0.9398\n",
      "Epoch 31/32\n",
      "1197/1197 [==============================] - 1s 498us/step - loss: 0.1631 - acc: 0.9382\n",
      "Epoch 32/32\n",
      "1197/1197 [==============================] - 1s 495us/step - loss: 0.1640 - acc: 0.9390\n",
      "300/300 [==============================] - 0s 851us/step\n",
      "Epoch 1/32\n",
      "1197/1197 [==============================] - 1s 1ms/step - loss: 0.5300 - acc: 0.8237\n",
      "Epoch 2/32\n",
      "1197/1197 [==============================] - 1s 499us/step - loss: 0.3029 - acc: 0.9039\n",
      "Epoch 3/32\n",
      "1197/1197 [==============================] - 1s 601us/step - loss: 0.2280 - acc: 0.9073\n",
      "Epoch 4/32\n",
      "1197/1197 [==============================] - 1s 534us/step - loss: 0.2128 - acc: 0.9156\n",
      "Epoch 5/32\n",
      "1197/1197 [==============================] - 1s 515us/step - loss: 0.2105 - acc: 0.9156\n",
      "Epoch 6/32\n",
      "1197/1197 [==============================] - 1s 524us/step - loss: 0.2073 - acc: 0.9181\n",
      "Epoch 7/32\n",
      "1197/1197 [==============================] - 1s 512us/step - loss: 0.2048 - acc: 0.9223\n",
      "Epoch 8/32\n",
      "1197/1197 [==============================] - 1s 523us/step - loss: 0.2026 - acc: 0.9198\n",
      "Epoch 9/32\n",
      "1197/1197 [==============================] - 1s 510us/step - loss: 0.2011 - acc: 0.9198\n",
      "Epoch 10/32\n",
      "1197/1197 [==============================] - 1s 509us/step - loss: 0.1974 - acc: 0.9231\n",
      "Epoch 11/32\n",
      "1197/1197 [==============================] - 1s 516us/step - loss: 0.1971 - acc: 0.9215\n",
      "Epoch 12/32\n",
      "1197/1197 [==============================] - 1s 523us/step - loss: 0.1958 - acc: 0.9206\n",
      "Epoch 13/32\n",
      "1197/1197 [==============================] - 1s 497us/step - loss: 0.1929 - acc: 0.9256\n",
      "Epoch 14/32\n",
      "1197/1197 [==============================] - 1s 511us/step - loss: 0.1917 - acc: 0.9231\n",
      "Epoch 15/32\n",
      "1197/1197 [==============================] - 1s 534us/step - loss: 0.1899 - acc: 0.9273\n",
      "Epoch 16/32\n",
      "1197/1197 [==============================] - 1s 525us/step - loss: 0.1888 - acc: 0.9290\n",
      "Epoch 17/32\n",
      "1197/1197 [==============================] - 1s 525us/step - loss: 0.1850 - acc: 0.9340\n",
      "Epoch 18/32\n",
      "1197/1197 [==============================] - 1s 511us/step - loss: 0.1835 - acc: 0.9315\n",
      "Epoch 19/32\n",
      "1197/1197 [==============================] - 1s 511us/step - loss: 0.1822 - acc: 0.9273\n",
      "Epoch 20/32\n",
      "1197/1197 [==============================] - 1s 499us/step - loss: 0.1796 - acc: 0.9315\n",
      "Epoch 21/32\n",
      "1197/1197 [==============================] - 1s 520us/step - loss: 0.1778 - acc: 0.9290\n",
      "Epoch 22/32\n",
      "1197/1197 [==============================] - 1s 527us/step - loss: 0.1758 - acc: 0.9390\n",
      "Epoch 23/32\n",
      "1197/1197 [==============================] - 1s 524us/step - loss: 0.1746 - acc: 0.9298\n",
      "Epoch 24/32\n",
      "1197/1197 [==============================] - 1s 524us/step - loss: 0.1721 - acc: 0.9348\n",
      "Epoch 25/32\n",
      "1197/1197 [==============================] - 1s 511us/step - loss: 0.1682 - acc: 0.9340\n",
      "Epoch 26/32\n",
      "1197/1197 [==============================] - 1s 498us/step - loss: 0.1679 - acc: 0.9332\n",
      "Epoch 27/32\n",
      "1197/1197 [==============================] - 1s 500us/step - loss: 0.1676 - acc: 0.9323\n",
      "Epoch 28/32\n",
      "1197/1197 [==============================] - 1s 507us/step - loss: 0.1651 - acc: 0.9357\n",
      "Epoch 29/32\n",
      "1197/1197 [==============================] - 1s 511us/step - loss: 0.1642 - acc: 0.9332\n",
      "Epoch 30/32\n",
      "1197/1197 [==============================] - 1s 497us/step - loss: 0.1637 - acc: 0.9382\n",
      "Epoch 31/32\n",
      "1197/1197 [==============================] - 1s 538us/step - loss: 0.1615 - acc: 0.9415\n",
      "Epoch 32/32\n",
      "1197/1197 [==============================] - 1s 523us/step - loss: 0.1591 - acc: 0.9365\n",
      "300/300 [==============================] - 0s 892us/step\n",
      "Epoch 1/32\n",
      "1198/1198 [==============================] - 1s 1ms/step - loss: 0.5214 - acc: 0.8698\n",
      "Epoch 2/32\n",
      "1198/1198 [==============================] - 1s 536us/step - loss: 0.2839 - acc: 0.9057\n",
      "Epoch 3/32\n",
      "1198/1198 [==============================] - 1s 524us/step - loss: 0.2283 - acc: 0.9107\n",
      "Epoch 4/32\n",
      "1198/1198 [==============================] - 1s 523us/step - loss: 0.2135 - acc: 0.9149\n",
      "Epoch 5/32\n",
      "1198/1198 [==============================] - 1s 542us/step - loss: 0.2059 - acc: 0.9190\n",
      "Epoch 6/32\n",
      "1198/1198 [==============================] - 1s 514us/step - loss: 0.2017 - acc: 0.9149\n",
      "Epoch 7/32\n",
      "1198/1198 [==============================] - 1s 511us/step - loss: 0.1976 - acc: 0.9190\n",
      "Epoch 8/32\n",
      "1198/1198 [==============================] - 1s 536us/step - loss: 0.1956 - acc: 0.9232\n",
      "Epoch 9/32\n",
      "1198/1198 [==============================] - 1s 524us/step - loss: 0.1912 - acc: 0.9224\n",
      "Epoch 10/32\n",
      "1198/1198 [==============================] - 1s 535us/step - loss: 0.1875 - acc: 0.9265\n",
      "Epoch 11/32\n",
      "1198/1198 [==============================] - 1s 532us/step - loss: 0.1859 - acc: 0.9290\n",
      "Epoch 12/32\n",
      "1198/1198 [==============================] - 1s 514us/step - loss: 0.1830 - acc: 0.9332\n",
      "Epoch 13/32\n",
      "1198/1198 [==============================] - 1s 523us/step - loss: 0.1791 - acc: 0.9332\n",
      "Epoch 14/32\n",
      "1198/1198 [==============================] - 1s 510us/step - loss: 0.1800 - acc: 0.9316\n",
      "Epoch 15/32\n",
      "1198/1198 [==============================] - 1s 525us/step - loss: 0.1765 - acc: 0.9366\n",
      "Epoch 16/32\n",
      "1198/1198 [==============================] - 1s 519us/step - loss: 0.1731 - acc: 0.9316\n",
      "Epoch 17/32\n",
      "1198/1198 [==============================] - 1s 540us/step - loss: 0.1733 - acc: 0.9391\n",
      "Epoch 18/32\n",
      "1198/1198 [==============================] - 1s 537us/step - loss: 0.1703 - acc: 0.9382\n",
      "Epoch 19/32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1198/1198 [==============================] - 1s 549us/step - loss: 0.1688 - acc: 0.9391\n",
      "Epoch 20/32\n",
      "1198/1198 [==============================] - 1s 625us/step - loss: 0.1654 - acc: 0.9432\n",
      "Epoch 21/32\n",
      "1198/1198 [==============================] - 1s 553us/step - loss: 0.1654 - acc: 0.9424\n",
      "Epoch 22/32\n",
      "1198/1198 [==============================] - 1s 523us/step - loss: 0.1653 - acc: 0.9432\n",
      "Epoch 23/32\n",
      "1198/1198 [==============================] - 1s 538us/step - loss: 0.1629 - acc: 0.9432\n",
      "Epoch 24/32\n",
      "1198/1198 [==============================] - 1s 509us/step - loss: 0.1606 - acc: 0.9432\n",
      "Epoch 25/32\n",
      "1198/1198 [==============================] - 1s 534us/step - loss: 0.1617 - acc: 0.9424\n",
      "Epoch 26/32\n",
      "1198/1198 [==============================] - 1s 499us/step - loss: 0.1595 - acc: 0.9466\n",
      "Epoch 27/32\n",
      "1198/1198 [==============================] - 1s 497us/step - loss: 0.1570 - acc: 0.9424\n",
      "Epoch 28/32\n",
      "1198/1198 [==============================] - 1s 549us/step - loss: 0.1570 - acc: 0.9424\n",
      "Epoch 29/32\n",
      "1198/1198 [==============================] - 1s 510us/step - loss: 0.1522 - acc: 0.9424\n",
      "Epoch 30/32\n",
      "1198/1198 [==============================] - 1s 586us/step - loss: 0.1534 - acc: 0.9441\n",
      "Epoch 31/32\n",
      "1198/1198 [==============================] - 1s 566us/step - loss: 0.1524 - acc: 0.9457\n",
      "Epoch 32/32\n",
      "1198/1198 [==============================] - 1s 563us/step - loss: 0.1500 - acc: 0.9491\n",
      "299/299 [==============================] - 0s 947us/step\n",
      "Epoch 1/32\n",
      "1198/1198 [==============================] - 1s 1ms/step - loss: 0.5125 - acc: 0.8664\n",
      "Epoch 2/32\n",
      "1198/1198 [==============================] - 1s 575us/step - loss: 0.2881 - acc: 0.8948\n",
      "Epoch 3/32\n",
      "1198/1198 [==============================] - 1s 539us/step - loss: 0.2447 - acc: 0.8982\n",
      "Epoch 4/32\n",
      "1198/1198 [==============================] - 1s 533us/step - loss: 0.2328 - acc: 0.9115\n",
      "Epoch 5/32\n",
      "1198/1198 [==============================] - 1s 523us/step - loss: 0.2237 - acc: 0.9057\n",
      "Epoch 6/32\n",
      "1198/1198 [==============================] - 1s 563us/step - loss: 0.2156 - acc: 0.9174\n",
      "Epoch 7/32\n",
      "1198/1198 [==============================] - 1s 536us/step - loss: 0.2156 - acc: 0.9165\n",
      "Epoch 8/32\n",
      "1198/1198 [==============================] - 1s 558us/step - loss: 0.2107 - acc: 0.9215\n",
      "Epoch 9/32\n",
      "1198/1198 [==============================] - 1s 528us/step - loss: 0.2052 - acc: 0.9190\n",
      "Epoch 10/32\n",
      "1198/1198 [==============================] - 1s 549us/step - loss: 0.2012 - acc: 0.9207\n",
      "Epoch 11/32\n",
      "1198/1198 [==============================] - 1s 536us/step - loss: 0.1992 - acc: 0.9215\n",
      "Epoch 12/32\n",
      "1198/1198 [==============================] - 1s 547us/step - loss: 0.1961 - acc: 0.9257\n",
      "Epoch 13/32\n",
      "1198/1198 [==============================] - 1s 553us/step - loss: 0.1932 - acc: 0.9232\n",
      "Epoch 14/32\n",
      "1198/1198 [==============================] - 1s 549us/step - loss: 0.1912 - acc: 0.9274\n",
      "Epoch 15/32\n",
      "1198/1198 [==============================] - 1s 588us/step - loss: 0.1864 - acc: 0.9249\n",
      "Epoch 16/32\n",
      "1198/1198 [==============================] - 1s 564us/step - loss: 0.1836 - acc: 0.9307\n",
      "Epoch 17/32\n",
      "1198/1198 [==============================] - 1s 549us/step - loss: 0.1831 - acc: 0.9324\n",
      "Epoch 18/32\n",
      "1198/1198 [==============================] - 1s 536us/step - loss: 0.1792 - acc: 0.9299\n",
      "Epoch 19/32\n",
      "1198/1198 [==============================] - 1s 549us/step - loss: 0.1778 - acc: 0.9316\n",
      "Epoch 20/32\n",
      "1198/1198 [==============================] - 1s 547us/step - loss: 0.1764 - acc: 0.9349\n",
      "Epoch 21/32\n",
      "1198/1198 [==============================] - 1s 566us/step - loss: 0.1733 - acc: 0.9324\n",
      "Epoch 22/32\n",
      "1198/1198 [==============================] - 1s 563us/step - loss: 0.1703 - acc: 0.9374\n",
      "Epoch 23/32\n",
      "1198/1198 [==============================] - 1s 536us/step - loss: 0.1709 - acc: 0.9366\n",
      "Epoch 24/32\n",
      "1198/1198 [==============================] - 1s 547us/step - loss: 0.1672 - acc: 0.9382\n",
      "Epoch 25/32\n",
      "1198/1198 [==============================] - 1s 553us/step - loss: 0.1669 - acc: 0.9399\n",
      "Epoch 26/32\n",
      "1198/1198 [==============================] - 1s 536us/step - loss: 0.1640 - acc: 0.9416\n",
      "Epoch 27/32\n",
      "1198/1198 [==============================] - 1s 536us/step - loss: 0.1630 - acc: 0.9399\n",
      "Epoch 28/32\n",
      "1198/1198 [==============================] - 1s 543us/step - loss: 0.1627 - acc: 0.9416\n",
      "Epoch 29/32\n",
      "1198/1198 [==============================] - 1s 555us/step - loss: 0.1588 - acc: 0.9449\n",
      "Epoch 30/32\n",
      "1198/1198 [==============================] - 1s 549us/step - loss: 0.1589 - acc: 0.9432\n",
      "Epoch 31/32\n",
      "1198/1198 [==============================] - 1s 549us/step - loss: 0.1578 - acc: 0.9474\n",
      "Epoch 32/32\n",
      "1198/1198 [==============================] - 1s 612us/step - loss: 0.1550 - acc: 0.9466\n",
      "299/299 [==============================] - 0s 1ms/step\n",
      "Epoch 1/32\n",
      "1198/1198 [==============================] - 1s 1ms/step - loss: 0.5209 - acc: 0.7930\n",
      "Epoch 2/32\n",
      "1198/1198 [==============================] - 1s 538us/step - loss: 0.3045 - acc: 0.9032\n",
      "Epoch 3/32\n",
      "1198/1198 [==============================] - 1s 549us/step - loss: 0.2344 - acc: 0.9098\n",
      "Epoch 4/32\n",
      "1198/1198 [==============================] - 1s 536us/step - loss: 0.2204 - acc: 0.9115\n",
      "Epoch 5/32\n",
      "1198/1198 [==============================] - 1s 536us/step - loss: 0.2141 - acc: 0.9132\n",
      "Epoch 6/32\n",
      "1198/1198 [==============================] - 1s 536us/step - loss: 0.2108 - acc: 0.9182\n",
      "Epoch 7/32\n",
      "1198/1198 [==============================] - 1s 547us/step - loss: 0.2067 - acc: 0.9190\n",
      "Epoch 8/32\n",
      "1198/1198 [==============================] - 1s 540us/step - loss: 0.2032 - acc: 0.9182\n",
      "Epoch 9/32\n",
      "1198/1198 [==============================] - 1s 550us/step - loss: 0.2012 - acc: 0.9207\n",
      "Epoch 10/32\n",
      "1198/1198 [==============================] - 1s 615us/step - loss: 0.1999 - acc: 0.9240\n",
      "Epoch 11/32\n",
      "1198/1198 [==============================] - 1s 549us/step - loss: 0.1954 - acc: 0.9240\n",
      "Epoch 12/32\n",
      "1198/1198 [==============================] - 1s 537us/step - loss: 0.1926 - acc: 0.9299\n",
      "Epoch 13/32\n",
      "1198/1198 [==============================] - 1s 549us/step - loss: 0.1922 - acc: 0.9240\n",
      "Epoch 14/32\n",
      "1198/1198 [==============================] - 1s 536us/step - loss: 0.1901 - acc: 0.9332\n",
      "Epoch 15/32\n",
      "1198/1198 [==============================] - 1s 547us/step - loss: 0.1861 - acc: 0.9332\n",
      "Epoch 16/32\n",
      "1198/1198 [==============================] - 1s 540us/step - loss: 0.1858 - acc: 0.9332\n",
      "Epoch 17/32\n",
      "1198/1198 [==============================] - 1s 524us/step - loss: 0.1820 - acc: 0.9307\n",
      "Epoch 18/32\n",
      "1198/1198 [==============================] - 1s 562us/step - loss: 0.1808 - acc: 0.9332\n",
      "Epoch 19/32\n",
      "1198/1198 [==============================] - 1s 522us/step - loss: 0.1792 - acc: 0.9332\n",
      "Epoch 20/32\n",
      "1198/1198 [==============================] - 1s 552us/step - loss: 0.1804 - acc: 0.9316\n",
      "Epoch 21/32\n",
      "1198/1198 [==============================] - 1s 536us/step - loss: 0.1762 - acc: 0.9341\n",
      "Epoch 22/32\n",
      "1198/1198 [==============================] - 1s 536us/step - loss: 0.1744 - acc: 0.9349\n",
      "Epoch 23/32\n",
      "1198/1198 [==============================] - 1s 548us/step - loss: 0.1731 - acc: 0.9374\n",
      "Epoch 24/32\n",
      "1198/1198 [==============================] - 1s 548us/step - loss: 0.1744 - acc: 0.9357\n",
      "Epoch 25/32\n",
      "1198/1198 [==============================] - 1s 555us/step - loss: 0.1709 - acc: 0.9366\n",
      "Epoch 26/32\n",
      "1198/1198 [==============================] - 1s 588us/step - loss: 0.1694 - acc: 0.9382\n",
      "Epoch 27/32\n",
      "1198/1198 [==============================] - 1s 576us/step - loss: 0.1681 - acc: 0.9407\n",
      "Epoch 28/32\n",
      "1198/1198 [==============================] - 1s 549us/step - loss: 0.1653 - acc: 0.9399\n",
      "Epoch 29/32\n",
      "1198/1198 [==============================] - 1s 535us/step - loss: 0.1640 - acc: 0.9416\n",
      "Epoch 30/32\n",
      "1198/1198 [==============================] - 1s 523us/step - loss: 0.1611 - acc: 0.9407\n",
      "Epoch 31/32\n",
      "1198/1198 [==============================] - 1s 575us/step - loss: 0.1622 - acc: 0.9424\n",
      "Epoch 32/32\n",
      "1198/1198 [==============================] - 1s 564us/step - loss: 0.1598 - acc: 0.9424\n",
      "299/299 [==============================] - 0s 993us/step\n",
      "Epoch 1/64\n",
      "1197/1197 [==============================] - 1s 1ms/step - loss: 0.5311 - acc: 0.8388\n",
      "Epoch 2/64\n",
      "1197/1197 [==============================] - 1s 564us/step - loss: 0.2751 - acc: 0.8989\n",
      "Epoch 3/64\n",
      "1197/1197 [==============================] - 1s 562us/step - loss: 0.2299 - acc: 0.9064\n",
      "Epoch 4/64\n",
      "1197/1197 [==============================] - 1s 651us/step - loss: 0.2180 - acc: 0.9098\n",
      "Epoch 5/64\n",
      "1197/1197 [==============================] - 1s 639us/step - loss: 0.2103 - acc: 0.9081\n",
      "Epoch 6/64\n",
      "1197/1197 [==============================] - 1s 626us/step - loss: 0.2018 - acc: 0.9148\n",
      "Epoch 7/64\n",
      "1197/1197 [==============================] - 1s 717us/step - loss: 0.1978 - acc: 0.9131\n",
      "Epoch 8/64\n",
      "1197/1197 [==============================] - 1s 740us/step - loss: 0.1913 - acc: 0.9181\n",
      "Epoch 9/64\n",
      "1197/1197 [==============================] - 1s 721us/step - loss: 0.1870 - acc: 0.9223\n",
      "Epoch 10/64\n",
      "1197/1197 [==============================] - 1s 588us/step - loss: 0.1813 - acc: 0.9240\n",
      "Epoch 11/64\n",
      "1197/1197 [==============================] - 1s 568us/step - loss: 0.1813 - acc: 0.9215\n",
      "Epoch 12/64\n",
      "1197/1197 [==============================] - 1s 665us/step - loss: 0.1730 - acc: 0.9273\n",
      "Epoch 13/64\n",
      "1197/1197 [==============================] - 1s 672us/step - loss: 0.1726 - acc: 0.9332\n",
      "Epoch 14/64\n",
      "1197/1197 [==============================] - 1s 638us/step - loss: 0.1670 - acc: 0.9348\n",
      "Epoch 15/64\n",
      "1197/1197 [==============================] - 1s 589us/step - loss: 0.1657 - acc: 0.9323\n",
      "Epoch 16/64\n",
      "1197/1197 [==============================] - 1s 581us/step - loss: 0.1639 - acc: 0.9315\n",
      "Epoch 17/64\n",
      "1197/1197 [==============================] - 1s 560us/step - loss: 0.1587 - acc: 0.9407\n",
      "Epoch 18/64\n",
      "1197/1197 [==============================] - 1s 576us/step - loss: 0.1585 - acc: 0.9348\n",
      "Epoch 19/64\n",
      "1197/1197 [==============================] - 1s 580us/step - loss: 0.1555 - acc: 0.9382\n",
      "Epoch 20/64\n",
      "1197/1197 [==============================] - 1s 549us/step - loss: 0.1537 - acc: 0.9407\n",
      "Epoch 21/64\n",
      "1197/1197 [==============================] - 1s 571us/step - loss: 0.1513 - acc: 0.9449\n",
      "Epoch 22/64\n",
      "1197/1197 [==============================] - 1s 537us/step - loss: 0.1488 - acc: 0.9449\n",
      "Epoch 23/64\n",
      "1197/1197 [==============================] - 1s 594us/step - loss: 0.1480 - acc: 0.9440\n",
      "Epoch 24/64\n",
      "1197/1197 [==============================] - 1s 559us/step - loss: 0.1461 - acc: 0.9457\n",
      "Epoch 25/64\n",
      "1197/1197 [==============================] - 1s 550us/step - loss: 0.1433 - acc: 0.9474\n",
      "Epoch 26/64\n",
      "1197/1197 [==============================] - 1s 579us/step - loss: 0.1410 - acc: 0.9490\n",
      "Epoch 27/64\n",
      "1197/1197 [==============================] - 1s 564us/step - loss: 0.1386 - acc: 0.9474\n",
      "Epoch 28/64\n",
      "1197/1197 [==============================] - 1s 572us/step - loss: 0.1383 - acc: 0.9474\n",
      "Epoch 29/64\n",
      "1197/1197 [==============================] - 1s 577us/step - loss: 0.1356 - acc: 0.9482\n",
      "Epoch 30/64\n",
      "1197/1197 [==============================] - 1s 567us/step - loss: 0.1344 - acc: 0.9499\n",
      "Epoch 31/64\n",
      "1197/1197 [==============================] - 1s 556us/step - loss: 0.1313 - acc: 0.9474\n",
      "Epoch 32/64\n",
      "1197/1197 [==============================] - 1s 565us/step - loss: 0.1310 - acc: 0.9574\n",
      "Epoch 33/64\n",
      "1197/1197 [==============================] - 1s 592us/step - loss: 0.1295 - acc: 0.9515\n",
      "Epoch 34/64\n",
      "1197/1197 [==============================] - 1s 551us/step - loss: 0.1271 - acc: 0.9532\n",
      "Epoch 35/64\n",
      "1197/1197 [==============================] - 1s 599us/step - loss: 0.1277 - acc: 0.9549\n",
      "Epoch 36/64\n",
      "1197/1197 [==============================] - 1s 563us/step - loss: 0.1246 - acc: 0.9532\n",
      "Epoch 37/64\n",
      "1197/1197 [==============================] - 1s 568us/step - loss: 0.1229 - acc: 0.9549\n",
      "Epoch 38/64\n",
      "1197/1197 [==============================] - 1s 559us/step - loss: 0.1208 - acc: 0.9557\n",
      "Epoch 39/64\n",
      "1197/1197 [==============================] - 1s 576us/step - loss: 0.1199 - acc: 0.9557\n",
      "Epoch 40/64\n",
      "1197/1197 [==============================] - 1s 581us/step - loss: 0.1184 - acc: 0.9582\n",
      "Epoch 41/64\n",
      "1197/1197 [==============================] - 1s 585us/step - loss: 0.1223 - acc: 0.9557\n",
      "Epoch 42/64\n",
      "1197/1197 [==============================] - 1s 576us/step - loss: 0.1159 - acc: 0.9582\n",
      "Epoch 43/64\n",
      "1197/1197 [==============================] - 1s 562us/step - loss: 0.1147 - acc: 0.9566\n",
      "Epoch 44/64\n",
      "1197/1197 [==============================] - 1s 599us/step - loss: 0.1135 - acc: 0.9599\n",
      "Epoch 45/64\n",
      "1197/1197 [==============================] - 1s 579us/step - loss: 0.1127 - acc: 0.9574\n",
      "Epoch 46/64\n",
      "1197/1197 [==============================] - 1s 589us/step - loss: 0.1105 - acc: 0.9624\n",
      "Epoch 47/64\n",
      "1197/1197 [==============================] - 1s 608us/step - loss: 0.1113 - acc: 0.9574\n",
      "Epoch 48/64\n",
      "1197/1197 [==============================] - 1s 556us/step - loss: 0.1127 - acc: 0.9566\n",
      "Epoch 49/64\n",
      "1197/1197 [==============================] - 1s 576us/step - loss: 0.1087 - acc: 0.9574\n",
      "Epoch 50/64\n",
      "1197/1197 [==============================] - 1s 594us/step - loss: 0.1120 - acc: 0.9549\n",
      "Epoch 51/64\n",
      "1197/1197 [==============================] - 1s 589us/step - loss: 0.1079 - acc: 0.9607\n",
      "Epoch 52/64\n",
      "1197/1197 [==============================] - 1s 599us/step - loss: 0.1072 - acc: 0.9599\n",
      "Epoch 53/64\n",
      "1197/1197 [==============================] - 1s 593us/step - loss: 0.1049 - acc: 0.9607\n",
      "Epoch 54/64\n",
      "1197/1197 [==============================] - 1s 650us/step - loss: 0.1048 - acc: 0.9624\n",
      "Epoch 55/64\n",
      "1197/1197 [==============================] - 1s 607us/step - loss: 0.1038 - acc: 0.9616\n",
      "Epoch 56/64\n",
      "1197/1197 [==============================] - 1s 586us/step - loss: 0.1065 - acc: 0.9616\n",
      "Epoch 57/64\n",
      "1197/1197 [==============================] - 1s 589us/step - loss: 0.1019 - acc: 0.9632\n",
      "Epoch 58/64\n",
      "1197/1197 [==============================] - 1s 568us/step - loss: 0.1057 - acc: 0.9591\n",
      "Epoch 59/64\n",
      "1197/1197 [==============================] - 1s 599us/step - loss: 0.1009 - acc: 0.9632\n",
      "Epoch 60/64\n",
      "1197/1197 [==============================] - 1s 576us/step - loss: 0.0980 - acc: 0.9641\n",
      "Epoch 61/64\n",
      "1197/1197 [==============================] - 1s 594us/step - loss: 0.1007 - acc: 0.9599\n",
      "Epoch 62/64\n",
      "1197/1197 [==============================] - 1s 599us/step - loss: 0.0986 - acc: 0.9649\n",
      "Epoch 63/64\n",
      "1197/1197 [==============================] - 1s 588us/step - loss: 0.0989 - acc: 0.9624\n",
      "Epoch 64/64\n",
      "1197/1197 [==============================] - 1s 607us/step - loss: 0.0972 - acc: 0.9666 0s - loss: 0.1007 - acc\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/64\n",
      "1197/1197 [==============================] - 2s 1ms/step - loss: 0.5180 - acc: 0.8605\n",
      "Epoch 2/64\n",
      "1197/1197 [==============================] - 1s 589us/step - loss: 0.2618 - acc: 0.9056\n",
      "Epoch 3/64\n",
      "1197/1197 [==============================] - 1s 607us/step - loss: 0.2191 - acc: 0.9106\n",
      "Epoch 4/64\n",
      "1197/1197 [==============================] - 1s 625us/step - loss: 0.2098 - acc: 0.9156\n",
      "Epoch 5/64\n",
      "1197/1197 [==============================] - 1s 607us/step - loss: 0.2046 - acc: 0.9156\n",
      "Epoch 6/64\n",
      "1197/1197 [==============================] - 1s 599us/step - loss: 0.1988 - acc: 0.9190\n",
      "Epoch 7/64\n",
      "1197/1197 [==============================] - 1s 590us/step - loss: 0.1965 - acc: 0.9215\n",
      "Epoch 8/64\n",
      "1197/1197 [==============================] - 1s 580us/step - loss: 0.1912 - acc: 0.9248\n",
      "Epoch 9/64\n",
      "1197/1197 [==============================] - 1s 585us/step - loss: 0.1881 - acc: 0.9265\n",
      "Epoch 10/64\n",
      "1197/1197 [==============================] - 1s 590us/step - loss: 0.1841 - acc: 0.9273\n",
      "Epoch 11/64\n",
      "1197/1197 [==============================] - 1s 606us/step - loss: 0.1791 - acc: 0.9323\n",
      "Epoch 12/64\n",
      "1197/1197 [==============================] - 1s 625us/step - loss: 0.1773 - acc: 0.9290\n",
      "Epoch 13/64\n",
      "1197/1197 [==============================] - 1s 615us/step - loss: 0.1744 - acc: 0.9307\n",
      "Epoch 14/64\n",
      "1197/1197 [==============================] - 1s 580us/step - loss: 0.1711 - acc: 0.9332\n",
      "Epoch 15/64\n",
      "1197/1197 [==============================] - 1s 599us/step - loss: 0.1690 - acc: 0.9357\n",
      "Epoch 16/64\n",
      "1197/1197 [==============================] - 1s 577us/step - loss: 0.1679 - acc: 0.9357\n",
      "Epoch 17/64\n",
      "1197/1197 [==============================] - 1s 593us/step - loss: 0.1648 - acc: 0.9407\n",
      "Epoch 18/64\n",
      "1197/1197 [==============================] - 1s 612us/step - loss: 0.1632 - acc: 0.9398\n",
      "Epoch 19/64\n",
      "1197/1197 [==============================] - 1s 600us/step - loss: 0.1618 - acc: 0.9407\n",
      "Epoch 20/64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1197/1197 [==============================] - 1s 580us/step - loss: 0.1621 - acc: 0.9398\n",
      "Epoch 21/64\n",
      "1197/1197 [==============================] - 1s 599us/step - loss: 0.1561 - acc: 0.9407 0s - loss: 0.1546 - acc: 0.9\n",
      "Epoch 22/64\n",
      "1197/1197 [==============================] - 1s 576us/step - loss: 0.1569 - acc: 0.9449\n",
      "Epoch 23/64\n",
      "1197/1197 [==============================] - 1s 594us/step - loss: 0.1529 - acc: 0.9449\n",
      "Epoch 24/64\n",
      "1197/1197 [==============================] - 1s 599us/step - loss: 0.1528 - acc: 0.9465\n",
      "Epoch 25/64\n",
      "1197/1197 [==============================] - 1s 597us/step - loss: 0.1518 - acc: 0.9449\n",
      "Epoch 26/64\n",
      "1197/1197 [==============================] - 1s 608us/step - loss: 0.1488 - acc: 0.9457\n",
      "Epoch 27/64\n",
      "1197/1197 [==============================] - 1s 615us/step - loss: 0.1495 - acc: 0.9490\n",
      "Epoch 28/64\n",
      "1197/1197 [==============================] - 1s 645us/step - loss: 0.1460 - acc: 0.9482\n",
      "Epoch 29/64\n",
      "1197/1197 [==============================] - 1s 599us/step - loss: 0.1431 - acc: 0.9532\n",
      "Epoch 30/64\n",
      "1197/1197 [==============================] - 1s 601us/step - loss: 0.1431 - acc: 0.9507\n",
      "Epoch 31/64\n",
      "1197/1197 [==============================] - 1s 682us/step - loss: 0.1414 - acc: 0.9532\n",
      "Epoch 32/64\n",
      "1197/1197 [==============================] - 1s 589us/step - loss: 0.1399 - acc: 0.9474\n",
      "Epoch 33/64\n",
      "1197/1197 [==============================] - 1s 659us/step - loss: 0.1387 - acc: 0.9499\n",
      "Epoch 34/64\n",
      "1197/1197 [==============================] - 1s 664us/step - loss: 0.1372 - acc: 0.9499\n",
      "Epoch 35/64\n",
      "1197/1197 [==============================] - 1s 697us/step - loss: 0.1361 - acc: 0.9507\n",
      "Epoch 36/64\n",
      "1197/1197 [==============================] - 1s 624us/step - loss: 0.1341 - acc: 0.9532\n",
      "Epoch 37/64\n",
      "1197/1197 [==============================] - 1s 690us/step - loss: 0.1320 - acc: 0.9541\n",
      "Epoch 38/64\n",
      "1197/1197 [==============================] - 1s 618us/step - loss: 0.1305 - acc: 0.9524\n",
      "Epoch 39/64\n",
      "1197/1197 [==============================] - 1s 594us/step - loss: 0.1300 - acc: 0.9524\n",
      "Epoch 40/64\n",
      "1197/1197 [==============================] - 1s 599us/step - loss: 0.1292 - acc: 0.9532\n",
      "Epoch 41/64\n",
      "1197/1197 [==============================] - 1s 684us/step - loss: 0.1297 - acc: 0.9507\n",
      "Epoch 42/64\n",
      "1197/1197 [==============================] - 1s 599us/step - loss: 0.1264 - acc: 0.9566\n",
      "Epoch 43/64\n",
      "1197/1197 [==============================] - 1s 564us/step - loss: 0.1252 - acc: 0.9591\n",
      "Epoch 44/64\n",
      "1197/1197 [==============================] - 1s 603us/step - loss: 0.1265 - acc: 0.9499\n",
      "Epoch 45/64\n",
      "1197/1197 [==============================] - 1s 601us/step - loss: 0.1237 - acc: 0.9566\n",
      "Epoch 46/64\n",
      "1197/1197 [==============================] - 1s 589us/step - loss: 0.1214 - acc: 0.9574\n",
      "Epoch 47/64\n",
      "1197/1197 [==============================] - 1s 607us/step - loss: 0.1207 - acc: 0.9566\n",
      "Epoch 48/64\n",
      "1197/1197 [==============================] - 1s 598us/step - loss: 0.1197 - acc: 0.9566 0s - loss: 0.1040 - acc: 0.\n",
      "Epoch 49/64\n",
      "1197/1197 [==============================] - 1s 603us/step - loss: 0.1183 - acc: 0.9566\n",
      "Epoch 50/64\n",
      "1197/1197 [==============================] - 1s 593us/step - loss: 0.1187 - acc: 0.9566\n",
      "Epoch 51/64\n",
      "1197/1197 [==============================] - 1s 572us/step - loss: 0.1166 - acc: 0.9607 0s - loss: 0.1187 - acc: 0.96\n",
      "Epoch 52/64\n",
      "1197/1197 [==============================] - 1s 603us/step - loss: 0.1162 - acc: 0.9574\n",
      "Epoch 53/64\n",
      "1197/1197 [==============================] - 1s 632us/step - loss: 0.1157 - acc: 0.9616\n",
      "Epoch 54/64\n",
      "1197/1197 [==============================] - 1s 587us/step - loss: 0.1134 - acc: 0.9616\n",
      "Epoch 55/64\n",
      "1197/1197 [==============================] - 1s 591us/step - loss: 0.1111 - acc: 0.9607\n",
      "Epoch 56/64\n",
      "1197/1197 [==============================] - 1s 609us/step - loss: 0.1108 - acc: 0.9599\n",
      "Epoch 57/64\n",
      "1197/1197 [==============================] - 1s 579us/step - loss: 0.1091 - acc: 0.9616\n",
      "Epoch 58/64\n",
      "1197/1197 [==============================] - 1s 605us/step - loss: 0.1079 - acc: 0.9591\n",
      "Epoch 59/64\n",
      "1197/1197 [==============================] - 1s 581us/step - loss: 0.1053 - acc: 0.9632\n",
      "Epoch 60/64\n",
      "1197/1197 [==============================] - 1s 593us/step - loss: 0.1070 - acc: 0.9607\n",
      "Epoch 61/64\n",
      "1197/1197 [==============================] - 1s 591us/step - loss: 0.1044 - acc: 0.9624\n",
      "Epoch 62/64\n",
      "1197/1197 [==============================] - 1s 587us/step - loss: 0.1042 - acc: 0.9657\n",
      "Epoch 63/64\n",
      "1197/1197 [==============================] - 1s 602us/step - loss: 0.1024 - acc: 0.9649\n",
      "Epoch 64/64\n",
      "1197/1197 [==============================] - 1s 594us/step - loss: 0.1020 - acc: 0.9657\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 1/64\n",
      "1198/1198 [==============================] - 2s 1ms/step - loss: 0.5312 - acc: 0.8573\n",
      "Epoch 2/64\n",
      "1198/1198 [==============================] - 1s 615us/step - loss: 0.2889 - acc: 0.9048\n",
      "Epoch 3/64\n",
      "1198/1198 [==============================] - 1s 606us/step - loss: 0.2270 - acc: 0.9157\n",
      "Epoch 4/64\n",
      "1198/1198 [==============================] - 1s 611us/step - loss: 0.2114 - acc: 0.9215\n",
      "Epoch 5/64\n",
      "1198/1198 [==============================] - 1s 620us/step - loss: 0.2058 - acc: 0.9190\n",
      "Epoch 6/64\n",
      "1198/1198 [==============================] - 1s 606us/step - loss: 0.1990 - acc: 0.9232\n",
      "Epoch 7/64\n",
      "1198/1198 [==============================] - 1s 656us/step - loss: 0.1911 - acc: 0.9299\n",
      "Epoch 8/64\n",
      "1198/1198 [==============================] - 1s 734us/step - loss: 0.1854 - acc: 0.9265\n",
      "Epoch 9/64\n",
      "1198/1198 [==============================] - 1s 628us/step - loss: 0.1821 - acc: 0.9349\n",
      "Epoch 10/64\n",
      "1198/1198 [==============================] - 1s 627us/step - loss: 0.1773 - acc: 0.9307\n",
      "Epoch 11/64\n",
      "1198/1198 [==============================] - 1s 602us/step - loss: 0.1740 - acc: 0.9341\n",
      "Epoch 12/64\n",
      "1198/1198 [==============================] - 1s 593us/step - loss: 0.1694 - acc: 0.9391\n",
      "Epoch 13/64\n",
      "1198/1198 [==============================] - 1s 599us/step - loss: 0.1683 - acc: 0.9407\n",
      "Epoch 14/64\n",
      "1198/1198 [==============================] - 1s 602us/step - loss: 0.1633 - acc: 0.9382\n",
      "Epoch 15/64\n",
      "1198/1198 [==============================] - 1s 606us/step - loss: 0.1613 - acc: 0.9374\n",
      "Epoch 16/64\n",
      "1198/1198 [==============================] - 1s 611us/step - loss: 0.1587 - acc: 0.9416\n",
      "Epoch 17/64\n",
      "1198/1198 [==============================] - 1s 668us/step - loss: 0.1567 - acc: 0.9382\n",
      "Epoch 18/64\n",
      "1198/1198 [==============================] - 1s 594us/step - loss: 0.1546 - acc: 0.9449\n",
      "Epoch 19/64\n",
      "1198/1198 [==============================] - 1s 580us/step - loss: 0.1520 - acc: 0.9416\n",
      "Epoch 20/64\n",
      "1198/1198 [==============================] - 1s 595us/step - loss: 0.1517 - acc: 0.9457\n",
      "Epoch 21/64\n",
      "1198/1198 [==============================] - 1s 603us/step - loss: 0.1489 - acc: 0.9441\n",
      "Epoch 22/64\n",
      "1198/1198 [==============================] - 1s 591us/step - loss: 0.1466 - acc: 0.9457\n",
      "Epoch 23/64\n",
      "1198/1198 [==============================] - 1s 593us/step - loss: 0.1460 - acc: 0.9499\n",
      "Epoch 24/64\n",
      "1198/1198 [==============================] - 1s 599us/step - loss: 0.1443 - acc: 0.9441\n",
      "Epoch 25/64\n",
      "1198/1198 [==============================] - 1s 602us/step - loss: 0.1423 - acc: 0.9524\n",
      "Epoch 26/64\n",
      "1198/1198 [==============================] - 1s 580us/step - loss: 0.1435 - acc: 0.9466\n",
      "Epoch 27/64\n",
      "1198/1198 [==============================] - 1s 572us/step - loss: 0.1408 - acc: 0.9516\n",
      "Epoch 28/64\n",
      "1198/1198 [==============================] - 1s 628us/step - loss: 0.1382 - acc: 0.9508\n",
      "Epoch 29/64\n",
      "1198/1198 [==============================] - 1s 605us/step - loss: 0.1391 - acc: 0.9482\n",
      "Epoch 30/64\n",
      "1198/1198 [==============================] - 1s 573us/step - loss: 0.1361 - acc: 0.9499\n",
      "Epoch 31/64\n",
      "1198/1198 [==============================] - 1s 588us/step - loss: 0.1358 - acc: 0.9499\n",
      "Epoch 32/64\n",
      "1198/1198 [==============================] - 1s 606us/step - loss: 0.1340 - acc: 0.9499\n",
      "Epoch 33/64\n",
      "1198/1198 [==============================] - 1s 624us/step - loss: 0.1353 - acc: 0.9541\n",
      "Epoch 34/64\n",
      "1198/1198 [==============================] - 1s 646us/step - loss: 0.1350 - acc: 0.9499\n",
      "Epoch 35/64\n",
      "1198/1198 [==============================] - 1s 625us/step - loss: 0.1344 - acc: 0.9516\n",
      "Epoch 36/64\n",
      "1198/1198 [==============================] - 1s 615us/step - loss: 0.1337 - acc: 0.9499\n",
      "Epoch 37/64\n",
      "1198/1198 [==============================] - 1s 576us/step - loss: 0.1306 - acc: 0.9482\n",
      "Epoch 38/64\n",
      "1198/1198 [==============================] - 1s 586us/step - loss: 0.1304 - acc: 0.9541\n",
      "Epoch 39/64\n",
      "1198/1198 [==============================] - 1s 601us/step - loss: 0.1308 - acc: 0.9533\n",
      "Epoch 40/64\n",
      "1198/1198 [==============================] - 1s 594us/step - loss: 0.1288 - acc: 0.9574\n",
      "Epoch 41/64\n",
      "1198/1198 [==============================] - 1s 609us/step - loss: 0.1272 - acc: 0.9524\n",
      "Epoch 42/64\n",
      "1198/1198 [==============================] - 1s 606us/step - loss: 0.1290 - acc: 0.9491\n",
      "Epoch 43/64\n",
      "1198/1198 [==============================] - 1s 599us/step - loss: 0.1292 - acc: 0.9508\n",
      "Epoch 44/64\n",
      "1198/1198 [==============================] - 1s 588us/step - loss: 0.1243 - acc: 0.9558\n",
      "Epoch 45/64\n",
      "1198/1198 [==============================] - 1s 607us/step - loss: 0.1265 - acc: 0.9549\n",
      "Epoch 46/64\n",
      "1198/1198 [==============================] - 1s 612us/step - loss: 0.1207 - acc: 0.9591\n",
      "Epoch 47/64\n",
      "1198/1198 [==============================] - 1s 575us/step - loss: 0.1257 - acc: 0.9533\n",
      "Epoch 48/64\n",
      "1198/1198 [==============================] - 1s 652us/step - loss: 0.1234 - acc: 0.9558\n",
      "Epoch 49/64\n",
      "1198/1198 [==============================] - 1s 603us/step - loss: 0.1233 - acc: 0.9533\n",
      "Epoch 50/64\n",
      "1198/1198 [==============================] - 1s 671us/step - loss: 0.1206 - acc: 0.9566\n",
      "Epoch 51/64\n",
      "1198/1198 [==============================] - 1s 585us/step - loss: 0.1203 - acc: 0.9533\n",
      "Epoch 52/64\n",
      "1198/1198 [==============================] - 1s 575us/step - loss: 0.1189 - acc: 0.9566\n",
      "Epoch 53/64\n",
      "1198/1198 [==============================] - 1s 580us/step - loss: 0.1194 - acc: 0.9574\n",
      "Epoch 54/64\n",
      "1198/1198 [==============================] - 1s 599us/step - loss: 0.1176 - acc: 0.9566\n",
      "Epoch 55/64\n",
      "1198/1198 [==============================] - 1s 601us/step - loss: 0.1190 - acc: 0.9524 0s - loss: 0.0908 - ac\n",
      "Epoch 56/64\n",
      "1198/1198 [==============================] - 1s 594us/step - loss: 0.1161 - acc: 0.9558\n",
      "Epoch 57/64\n",
      "1198/1198 [==============================] - 1s 611us/step - loss: 0.1205 - acc: 0.9516\n",
      "Epoch 58/64\n",
      "1198/1198 [==============================] - 1s 619us/step - loss: 0.1151 - acc: 0.9574\n",
      "Epoch 59/64\n",
      "1198/1198 [==============================] - 1s 611us/step - loss: 0.1129 - acc: 0.9541\n",
      "Epoch 60/64\n",
      "1198/1198 [==============================] - 1s 601us/step - loss: 0.1140 - acc: 0.9574\n",
      "Epoch 61/64\n",
      "1198/1198 [==============================] - 1s 620us/step - loss: 0.1148 - acc: 0.9591\n",
      "Epoch 62/64\n",
      "1198/1198 [==============================] - 1s 623us/step - loss: 0.1124 - acc: 0.9583\n",
      "Epoch 63/64\n",
      "1198/1198 [==============================] - 1s 619us/step - loss: 0.1119 - acc: 0.9558\n",
      "Epoch 64/64\n",
      "1198/1198 [==============================] - 1s 607us/step - loss: 0.1119 - acc: 0.9566\n",
      "299/299 [==============================] - 0s 1ms/step\n",
      "Epoch 1/64\n",
      "1198/1198 [==============================] - 2s 1ms/step - loss: 0.5527 - acc: 0.7888A: 0s - loss: 0.5658 - acc: 0.783\n",
      "Epoch 2/64\n",
      "1198/1198 [==============================] - 1s 586us/step - loss: 0.2937 - acc: 0.8948\n",
      "Epoch 3/64\n",
      "1198/1198 [==============================] - 1s 711us/step - loss: 0.2409 - acc: 0.9015\n",
      "Epoch 4/64\n",
      "1198/1198 [==============================] - 1s 597us/step - loss: 0.2256 - acc: 0.9140\n",
      "Epoch 5/64\n",
      "1198/1198 [==============================] - 1s 602us/step - loss: 0.2159 - acc: 0.9115\n",
      "Epoch 6/64\n",
      "1198/1198 [==============================] - 1s 606us/step - loss: 0.2073 - acc: 0.9165\n",
      "Epoch 7/64\n",
      "1198/1198 [==============================] - 1s 611us/step - loss: 0.2008 - acc: 0.9190\n",
      "Epoch 8/64\n",
      "1198/1198 [==============================] - 1s 615us/step - loss: 0.1994 - acc: 0.9182 0s - loss: 0.1726 - acc\n",
      "Epoch 9/64\n",
      "1198/1198 [==============================] - 1s 606us/step - loss: 0.1932 - acc: 0.9257\n",
      "Epoch 10/64\n",
      "1198/1198 [==============================] - 1s 598us/step - loss: 0.1893 - acc: 0.9240\n",
      "Epoch 11/64\n",
      "1198/1198 [==============================] - 1s 606us/step - loss: 0.1878 - acc: 0.9232\n",
      "Epoch 12/64\n",
      "1198/1198 [==============================] - 1s 611us/step - loss: 0.1826 - acc: 0.9274 0s - loss: 0.1704 - acc: 0.\n",
      "Epoch 13/64\n",
      "1198/1198 [==============================] - 1s 588us/step - loss: 0.1783 - acc: 0.9240\n",
      "Epoch 14/64\n",
      "1198/1198 [==============================] - 1s 633us/step - loss: 0.1758 - acc: 0.9316\n",
      "Epoch 15/64\n",
      "1198/1198 [==============================] - 1s 624us/step - loss: 0.1721 - acc: 0.9341\n",
      "Epoch 16/64\n",
      "1198/1198 [==============================] - 1s 632us/step - loss: 0.1680 - acc: 0.9366\n",
      "Epoch 17/64\n",
      "1198/1198 [==============================] - 1s 604us/step - loss: 0.1696 - acc: 0.9332\n",
      "Epoch 18/64\n",
      "1198/1198 [==============================] - 1s 593us/step - loss: 0.1628 - acc: 0.9366\n",
      "Epoch 19/64\n",
      "1198/1198 [==============================] - 1s 593us/step - loss: 0.1609 - acc: 0.9374\n",
      "Epoch 20/64\n",
      "1198/1198 [==============================] - 1s 599us/step - loss: 0.1575 - acc: 0.9374\n",
      "Epoch 21/64\n",
      "1198/1198 [==============================] - 1s 588us/step - loss: 0.1555 - acc: 0.9457\n",
      "Epoch 22/64\n",
      "1198/1198 [==============================] - 1s 593us/step - loss: 0.1534 - acc: 0.9416\n",
      "Epoch 23/64\n",
      "1198/1198 [==============================] - 1s 580us/step - loss: 0.1506 - acc: 0.9441\n",
      "Epoch 24/64\n",
      "1198/1198 [==============================] - 1s 609us/step - loss: 0.1473 - acc: 0.9482\n",
      "Epoch 25/64\n",
      "1198/1198 [==============================] - 1s 604us/step - loss: 0.1463 - acc: 0.9432 0s - loss: 0.1430 - acc\n",
      "Epoch 26/64\n",
      "1198/1198 [==============================] - 1s 649us/step - loss: 0.1445 - acc: 0.9466\n",
      "Epoch 27/64\n",
      "1198/1198 [==============================] - 1s 589us/step - loss: 0.1412 - acc: 0.9491\n",
      "Epoch 28/64\n",
      "1198/1198 [==============================] - 1s 607us/step - loss: 0.1380 - acc: 0.9499\n",
      "Epoch 29/64\n",
      "1198/1198 [==============================] - 1s 570us/step - loss: 0.1371 - acc: 0.9491\n",
      "Epoch 30/64\n",
      "1198/1198 [==============================] - 1s 588us/step - loss: 0.1351 - acc: 0.9524\n",
      "Epoch 31/64\n",
      "1198/1198 [==============================] - 1s 567us/step - loss: 0.1330 - acc: 0.9549\n",
      "Epoch 32/64\n",
      "1198/1198 [==============================] - 1s 585us/step - loss: 0.1303 - acc: 0.9524\n",
      "Epoch 33/64\n",
      "1198/1198 [==============================] - 1s 601us/step - loss: 0.1322 - acc: 0.9482\n",
      "Epoch 34/64\n",
      "1198/1198 [==============================] - 1s 580us/step - loss: 0.1266 - acc: 0.9583\n",
      "Epoch 35/64\n",
      "1198/1198 [==============================] - 1s 574us/step - loss: 0.1253 - acc: 0.9566\n",
      "Epoch 36/64\n",
      "1198/1198 [==============================] - 1s 574us/step - loss: 0.1255 - acc: 0.9541\n",
      "Epoch 37/64\n",
      "1198/1198 [==============================] - 1s 593us/step - loss: 0.1216 - acc: 0.9591\n",
      "Epoch 38/64\n",
      "1198/1198 [==============================] - 1s 587us/step - loss: 0.1217 - acc: 0.9624\n",
      "Epoch 39/64\n",
      "1198/1198 [==============================] - 1s 601us/step - loss: 0.1191 - acc: 0.9583\n",
      "Epoch 40/64\n",
      "1198/1198 [==============================] - 1s 593us/step - loss: 0.1192 - acc: 0.9616\n",
      "Epoch 41/64\n",
      "1198/1198 [==============================] - 1s 598us/step - loss: 0.1167 - acc: 0.9624\n",
      "Epoch 42/64\n",
      "1198/1198 [==============================] - 1s 614us/step - loss: 0.1175 - acc: 0.9608 0s - loss: 0.1111 - acc: 0\n",
      "Epoch 43/64\n",
      "1198/1198 [==============================] - 1s 594us/step - loss: 0.1142 - acc: 0.9633\n",
      "Epoch 44/64\n",
      "1198/1198 [==============================] - 1s 714us/step - loss: 0.1112 - acc: 0.9649\n",
      "Epoch 45/64\n",
      "1198/1198 [==============================] - 1s 623us/step - loss: 0.1078 - acc: 0.9633\n",
      "Epoch 46/64\n",
      "1198/1198 [==============================] - 1s 606us/step - loss: 0.1095 - acc: 0.9658\n",
      "Epoch 47/64\n",
      "1198/1198 [==============================] - 1s 607us/step - loss: 0.1091 - acc: 0.9674\n",
      "Epoch 48/64\n",
      "1198/1198 [==============================] - 1s 584us/step - loss: 0.1055 - acc: 0.9624\n",
      "Epoch 49/64\n",
      "1198/1198 [==============================] - 1s 576us/step - loss: 0.1075 - acc: 0.9641\n",
      "Epoch 50/64\n",
      "1198/1198 [==============================] - 1s 619us/step - loss: 0.1057 - acc: 0.9658\n",
      "Epoch 51/64\n",
      "1198/1198 [==============================] - 1s 572us/step - loss: 0.1061 - acc: 0.9641\n",
      "Epoch 52/64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1198/1198 [==============================] - 1s 575us/step - loss: 0.1042 - acc: 0.9649\n",
      "Epoch 53/64\n",
      "1198/1198 [==============================] - 1s 593us/step - loss: 0.1027 - acc: 0.9658\n",
      "Epoch 54/64\n",
      "1198/1198 [==============================] - 1s 599us/step - loss: 0.0974 - acc: 0.9691\n",
      "Epoch 55/64\n",
      "1198/1198 [==============================] - 1s 588us/step - loss: 0.0986 - acc: 0.9683\n",
      "Epoch 56/64\n",
      "1198/1198 [==============================] - 1s 580us/step - loss: 0.0972 - acc: 0.9699\n",
      "Epoch 57/64\n",
      "1198/1198 [==============================] - 1s 690us/step - loss: 0.0960 - acc: 0.9699\n",
      "Epoch 58/64\n",
      "1198/1198 [==============================] - 1s 616us/step - loss: 0.0955 - acc: 0.9674\n",
      "Epoch 59/64\n",
      "1198/1198 [==============================] - 1s 808us/step - loss: 0.0933 - acc: 0.9716\n",
      "Epoch 60/64\n",
      "1198/1198 [==============================] - 1s 707us/step - loss: 0.0906 - acc: 0.9708\n",
      "Epoch 61/64\n",
      "1198/1198 [==============================] - 1s 641us/step - loss: 0.0940 - acc: 0.9683\n",
      "Epoch 62/64\n",
      "1198/1198 [==============================] - 1s 619us/step - loss: 0.0896 - acc: 0.9766\n",
      "Epoch 63/64\n",
      "1198/1198 [==============================] - 1s 599us/step - loss: 0.0906 - acc: 0.9725\n",
      "Epoch 64/64\n",
      "1198/1198 [==============================] - 1s 620us/step - loss: 0.0878 - acc: 0.9708\n",
      "299/299 [==============================] - 0s 1ms/step\n",
      "Epoch 1/64\n",
      "1198/1198 [==============================] - 2s 1ms/step - loss: 0.5265 - acc: 0.8798\n",
      "Epoch 2/64\n",
      "1198/1198 [==============================] - 1s 672us/step - loss: 0.2731 - acc: 0.9040\n",
      "Epoch 3/64\n",
      "1198/1198 [==============================] - 1s 624us/step - loss: 0.2288 - acc: 0.9082\n",
      "Epoch 4/64\n",
      "1198/1198 [==============================] - 1s 601us/step - loss: 0.2179 - acc: 0.9107\n",
      "Epoch 5/64\n",
      "1198/1198 [==============================] - 1s 579us/step - loss: 0.2109 - acc: 0.9132\n",
      "Epoch 6/64\n",
      "1198/1198 [==============================] - 1s 611us/step - loss: 0.2051 - acc: 0.9207\n",
      "Epoch 7/64\n",
      "1198/1198 [==============================] - 1s 607us/step - loss: 0.2026 - acc: 0.9215\n",
      "Epoch 8/64\n",
      "1198/1198 [==============================] - 1s 625us/step - loss: 0.1981 - acc: 0.9207\n",
      "Epoch 9/64\n",
      "1198/1198 [==============================] - 1s 628us/step - loss: 0.1930 - acc: 0.9240\n",
      "Epoch 10/64\n",
      "1198/1198 [==============================] - 1s 642us/step - loss: 0.1883 - acc: 0.9290\n",
      "Epoch 11/64\n",
      "1198/1198 [==============================] - 1s 667us/step - loss: 0.1877 - acc: 0.9232\n",
      "Epoch 12/64\n",
      "1198/1198 [==============================] - 1s 606us/step - loss: 0.1817 - acc: 0.9207\n",
      "Epoch 13/64\n",
      "1198/1198 [==============================] - 1s 611us/step - loss: 0.1837 - acc: 0.9307\n",
      "Epoch 14/64\n",
      "1198/1198 [==============================] - 1s 594us/step - loss: 0.1771 - acc: 0.9282\n",
      "Epoch 15/64\n",
      "1198/1198 [==============================] - 1s 574us/step - loss: 0.1737 - acc: 0.9332\n",
      "Epoch 16/64\n",
      "1198/1198 [==============================] - 1s 625us/step - loss: 0.1705 - acc: 0.9307\n",
      "Epoch 17/64\n",
      "1198/1198 [==============================] - 1s 672us/step - loss: 0.1684 - acc: 0.9357\n",
      "Epoch 18/64\n",
      "1198/1198 [==============================] - 1s 609us/step - loss: 0.1647 - acc: 0.9382\n",
      "Epoch 19/64\n",
      "1198/1198 [==============================] - 1s 626us/step - loss: 0.1635 - acc: 0.9349\n",
      "Epoch 20/64\n",
      "1198/1198 [==============================] - 1s 603us/step - loss: 0.1647 - acc: 0.9316\n",
      "Epoch 21/64\n",
      "1198/1198 [==============================] - 1s 628us/step - loss: 0.1594 - acc: 0.9391\n",
      "Epoch 22/64\n",
      "1198/1198 [==============================] - 1s 606us/step - loss: 0.1589 - acc: 0.9457\n",
      "Epoch 23/64\n",
      "1198/1198 [==============================] - 1s 612us/step - loss: 0.1564 - acc: 0.9466\n",
      "Epoch 24/64\n",
      "1198/1198 [==============================] - 1s 662us/step - loss: 0.1550 - acc: 0.9424\n",
      "Epoch 25/64\n",
      "1198/1198 [==============================] - 1s 605us/step - loss: 0.1538 - acc: 0.9424\n",
      "Epoch 26/64\n",
      "1198/1198 [==============================] - 1s 589us/step - loss: 0.1506 - acc: 0.9424\n",
      "Epoch 27/64\n",
      "1198/1198 [==============================] - 1s 607us/step - loss: 0.1495 - acc: 0.9432\n",
      "Epoch 28/64\n",
      "1198/1198 [==============================] - 1s 610us/step - loss: 0.1478 - acc: 0.9491\n",
      "Epoch 29/64\n",
      "1198/1198 [==============================] - 1s 615us/step - loss: 0.1460 - acc: 0.9474\n",
      "Epoch 30/64\n",
      "1198/1198 [==============================] - 1s 620us/step - loss: 0.1442 - acc: 0.9466\n",
      "Epoch 31/64\n",
      "1198/1198 [==============================] - 1s 624us/step - loss: 0.1434 - acc: 0.9474\n",
      "Epoch 32/64\n",
      "1198/1198 [==============================] - 1s 620us/step - loss: 0.1413 - acc: 0.9508\n",
      "Epoch 33/64\n",
      "1198/1198 [==============================] - 1s 611us/step - loss: 0.1403 - acc: 0.9474\n",
      "Epoch 34/64\n",
      "1198/1198 [==============================] - 1s 601us/step - loss: 0.1389 - acc: 0.9516\n",
      "Epoch 35/64\n",
      "1198/1198 [==============================] - 1s 606us/step - loss: 0.1391 - acc: 0.9491\n",
      "Epoch 36/64\n",
      "1198/1198 [==============================] - 1s 598us/step - loss: 0.1387 - acc: 0.9474\n",
      "Epoch 37/64\n",
      "1198/1198 [==============================] - 1s 615us/step - loss: 0.1360 - acc: 0.9533\n",
      "Epoch 38/64\n",
      "1198/1198 [==============================] - 1s 597us/step - loss: 0.1335 - acc: 0.9524\n",
      "Epoch 39/64\n",
      "1198/1198 [==============================] - 1s 578us/step - loss: 0.1332 - acc: 0.9524\n",
      "Epoch 40/64\n",
      "1198/1198 [==============================] - 1s 617us/step - loss: 0.1323 - acc: 0.9524\n",
      "Epoch 41/64\n",
      "1198/1198 [==============================] - 1s 614us/step - loss: 0.1307 - acc: 0.9549\n",
      "Epoch 42/64\n",
      "1198/1198 [==============================] - 1s 614us/step - loss: 0.1295 - acc: 0.9533\n",
      "Epoch 43/64\n",
      "1198/1198 [==============================] - 1s 658us/step - loss: 0.1276 - acc: 0.9541\n",
      "Epoch 44/64\n",
      "1198/1198 [==============================] - 1s 664us/step - loss: 0.1293 - acc: 0.9533\n",
      "Epoch 45/64\n",
      "1198/1198 [==============================] - 1s 646us/step - loss: 0.1268 - acc: 0.9574\n",
      "Epoch 46/64\n",
      "1198/1198 [==============================] - 1s 611us/step - loss: 0.1273 - acc: 0.9558\n",
      "Epoch 47/64\n",
      "1198/1198 [==============================] - 1s 606us/step - loss: 0.1242 - acc: 0.9583\n",
      "Epoch 48/64\n",
      "1198/1198 [==============================] - 1s 687us/step - loss: 0.1238 - acc: 0.9524\n",
      "Epoch 49/64\n",
      "1198/1198 [==============================] - 1s 601us/step - loss: 0.1221 - acc: 0.9524\n",
      "Epoch 50/64\n",
      "1198/1198 [==============================] - 1s 606us/step - loss: 0.1207 - acc: 0.9624\n",
      "Epoch 51/64\n",
      "1198/1198 [==============================] - 1s 612us/step - loss: 0.1237 - acc: 0.9524\n",
      "Epoch 52/64\n",
      "1198/1198 [==============================] - 1s 620us/step - loss: 0.1201 - acc: 0.9566\n",
      "Epoch 53/64\n",
      "1198/1198 [==============================] - 1s 637us/step - loss: 0.1204 - acc: 0.9616\n",
      "Epoch 54/64\n",
      "1198/1198 [==============================] - 1s 588us/step - loss: 0.1176 - acc: 0.9599\n",
      "Epoch 55/64\n",
      "1198/1198 [==============================] - 1s 620us/step - loss: 0.1168 - acc: 0.9591\n",
      "Epoch 56/64\n",
      "1198/1198 [==============================] - 1s 636us/step - loss: 0.1148 - acc: 0.9558\n",
      "Epoch 57/64\n",
      "1198/1198 [==============================] - 1s 620us/step - loss: 0.1170 - acc: 0.9558\n",
      "Epoch 58/64\n",
      "1198/1198 [==============================] - 1s 625us/step - loss: 0.1139 - acc: 0.9616\n",
      "Epoch 59/64\n",
      "1198/1198 [==============================] - 1s 614us/step - loss: 0.1100 - acc: 0.9599\n",
      "Epoch 60/64\n",
      "1198/1198 [==============================] - 1s 607us/step - loss: 0.1113 - acc: 0.9633\n",
      "Epoch 61/64\n",
      "1198/1198 [==============================] - 1s 598us/step - loss: 0.1100 - acc: 0.9549\n",
      "Epoch 62/64\n",
      "1198/1198 [==============================] - 1s 602us/step - loss: 0.1083 - acc: 0.9666\n",
      "Epoch 63/64\n",
      "1198/1198 [==============================] - 1s 592us/step - loss: 0.1071 - acc: 0.9633\n",
      "Epoch 64/64\n",
      "1198/1198 [==============================] - 1s 570us/step - loss: 0.1053 - acc: 0.9658\n",
      "299/299 [==============================] - 0s 1ms/step\n",
      "Epoch 1/64\n",
      "1197/1197 [==============================] - 2s 1ms/step - loss: 0.5559 - acc: 0.8647\n",
      "Epoch 2/64\n",
      "1197/1197 [==============================] - 1s 580us/step - loss: 0.3272 - acc: 0.8964\n",
      "Epoch 3/64\n",
      "1197/1197 [==============================] - 1s 600us/step - loss: 0.2514 - acc: 0.9014\n",
      "Epoch 4/64\n",
      "1197/1197 [==============================] - 1s 589us/step - loss: 0.2330 - acc: 0.9006\n",
      "Epoch 5/64\n",
      "1197/1197 [==============================] - 1s 581us/step - loss: 0.2221 - acc: 0.9048\n",
      "Epoch 6/64\n",
      "1197/1197 [==============================] - 1s 598us/step - loss: 0.2187 - acc: 0.9056\n",
      "Epoch 7/64\n",
      "1197/1197 [==============================] - 1s 551us/step - loss: 0.2122 - acc: 0.9073\n",
      "Epoch 8/64\n",
      "1197/1197 [==============================] - 1s 606us/step - loss: 0.2101 - acc: 0.9089\n",
      "Epoch 9/64\n",
      "1197/1197 [==============================] - 1s 599us/step - loss: 0.2075 - acc: 0.9131\n",
      "Epoch 10/64\n",
      "1197/1197 [==============================] - 1s 589us/step - loss: 0.2037 - acc: 0.9165\n",
      "Epoch 11/64\n",
      "1197/1197 [==============================] - 1s 580us/step - loss: 0.2019 - acc: 0.9098\n",
      "Epoch 12/64\n",
      "1197/1197 [==============================] - 1s 599us/step - loss: 0.1968 - acc: 0.9156\n",
      "Epoch 13/64\n",
      "1197/1197 [==============================] - 1s 576us/step - loss: 0.1936 - acc: 0.9215\n",
      "Epoch 14/64\n",
      "1197/1197 [==============================] - 1s 594us/step - loss: 0.1937 - acc: 0.9123\n",
      "Epoch 15/64\n",
      "1197/1197 [==============================] - 1s 573us/step - loss: 0.1919 - acc: 0.9206\n",
      "Epoch 16/64\n",
      "1197/1197 [==============================] - 1s 588us/step - loss: 0.1868 - acc: 0.9198\n",
      "Epoch 17/64\n",
      "1197/1197 [==============================] - 1s 581us/step - loss: 0.1856 - acc: 0.9215\n",
      "Epoch 18/64\n",
      "1197/1197 [==============================] - 1s 599us/step - loss: 0.1813 - acc: 0.9231\n",
      "Epoch 19/64\n",
      "1197/1197 [==============================] - 1s 590us/step - loss: 0.1799 - acc: 0.9223\n",
      "Epoch 20/64\n",
      "1197/1197 [==============================] - 1s 582us/step - loss: 0.1777 - acc: 0.9282\n",
      "Epoch 21/64\n",
      "1197/1197 [==============================] - 1s 675us/step - loss: 0.1752 - acc: 0.9332\n",
      "Epoch 22/64\n",
      "1197/1197 [==============================] - 1s 607us/step - loss: 0.1712 - acc: 0.9265\n",
      "Epoch 23/64\n",
      "1197/1197 [==============================] - 1s 586us/step - loss: 0.1704 - acc: 0.9323\n",
      "Epoch 24/64\n",
      "1197/1197 [==============================] - 1s 588us/step - loss: 0.1690 - acc: 0.9323\n",
      "Epoch 25/64\n",
      "1197/1197 [==============================] - 1s 581us/step - loss: 0.1665 - acc: 0.9332\n",
      "Epoch 26/64\n",
      "1197/1197 [==============================] - 1s 583us/step - loss: 0.1661 - acc: 0.9373\n",
      "Epoch 27/64\n",
      "1197/1197 [==============================] - 1s 590us/step - loss: 0.1624 - acc: 0.9382\n",
      "Epoch 28/64\n",
      "1197/1197 [==============================] - 1s 607us/step - loss: 0.1616 - acc: 0.9390\n",
      "Epoch 29/64\n",
      "1197/1197 [==============================] - 1s 613us/step - loss: 0.1576 - acc: 0.9348\n",
      "Epoch 30/64\n",
      "1197/1197 [==============================] - 1s 698us/step - loss: 0.1574 - acc: 0.9340\n",
      "Epoch 31/64\n",
      "1197/1197 [==============================] - 1s 625us/step - loss: 0.1559 - acc: 0.9415\n",
      "Epoch 32/64\n",
      "1197/1197 [==============================] - 1s 651us/step - loss: 0.1533 - acc: 0.9449\n",
      "Epoch 33/64\n",
      "1197/1197 [==============================] - 1s 645us/step - loss: 0.1507 - acc: 0.9490\n",
      "Epoch 34/64\n",
      "1197/1197 [==============================] - 1s 654us/step - loss: 0.1502 - acc: 0.9457\n",
      "Epoch 35/64\n",
      "1197/1197 [==============================] - 1s 708us/step - loss: 0.1485 - acc: 0.9449\n",
      "Epoch 36/64\n",
      "1197/1197 [==============================] - 1s 659us/step - loss: 0.1462 - acc: 0.9457\n",
      "Epoch 37/64\n",
      "1197/1197 [==============================] - 1s 717us/step - loss: 0.1425 - acc: 0.9465\n",
      "Epoch 38/64\n",
      "1197/1197 [==============================] - 1s 644us/step - loss: 0.1416 - acc: 0.9499\n",
      "Epoch 39/64\n",
      "1197/1197 [==============================] - 1s 730us/step - loss: 0.1421 - acc: 0.9482\n",
      "Epoch 40/64\n",
      "1197/1197 [==============================] - 1s 686us/step - loss: 0.1410 - acc: 0.9490\n",
      "Epoch 41/64\n",
      "1197/1197 [==============================] - 1s 663us/step - loss: 0.1369 - acc: 0.9507\n",
      "Epoch 42/64\n",
      "1197/1197 [==============================] - 1s 691us/step - loss: 0.1357 - acc: 0.9557\n",
      "Epoch 43/64\n",
      "1197/1197 [==============================] - 1s 684us/step - loss: 0.1336 - acc: 0.9474\n",
      "Epoch 44/64\n",
      "1197/1197 [==============================] - 1s 669us/step - loss: 0.1355 - acc: 0.9524\n",
      "Epoch 45/64\n",
      "1197/1197 [==============================] - 1s 695us/step - loss: 0.1315 - acc: 0.9515\n",
      "Epoch 46/64\n",
      "1197/1197 [==============================] - 1s 666us/step - loss: 0.1313 - acc: 0.9524\n",
      "Epoch 47/64\n",
      "1197/1197 [==============================] - 1s 710us/step - loss: 0.1284 - acc: 0.9549\n",
      "Epoch 48/64\n",
      "1197/1197 [==============================] - 1s 678us/step - loss: 0.1296 - acc: 0.9582\n",
      "Epoch 49/64\n",
      "1197/1197 [==============================] - 1s 761us/step - loss: 0.1255 - acc: 0.9582\n",
      "Epoch 50/64\n",
      "1197/1197 [==============================] - 1s 815us/step - loss: 0.1241 - acc: 0.9557\n",
      "Epoch 51/64\n",
      "1197/1197 [==============================] - 1s 774us/step - loss: 0.1256 - acc: 0.9582\n",
      "Epoch 52/64\n",
      "1197/1197 [==============================] - 1s 831us/step - loss: 0.1196 - acc: 0.9574\n",
      "Epoch 53/64\n",
      "1197/1197 [==============================] - 1s 786us/step - loss: 0.1210 - acc: 0.9557\n",
      "Epoch 54/64\n",
      "1197/1197 [==============================] - 1s 787us/step - loss: 0.1174 - acc: 0.9599\n",
      "Epoch 55/64\n",
      "1197/1197 [==============================] - 1s 804us/step - loss: 0.1183 - acc: 0.9582\n",
      "Epoch 56/64\n",
      "1197/1197 [==============================] - 1s 799us/step - loss: 0.1160 - acc: 0.9591\n",
      "Epoch 57/64\n",
      "1197/1197 [==============================] - 1s 767us/step - loss: 0.1149 - acc: 0.9591\n",
      "Epoch 58/64\n",
      "1197/1197 [==============================] - 1s 748us/step - loss: 0.1121 - acc: 0.9582\n",
      "Epoch 59/64\n",
      "1197/1197 [==============================] - 1s 877us/step - loss: 0.1107 - acc: 0.9566\n",
      "Epoch 60/64\n",
      "1197/1197 [==============================] - 1s 789us/step - loss: 0.1096 - acc: 0.9632\n",
      "Epoch 61/64\n",
      "1197/1197 [==============================] - 1s 787us/step - loss: 0.1116 - acc: 0.9591\n",
      "Epoch 62/64\n",
      "1197/1197 [==============================] - 1s 842us/step - loss: 0.1077 - acc: 0.9641\n",
      "Epoch 63/64\n",
      "1197/1197 [==============================] - 1s 776us/step - loss: 0.1054 - acc: 0.9591\n",
      "Epoch 64/64\n",
      "1197/1197 [==============================] - 1s 812us/step - loss: 0.1049 - acc: 0.9649\n",
      "300/300 [==============================] - 1s 2ms/step\n",
      "Epoch 1/64\n",
      "1197/1197 [==============================] - 2s 2ms/step - loss: 0.4993 - acc: 0.8739\n",
      "Epoch 2/64\n",
      "1197/1197 [==============================] - 1s 747us/step - loss: 0.2680 - acc: 0.9039\n",
      "Epoch 3/64\n",
      "1197/1197 [==============================] - 1s 816us/step - loss: 0.2264 - acc: 0.9048\n",
      "Epoch 4/64\n",
      "1197/1197 [==============================] - 1s 762us/step - loss: 0.2137 - acc: 0.9106\n",
      "Epoch 5/64\n",
      "1197/1197 [==============================] - 1s 792us/step - loss: 0.2102 - acc: 0.9148\n",
      "Epoch 6/64\n",
      "1197/1197 [==============================] - 1s 785us/step - loss: 0.2050 - acc: 0.9173\n",
      "Epoch 7/64\n",
      "1197/1197 [==============================] - 1s 777us/step - loss: 0.2033 - acc: 0.9173\n",
      "Epoch 8/64\n",
      "1197/1197 [==============================] - 1s 764us/step - loss: 0.1994 - acc: 0.9215\n",
      "Epoch 9/64\n",
      "1197/1197 [==============================] - 1s 762us/step - loss: 0.1974 - acc: 0.9240\n",
      "Epoch 10/64\n",
      "1197/1197 [==============================] - 1s 800us/step - loss: 0.1955 - acc: 0.9240\n",
      "Epoch 11/64\n",
      "1197/1197 [==============================] - 1s 944us/step - loss: 0.1922 - acc: 0.9256\n",
      "Epoch 12/64\n",
      "1197/1197 [==============================] - 1s 956us/step - loss: 0.1928 - acc: 0.9256\n",
      "Epoch 13/64\n",
      "1197/1197 [==============================] - 1s 903us/step - loss: 0.1888 - acc: 0.9282\n",
      "Epoch 14/64\n",
      "1197/1197 [==============================] - 1s 811us/step - loss: 0.1893 - acc: 0.9265\n",
      "Epoch 15/64\n",
      "1197/1197 [==============================] - 1s 839us/step - loss: 0.1851 - acc: 0.9282 0s - loss: 0.1945 - acc: 0.9\n",
      "Epoch 16/64\n",
      "1197/1197 [==============================] - 1s 800us/step - loss: 0.1849 - acc: 0.9315\n",
      "Epoch 17/64\n",
      "1197/1197 [==============================] - 1s 789us/step - loss: 0.1827 - acc: 0.9315\n",
      "Epoch 18/64\n",
      "1197/1197 [==============================] - 1s 792us/step - loss: 0.1822 - acc: 0.9273\n",
      "Epoch 19/64\n",
      "1197/1197 [==============================] - 1s 813us/step - loss: 0.1805 - acc: 0.9298\n",
      "Epoch 20/64\n",
      "1197/1197 [==============================] - 1s 786us/step - loss: 0.1801 - acc: 0.9323\n",
      "Epoch 21/64\n",
      "1197/1197 [==============================] - 1s 800us/step - loss: 0.1787 - acc: 0.9290\n",
      "Epoch 22/64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1197/1197 [==============================] - 1s 763us/step - loss: 0.1755 - acc: 0.9348\n",
      "Epoch 23/64\n",
      "1197/1197 [==============================] - 1s 742us/step - loss: 0.1746 - acc: 0.9348\n",
      "Epoch 24/64\n",
      "1197/1197 [==============================] - 1s 787us/step - loss: 0.1740 - acc: 0.9323\n",
      "Epoch 25/64\n",
      "1197/1197 [==============================] - 1s 812us/step - loss: 0.1723 - acc: 0.9340\n",
      "Epoch 26/64\n",
      "1197/1197 [==============================] - 1s 709us/step - loss: 0.1710 - acc: 0.9323\n",
      "Epoch 27/64\n",
      "1197/1197 [==============================] - 1s 730us/step - loss: 0.1689 - acc: 0.9323\n",
      "Epoch 28/64\n",
      "1197/1197 [==============================] - 1s 753us/step - loss: 0.1655 - acc: 0.9390\n",
      "Epoch 29/64\n",
      "1197/1197 [==============================] - 1s 757us/step - loss: 0.1645 - acc: 0.9390\n",
      "Epoch 30/64\n",
      "1197/1197 [==============================] - 1s 742us/step - loss: 0.1628 - acc: 0.9390\n",
      "Epoch 31/64\n",
      "1197/1197 [==============================] - 1s 799us/step - loss: 0.1621 - acc: 0.9382\n",
      "Epoch 32/64\n",
      "1197/1197 [==============================] - 1s 792us/step - loss: 0.1607 - acc: 0.9407\n",
      "Epoch 33/64\n",
      "1197/1197 [==============================] - 1s 743us/step - loss: 0.1566 - acc: 0.9424\n",
      "Epoch 34/64\n",
      "1197/1197 [==============================] - 1s 741us/step - loss: 0.1572 - acc: 0.9449\n",
      "Epoch 35/64\n",
      "1197/1197 [==============================] - 1s 761us/step - loss: 0.1561 - acc: 0.9432\n",
      "Epoch 36/64\n",
      "1197/1197 [==============================] - 1s 764us/step - loss: 0.1540 - acc: 0.9398\n",
      "Epoch 37/64\n",
      "1197/1197 [==============================] - 1s 742us/step - loss: 0.1532 - acc: 0.9440\n",
      "Epoch 38/64\n",
      "1197/1197 [==============================] - 1s 760us/step - loss: 0.1510 - acc: 0.9449\n",
      "Epoch 39/64\n",
      "1197/1197 [==============================] - 1s 750us/step - loss: 0.1506 - acc: 0.9415\n",
      "Epoch 40/64\n",
      "1197/1197 [==============================] - 1s 760us/step - loss: 0.1484 - acc: 0.9457\n",
      "Epoch 41/64\n",
      "1197/1197 [==============================] - 1s 754us/step - loss: 0.1475 - acc: 0.9432\n",
      "Epoch 42/64\n",
      "1197/1197 [==============================] - 1s 747us/step - loss: 0.1481 - acc: 0.9432\n",
      "Epoch 43/64\n",
      "1197/1197 [==============================] - 1s 763us/step - loss: 0.1466 - acc: 0.9457\n",
      "Epoch 44/64\n",
      "1197/1197 [==============================] - 1s 794us/step - loss: 0.1453 - acc: 0.9465\n",
      "Epoch 45/64\n",
      "1197/1197 [==============================] - 1s 774us/step - loss: 0.1426 - acc: 0.9432\n",
      "Epoch 46/64\n",
      "1197/1197 [==============================] - 1s 760us/step - loss: 0.1414 - acc: 0.9457\n",
      "Epoch 47/64\n",
      "1197/1197 [==============================] - 1s 737us/step - loss: 0.1399 - acc: 0.9499\n",
      "Epoch 48/64\n",
      "1197/1197 [==============================] - 1s 743us/step - loss: 0.1422 - acc: 0.9482\n",
      "Epoch 49/64\n",
      "1197/1197 [==============================] - 1s 773us/step - loss: 0.1405 - acc: 0.9490\n",
      "Epoch 50/64\n",
      "1197/1197 [==============================] - 1s 751us/step - loss: 0.1362 - acc: 0.9465\n",
      "Epoch 51/64\n",
      "1197/1197 [==============================] - 1s 768us/step - loss: 0.1394 - acc: 0.9465\n",
      "Epoch 52/64\n",
      "1197/1197 [==============================] - 1s 773us/step - loss: 0.1377 - acc: 0.9482\n",
      "Epoch 53/64\n",
      "1197/1197 [==============================] - 1s 734us/step - loss: 0.1306 - acc: 0.9515\n",
      "Epoch 54/64\n",
      "1197/1197 [==============================] - 1s 777us/step - loss: 0.1372 - acc: 0.9465\n",
      "Epoch 55/64\n",
      "1197/1197 [==============================] - 1s 770us/step - loss: 0.1345 - acc: 0.9490\n",
      "Epoch 56/64\n",
      "1197/1197 [==============================] - 1s 785us/step - loss: 0.1327 - acc: 0.9515\n",
      "Epoch 57/64\n",
      "1197/1197 [==============================] - 1s 787us/step - loss: 0.1322 - acc: 0.9515\n",
      "Epoch 58/64\n",
      "1197/1197 [==============================] - 1s 776us/step - loss: 0.1328 - acc: 0.9474\n",
      "Epoch 59/64\n",
      "1197/1197 [==============================] - 1s 838us/step - loss: 0.1311 - acc: 0.9499\n",
      "Epoch 60/64\n",
      "1197/1197 [==============================] - 1s 769us/step - loss: 0.1314 - acc: 0.9499\n",
      "Epoch 61/64\n",
      "1197/1197 [==============================] - 1s 772us/step - loss: 0.1300 - acc: 0.9532\n",
      "Epoch 62/64\n",
      "1197/1197 [==============================] - 1s 751us/step - loss: 0.1281 - acc: 0.9566\n",
      "Epoch 63/64\n",
      "1197/1197 [==============================] - 1s 777us/step - loss: 0.1278 - acc: 0.9524\n",
      "Epoch 64/64\n",
      "1197/1197 [==============================] - 1s 750us/step - loss: 0.1263 - acc: 0.9566\n",
      "300/300 [==============================] - 1s 2ms/step\n",
      "Epoch 1/64\n",
      "1198/1198 [==============================] - 2s 2ms/step - loss: 0.4786 - acc: 0.8706\n",
      "Epoch 2/64\n",
      "1198/1198 [==============================] - 1s 773us/step - loss: 0.2633 - acc: 0.9007\n",
      "Epoch 3/64\n",
      "1198/1198 [==============================] - 1s 763us/step - loss: 0.2273 - acc: 0.9048\n",
      "Epoch 4/64\n",
      "1198/1198 [==============================] - 1s 798us/step - loss: 0.2166 - acc: 0.9132\n",
      "Epoch 5/64\n",
      "1198/1198 [==============================] - 1s 821us/step - loss: 0.2107 - acc: 0.9132\n",
      "Epoch 6/64\n",
      "1198/1198 [==============================] - 1s 811us/step - loss: 0.2037 - acc: 0.9174\n",
      "Epoch 7/64\n",
      "1198/1198 [==============================] - 1s 799us/step - loss: 0.1990 - acc: 0.9240\n",
      "Epoch 8/64\n",
      "1198/1198 [==============================] - 1s 749us/step - loss: 0.1936 - acc: 0.9215\n",
      "Epoch 9/64\n",
      "1198/1198 [==============================] - 1s 770us/step - loss: 0.1906 - acc: 0.9274\n",
      "Epoch 10/64\n",
      "1198/1198 [==============================] - 1s 785us/step - loss: 0.1867 - acc: 0.9290\n",
      "Epoch 11/64\n",
      "1198/1198 [==============================] - 1s 796us/step - loss: 0.1827 - acc: 0.9299\n",
      "Epoch 12/64\n",
      "1198/1198 [==============================] - 1s 812us/step - loss: 0.1795 - acc: 0.9357\n",
      "Epoch 13/64\n",
      "1198/1198 [==============================] - 1s 843us/step - loss: 0.1774 - acc: 0.9332\n",
      "Epoch 14/64\n",
      "1198/1198 [==============================] - 1s 808us/step - loss: 0.1733 - acc: 0.9349\n",
      "Epoch 15/64\n",
      "1198/1198 [==============================] - 1s 864us/step - loss: 0.1737 - acc: 0.9349\n",
      "Epoch 16/64\n",
      "1198/1198 [==============================] - 1s 782us/step - loss: 0.1725 - acc: 0.9349 0s - loss: 0.1580 - ac\n",
      "Epoch 17/64\n",
      "1198/1198 [==============================] - 1s 746us/step - loss: 0.1684 - acc: 0.9374\n",
      "Epoch 18/64\n",
      "1198/1198 [==============================] - 1s 697us/step - loss: 0.1674 - acc: 0.9441\n",
      "Epoch 19/64\n",
      "1198/1198 [==============================] - 1s 704us/step - loss: 0.1660 - acc: 0.9407\n",
      "Epoch 20/64\n",
      "1198/1198 [==============================] - 1s 720us/step - loss: 0.1643 - acc: 0.9399\n",
      "Epoch 21/64\n",
      "1198/1198 [==============================] - 1s 713us/step - loss: 0.1625 - acc: 0.9416\n",
      "Epoch 22/64\n",
      "1198/1198 [==============================] - 1s 700us/step - loss: 0.1600 - acc: 0.9416\n",
      "Epoch 23/64\n",
      "1198/1198 [==============================] - 1s 722us/step - loss: 0.1590 - acc: 0.9457\n",
      "Epoch 24/64\n",
      "1198/1198 [==============================] - 1s 690us/step - loss: 0.1587 - acc: 0.9474\n",
      "Epoch 25/64\n",
      "1198/1198 [==============================] - 1s 708us/step - loss: 0.1573 - acc: 0.9474\n",
      "Epoch 26/64\n",
      "1198/1198 [==============================] - 1s 801us/step - loss: 0.1538 - acc: 0.9449\n",
      "Epoch 27/64\n",
      "1198/1198 [==============================] - 1s 748us/step - loss: 0.1544 - acc: 0.9499\n",
      "Epoch 28/64\n",
      "1198/1198 [==============================] - 1s 700us/step - loss: 0.1520 - acc: 0.9491\n",
      "Epoch 29/64\n",
      "1198/1198 [==============================] - 1s 684us/step - loss: 0.1530 - acc: 0.9491\n",
      "Epoch 30/64\n",
      "1198/1198 [==============================] - 1s 676us/step - loss: 0.1507 - acc: 0.9499\n",
      "Epoch 31/64\n",
      "1198/1198 [==============================] - 1s 646us/step - loss: 0.1499 - acc: 0.9499\n",
      "Epoch 32/64\n",
      "1198/1198 [==============================] - 1s 688us/step - loss: 0.1466 - acc: 0.9482\n",
      "Epoch 33/64\n",
      "1198/1198 [==============================] - 1s 732us/step - loss: 0.1449 - acc: 0.9516\n",
      "Epoch 34/64\n",
      "1198/1198 [==============================] - 1s 681us/step - loss: 0.1452 - acc: 0.9516\n",
      "Epoch 35/64\n",
      "1198/1198 [==============================] - 1s 720us/step - loss: 0.1434 - acc: 0.9533\n",
      "Epoch 36/64\n",
      "1198/1198 [==============================] - 1s 685us/step - loss: 0.1428 - acc: 0.9524\n",
      "Epoch 37/64\n",
      "1198/1198 [==============================] - 1s 690us/step - loss: 0.1423 - acc: 0.9549\n",
      "Epoch 38/64\n",
      "1198/1198 [==============================] - 1s 710us/step - loss: 0.1402 - acc: 0.9533\n",
      "Epoch 39/64\n",
      "1198/1198 [==============================] - 1s 676us/step - loss: 0.1389 - acc: 0.9541\n",
      "Epoch 40/64\n",
      "1198/1198 [==============================] - 1s 838us/step - loss: 0.1382 - acc: 0.9524\n",
      "Epoch 41/64\n",
      "1198/1198 [==============================] - 1s 672us/step - loss: 0.1385 - acc: 0.9524\n",
      "Epoch 42/64\n",
      "1198/1198 [==============================] - 1s 675us/step - loss: 0.1378 - acc: 0.9533\n",
      "Epoch 43/64\n",
      "1198/1198 [==============================] - 1s 673us/step - loss: 0.1372 - acc: 0.9524\n",
      "Epoch 44/64\n",
      "1198/1198 [==============================] - 1s 676us/step - loss: 0.1352 - acc: 0.9566\n",
      "Epoch 45/64\n",
      "1198/1198 [==============================] - 1s 688us/step - loss: 0.1341 - acc: 0.9574\n",
      "Epoch 46/64\n",
      "1198/1198 [==============================] - 1s 672us/step - loss: 0.1319 - acc: 0.9591\n",
      "Epoch 47/64\n",
      "1198/1198 [==============================] - 1s 670us/step - loss: 0.1310 - acc: 0.9549\n",
      "Epoch 48/64\n",
      "1198/1198 [==============================] - 1s 675us/step - loss: 0.1295 - acc: 0.9566\n",
      "Epoch 49/64\n",
      "1198/1198 [==============================] - 1s 669us/step - loss: 0.1284 - acc: 0.9566\n",
      "Epoch 50/64\n",
      "1198/1198 [==============================] - 1s 694us/step - loss: 0.1274 - acc: 0.9616\n",
      "Epoch 51/64\n",
      "1198/1198 [==============================] - 1s 691us/step - loss: 0.1276 - acc: 0.9599\n",
      "Epoch 52/64\n",
      "1198/1198 [==============================] - 1s 672us/step - loss: 0.1253 - acc: 0.9574\n",
      "Epoch 53/64\n",
      "1198/1198 [==============================] - 1s 651us/step - loss: 0.1232 - acc: 0.9624\n",
      "Epoch 54/64\n",
      "1198/1198 [==============================] - 1s 671us/step - loss: 0.1209 - acc: 0.9633\n",
      "Epoch 55/64\n",
      "1198/1198 [==============================] - 1s 768us/step - loss: 0.1211 - acc: 0.9624\n",
      "Epoch 56/64\n",
      "1198/1198 [==============================] - 1s 681us/step - loss: 0.1194 - acc: 0.9616\n",
      "Epoch 57/64\n",
      "1198/1198 [==============================] - 1s 652us/step - loss: 0.1185 - acc: 0.9583\n",
      "Epoch 58/64\n",
      "1198/1198 [==============================] - 1s 673us/step - loss: 0.1179 - acc: 0.9616\n",
      "Epoch 59/64\n",
      "1198/1198 [==============================] - 1s 672us/step - loss: 0.1165 - acc: 0.9624\n",
      "Epoch 60/64\n",
      "1198/1198 [==============================] - 1s 647us/step - loss: 0.1149 - acc: 0.9649\n",
      "Epoch 61/64\n",
      "1198/1198 [==============================] - 1s 635us/step - loss: 0.1150 - acc: 0.9649\n",
      "Epoch 62/64\n",
      "1198/1198 [==============================] - 1s 684us/step - loss: 0.1140 - acc: 0.9658\n",
      "Epoch 63/64\n",
      "1198/1198 [==============================] - 1s 677us/step - loss: 0.1134 - acc: 0.9658\n",
      "Epoch 64/64\n",
      "1198/1198 [==============================] - 1s 743us/step - loss: 0.1101 - acc: 0.9649\n",
      "299/299 [==============================] - 0s 2ms/step\n",
      "Epoch 1/64\n",
      "1198/1198 [==============================] - 2s 2ms/step - loss: 0.4763 - acc: 0.8539\n",
      "Epoch 2/64\n",
      "1198/1198 [==============================] - 1s 683us/step - loss: 0.2760 - acc: 0.8948\n",
      "Epoch 3/64\n",
      "1198/1198 [==============================] - 1s 651us/step - loss: 0.2449 - acc: 0.8998\n",
      "Epoch 4/64\n",
      "1198/1198 [==============================] - 1s 659us/step - loss: 0.2327 - acc: 0.9040\n",
      "Epoch 5/64\n",
      "1198/1198 [==============================] - 1s 702us/step - loss: 0.2247 - acc: 0.9098\n",
      "Epoch 6/64\n",
      "1198/1198 [==============================] - 1s 682us/step - loss: 0.2187 - acc: 0.9140\n",
      "Epoch 7/64\n",
      "1198/1198 [==============================] - 1s 680us/step - loss: 0.2161 - acc: 0.9149\n",
      "Epoch 8/64\n",
      "1198/1198 [==============================] - 1s 668us/step - loss: 0.2111 - acc: 0.9149\n",
      "Epoch 9/64\n",
      "1198/1198 [==============================] - 1s 669us/step - loss: 0.2088 - acc: 0.9182\n",
      "Epoch 10/64\n",
      "1198/1198 [==============================] - 1s 664us/step - loss: 0.2057 - acc: 0.9199\n",
      "Epoch 11/64\n",
      "1198/1198 [==============================] - 1s 677us/step - loss: 0.2019 - acc: 0.9224\n",
      "Epoch 12/64\n",
      "1198/1198 [==============================] - 1s 683us/step - loss: 0.1991 - acc: 0.9224\n",
      "Epoch 13/64\n",
      "1198/1198 [==============================] - 1s 685us/step - loss: 0.1984 - acc: 0.9232\n",
      "Epoch 14/64\n",
      "1198/1198 [==============================] - 1s 703us/step - loss: 0.1915 - acc: 0.9232\n",
      "Epoch 15/64\n",
      "1198/1198 [==============================] - 1s 746us/step - loss: 0.1925 - acc: 0.9257\n",
      "Epoch 16/64\n",
      "1198/1198 [==============================] - 1s 731us/step - loss: 0.1886 - acc: 0.9249\n",
      "Epoch 17/64\n",
      "1198/1198 [==============================] - 1s 721us/step - loss: 0.1861 - acc: 0.9274\n",
      "Epoch 18/64\n",
      "1198/1198 [==============================] - 1s 724us/step - loss: 0.1849 - acc: 0.9324\n",
      "Epoch 19/64\n",
      "1198/1198 [==============================] - 1s 688us/step - loss: 0.1835 - acc: 0.9274\n",
      "Epoch 20/64\n",
      "1198/1198 [==============================] - 1s 799us/step - loss: 0.1816 - acc: 0.9265\n",
      "Epoch 21/64\n",
      "1198/1198 [==============================] - 1s 798us/step - loss: 0.1761 - acc: 0.9341\n",
      "Epoch 22/64\n",
      "1198/1198 [==============================] - 1s 684us/step - loss: 0.1767 - acc: 0.9307\n",
      "Epoch 23/64\n",
      "1198/1198 [==============================] - 1s 677us/step - loss: 0.1760 - acc: 0.9357\n",
      "Epoch 24/64\n",
      "1198/1198 [==============================] - 1s 671us/step - loss: 0.1719 - acc: 0.9341\n",
      "Epoch 25/64\n",
      "1198/1198 [==============================] - 1s 677us/step - loss: 0.1722 - acc: 0.9366\n",
      "Epoch 26/64\n",
      "1198/1198 [==============================] - 1s 671us/step - loss: 0.1680 - acc: 0.9341\n",
      "Epoch 27/64\n",
      "1198/1198 [==============================] - 1s 690us/step - loss: 0.1676 - acc: 0.9382\n",
      "Epoch 28/64\n",
      "1198/1198 [==============================] - 1s 696us/step - loss: 0.1663 - acc: 0.9382\n",
      "Epoch 29/64\n",
      "1198/1198 [==============================] - 1s 664us/step - loss: 0.1620 - acc: 0.9424\n",
      "Epoch 30/64\n",
      "1198/1198 [==============================] - 1s 707us/step - loss: 0.1612 - acc: 0.9424\n",
      "Epoch 31/64\n",
      "1198/1198 [==============================] - 1s 698us/step - loss: 0.1590 - acc: 0.9441\n",
      "Epoch 32/64\n",
      "1198/1198 [==============================] - 1s 650us/step - loss: 0.1552 - acc: 0.9407\n",
      "Epoch 33/64\n",
      "1198/1198 [==============================] - 1s 724us/step - loss: 0.1556 - acc: 0.9399\n",
      "Epoch 34/64\n",
      "1198/1198 [==============================] - 1s 768us/step - loss: 0.1544 - acc: 0.9416\n",
      "Epoch 35/64\n",
      "1198/1198 [==============================] - 1s 720us/step - loss: 0.1518 - acc: 0.9424\n",
      "Epoch 36/64\n",
      "1198/1198 [==============================] - 1s 698us/step - loss: 0.1511 - acc: 0.9449\n",
      "Epoch 37/64\n",
      "1198/1198 [==============================] - 1s 729us/step - loss: 0.1477 - acc: 0.9457\n",
      "Epoch 38/64\n",
      "1198/1198 [==============================] - 1s 707us/step - loss: 0.1474 - acc: 0.9474\n",
      "Epoch 39/64\n",
      "1198/1198 [==============================] - 1s 719us/step - loss: 0.1458 - acc: 0.9449\n",
      "Epoch 40/64\n",
      "1198/1198 [==============================] - 1s 692us/step - loss: 0.1424 - acc: 0.9466\n",
      "Epoch 41/64\n",
      "1198/1198 [==============================] - 1s 738us/step - loss: 0.1425 - acc: 0.9474\n",
      "Epoch 42/64\n",
      "1198/1198 [==============================] - 1s 689us/step - loss: 0.1426 - acc: 0.9499\n",
      "Epoch 43/64\n",
      "1198/1198 [==============================] - 1s 694us/step - loss: 0.1373 - acc: 0.9516\n",
      "Epoch 44/64\n",
      "1198/1198 [==============================] - 1s 711us/step - loss: 0.1369 - acc: 0.9541\n",
      "Epoch 45/64\n",
      "1198/1198 [==============================] - 1s 742us/step - loss: 0.1353 - acc: 0.9566\n",
      "Epoch 46/64\n",
      "1198/1198 [==============================] - 1s 723us/step - loss: 0.1357 - acc: 0.9541\n",
      "Epoch 47/64\n",
      "1198/1198 [==============================] - 1s 688us/step - loss: 0.1341 - acc: 0.9491\n",
      "Epoch 48/64\n",
      "1198/1198 [==============================] - 1s 707us/step - loss: 0.1327 - acc: 0.9533 0s - loss: 0.1057 - \n",
      "Epoch 49/64\n",
      "1198/1198 [==============================] - 1s 686us/step - loss: 0.1301 - acc: 0.9549\n",
      "Epoch 50/64\n",
      "1198/1198 [==============================] - 1s 677us/step - loss: 0.1281 - acc: 0.9558\n",
      "Epoch 51/64\n",
      "1198/1198 [==============================] - 1s 682us/step - loss: 0.1251 - acc: 0.9558\n",
      "Epoch 52/64\n",
      "1198/1198 [==============================] - 1s 689us/step - loss: 0.1250 - acc: 0.9574\n",
      "Epoch 53/64\n",
      "1198/1198 [==============================] - 1s 698us/step - loss: 0.1244 - acc: 0.9558\n",
      "Epoch 54/64\n",
      "1198/1198 [==============================] - 1s 729us/step - loss: 0.1210 - acc: 0.9599\n",
      "Epoch 55/64\n",
      "1198/1198 [==============================] - 1s 733us/step - loss: 0.1203 - acc: 0.9599\n",
      "Epoch 56/64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1198/1198 [==============================] - 1s 737us/step - loss: 0.1204 - acc: 0.9566 0s - loss: 0.1118 - acc: 0.9\n",
      "Epoch 57/64\n",
      "1198/1198 [==============================] - 1s 703us/step - loss: 0.1188 - acc: 0.9599\n",
      "Epoch 58/64\n",
      "1198/1198 [==============================] - 1s 707us/step - loss: 0.1188 - acc: 0.9574\n",
      "Epoch 59/64\n",
      "1198/1198 [==============================] - 1s 682us/step - loss: 0.1181 - acc: 0.9574\n",
      "Epoch 60/64\n",
      "1198/1198 [==============================] - 1s 690us/step - loss: 0.1139 - acc: 0.9616\n",
      "Epoch 61/64\n",
      "1198/1198 [==============================] - 1s 686us/step - loss: 0.1162 - acc: 0.9574\n",
      "Epoch 62/64\n",
      "1198/1198 [==============================] - 1s 688us/step - loss: 0.1138 - acc: 0.9583\n",
      "Epoch 63/64\n",
      "1198/1198 [==============================] - 1s 698us/step - loss: 0.1127 - acc: 0.9616\n",
      "Epoch 64/64\n",
      "1198/1198 [==============================] - 1s 702us/step - loss: 0.1132 - acc: 0.9608\n",
      "299/299 [==============================] - 1s 2ms/step\n",
      "Epoch 1/64\n",
      "1198/1198 [==============================] - 2s 2ms/step - loss: 0.5962 - acc: 0.8372\n",
      "Epoch 2/64\n",
      "1198/1198 [==============================] - 1s 676us/step - loss: 0.3358 - acc: 0.8973\n",
      "Epoch 3/64\n",
      "1198/1198 [==============================] - 1s 696us/step - loss: 0.2427 - acc: 0.9032\n",
      "Epoch 4/64\n",
      "1198/1198 [==============================] - 1s 678us/step - loss: 0.2267 - acc: 0.9124\n",
      "Epoch 5/64\n",
      "1198/1198 [==============================] - 1s 746us/step - loss: 0.2201 - acc: 0.9149\n",
      "Epoch 6/64\n",
      "1198/1198 [==============================] - 1s 723us/step - loss: 0.2151 - acc: 0.9157\n",
      "Epoch 7/64\n",
      "1198/1198 [==============================] - 1s 838us/step - loss: 0.2126 - acc: 0.9190\n",
      "Epoch 8/64\n",
      "1198/1198 [==============================] - 1s 689us/step - loss: 0.2086 - acc: 0.9182\n",
      "Epoch 9/64\n",
      "1198/1198 [==============================] - 1s 685us/step - loss: 0.2072 - acc: 0.9207 0s - loss: 0.2134 - acc\n",
      "Epoch 10/64\n",
      "1198/1198 [==============================] - 1s 716us/step - loss: 0.2012 - acc: 0.9207\n",
      "Epoch 11/64\n",
      "1198/1198 [==============================] - 1s 706us/step - loss: 0.2037 - acc: 0.9257\n",
      "Epoch 12/64\n",
      "1198/1198 [==============================] - 1s 699us/step - loss: 0.1989 - acc: 0.9232\n",
      "Epoch 13/64\n",
      "1198/1198 [==============================] - 1s 703us/step - loss: 0.1947 - acc: 0.9232\n",
      "Epoch 14/64\n",
      "1198/1198 [==============================] - 1s 711us/step - loss: 0.1948 - acc: 0.9274\n",
      "Epoch 15/64\n",
      "1198/1198 [==============================] - 1s 715us/step - loss: 0.1924 - acc: 0.9282 0s - loss: 0.1744 - acc\n",
      "Epoch 16/64\n",
      "1198/1198 [==============================] - 1s 707us/step - loss: 0.1889 - acc: 0.9299\n",
      "Epoch 17/64\n",
      "1198/1198 [==============================] - 1s 699us/step - loss: 0.1875 - acc: 0.9274\n",
      "Epoch 18/64\n",
      "1198/1198 [==============================] - 1s 702us/step - loss: 0.1844 - acc: 0.9290\n",
      "Epoch 19/64\n",
      "1198/1198 [==============================] - 1s 698us/step - loss: 0.1830 - acc: 0.9324\n",
      "Epoch 20/64\n",
      "1198/1198 [==============================] - 1s 838us/step - loss: 0.1818 - acc: 0.9349\n",
      "Epoch 21/64\n",
      "1198/1198 [==============================] - 1s 768us/step - loss: 0.1785 - acc: 0.9374\n",
      "Epoch 22/64\n",
      "1198/1198 [==============================] - 1s 721us/step - loss: 0.1765 - acc: 0.9374\n",
      "Epoch 23/64\n",
      "1198/1198 [==============================] - 1s 737us/step - loss: 0.1735 - acc: 0.9332\n",
      "Epoch 24/64\n",
      "1198/1198 [==============================] - 1s 702us/step - loss: 0.1733 - acc: 0.9349\n",
      "Epoch 25/64\n",
      "1198/1198 [==============================] - 1s 693us/step - loss: 0.1717 - acc: 0.9391\n",
      "Epoch 26/64\n",
      "1198/1198 [==============================] - 1s 680us/step - loss: 0.1688 - acc: 0.9374\n",
      "Epoch 27/64\n",
      "1198/1198 [==============================] - 1s 681us/step - loss: 0.1666 - acc: 0.9341\n",
      "Epoch 28/64\n",
      "1198/1198 [==============================] - 1s 697us/step - loss: 0.1666 - acc: 0.9399\n",
      "Epoch 29/64\n",
      "1198/1198 [==============================] - 1s 717us/step - loss: 0.1644 - acc: 0.9416\n",
      "Epoch 30/64\n",
      "1198/1198 [==============================] - 1s 697us/step - loss: 0.1633 - acc: 0.9416\n",
      "Epoch 31/64\n",
      "1198/1198 [==============================] - 1s 715us/step - loss: 0.1611 - acc: 0.9424\n",
      "Epoch 32/64\n",
      "1198/1198 [==============================] - 1s 695us/step - loss: 0.1601 - acc: 0.9382\n",
      "Epoch 33/64\n",
      "1198/1198 [==============================] - 1s 736us/step - loss: 0.1570 - acc: 0.9424\n",
      "Epoch 34/64\n",
      "1198/1198 [==============================] - 1s 702us/step - loss: 0.1582 - acc: 0.9382\n",
      "Epoch 35/64\n",
      "1198/1198 [==============================] - 1s 726us/step - loss: 0.1549 - acc: 0.9382\n",
      "Epoch 36/64\n",
      "1198/1198 [==============================] - 1s 737us/step - loss: 0.1531 - acc: 0.9416\n",
      "Epoch 37/64\n",
      "1198/1198 [==============================] - 1s 707us/step - loss: 0.1508 - acc: 0.9399\n",
      "Epoch 38/64\n",
      "1198/1198 [==============================] - 1s 697us/step - loss: 0.1506 - acc: 0.9416\n",
      "Epoch 39/64\n",
      "1198/1198 [==============================] - 1s 742us/step - loss: 0.1487 - acc: 0.9466\n",
      "Epoch 40/64\n",
      "1198/1198 [==============================] - 1s 721us/step - loss: 0.1481 - acc: 0.9449\n",
      "Epoch 41/64\n",
      "1198/1198 [==============================] - 1s 994us/step - loss: 0.1455 - acc: 0.9457\n",
      "Epoch 42/64\n",
      "1198/1198 [==============================] - 1s 734us/step - loss: 0.1459 - acc: 0.9457\n",
      "Epoch 43/64\n",
      "1198/1198 [==============================] - 1s 724us/step - loss: 0.1421 - acc: 0.9499\n",
      "Epoch 44/64\n",
      "1198/1198 [==============================] - 1s 717us/step - loss: 0.1412 - acc: 0.9474\n",
      "Epoch 45/64\n",
      "1198/1198 [==============================] - 1s 759us/step - loss: 0.1412 - acc: 0.9508\n",
      "Epoch 46/64\n",
      "1198/1198 [==============================] - 1s 717us/step - loss: 0.1377 - acc: 0.9474\n",
      "Epoch 47/64\n",
      "1198/1198 [==============================] - 1s 734us/step - loss: 0.1380 - acc: 0.9508\n",
      "Epoch 48/64\n",
      "1198/1198 [==============================] - 1s 710us/step - loss: 0.1368 - acc: 0.9533\n",
      "Epoch 49/64\n",
      "1198/1198 [==============================] - 1s 729us/step - loss: 0.1329 - acc: 0.9499\n",
      "Epoch 50/64\n",
      "1198/1198 [==============================] - 1s 735us/step - loss: 0.1331 - acc: 0.9499\n",
      "Epoch 51/64\n",
      "1198/1198 [==============================] - 1s 736us/step - loss: 0.1302 - acc: 0.9533 0s - loss: 0.1196 - acc: 0.9\n",
      "Epoch 52/64\n",
      "1198/1198 [==============================] - 1s 729us/step - loss: 0.1285 - acc: 0.9541\n",
      "Epoch 53/64\n",
      "1198/1198 [==============================] - 1s 759us/step - loss: 0.1255 - acc: 0.9499\n",
      "Epoch 54/64\n",
      "1198/1198 [==============================] - 1s 725us/step - loss: 0.1255 - acc: 0.9549\n",
      "Epoch 55/64\n",
      "1198/1198 [==============================] - 1s 714us/step - loss: 0.1231 - acc: 0.9566\n",
      "Epoch 56/64\n",
      "1198/1198 [==============================] - 1s 735us/step - loss: 0.1211 - acc: 0.9549\n",
      "Epoch 57/64\n",
      "1198/1198 [==============================] - 1s 738us/step - loss: 0.1198 - acc: 0.9549\n",
      "Epoch 58/64\n",
      "1198/1198 [==============================] - 1s 714us/step - loss: 0.1192 - acc: 0.9541\n",
      "Epoch 59/64\n",
      "1198/1198 [==============================] - 1s 721us/step - loss: 0.1170 - acc: 0.9608\n",
      "Epoch 60/64\n",
      "1198/1198 [==============================] - 1s 763us/step - loss: 0.1161 - acc: 0.9558\n",
      "Epoch 61/64\n",
      "1198/1198 [==============================] - 1s 742us/step - loss: 0.1134 - acc: 0.9574\n",
      "Epoch 62/64\n",
      "1198/1198 [==============================] - 1s 734us/step - loss: 0.1145 - acc: 0.9616\n",
      "Epoch 63/64\n",
      "1198/1198 [==============================] - 1s 749us/step - loss: 0.1117 - acc: 0.9566\n",
      "Epoch 64/64\n",
      "1198/1198 [==============================] - 1s 768us/step - loss: 0.1119 - acc: 0.9549\n",
      "299/299 [==============================] - 1s 2ms/step\n",
      "Epoch 1/32\n",
      "1197/1197 [==============================] - 2s 1ms/step - loss: 0.6178 - acc: 0.7978\n",
      "Epoch 2/32\n",
      "1197/1197 [==============================] - 0s 384us/step - loss: 0.3969 - acc: 0.8805\n",
      "Epoch 3/32\n",
      "1197/1197 [==============================] - 0s 393us/step - loss: 0.2700 - acc: 0.9006\n",
      "Epoch 4/32\n",
      "1197/1197 [==============================] - 0s 380us/step - loss: 0.2361 - acc: 0.9056\n",
      "Epoch 5/32\n",
      "1197/1197 [==============================] - 0s 375us/step - loss: 0.2223 - acc: 0.9098\n",
      "Epoch 6/32\n",
      "1197/1197 [==============================] - 0s 406us/step - loss: 0.2149 - acc: 0.9081\n",
      "Epoch 7/32\n",
      "1197/1197 [==============================] - 0s 393us/step - loss: 0.2088 - acc: 0.9089\n",
      "Epoch 8/32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1197/1197 [==============================] - 1s 420us/step - loss: 0.2041 - acc: 0.9081\n",
      "Epoch 9/32\n",
      "1197/1197 [==============================] - 0s 366us/step - loss: 0.2014 - acc: 0.9148\n",
      "Epoch 10/32\n",
      "1197/1197 [==============================] - 0s 381us/step - loss: 0.1966 - acc: 0.9131\n",
      "Epoch 11/32\n",
      "1197/1197 [==============================] - 0s 370us/step - loss: 0.1937 - acc: 0.9156\n",
      "Epoch 12/32\n",
      "1197/1197 [==============================] - 0s 367us/step - loss: 0.1895 - acc: 0.9173\n",
      "Epoch 13/32\n",
      "1197/1197 [==============================] - 0s 376us/step - loss: 0.1869 - acc: 0.9215\n",
      "Epoch 14/32\n",
      "1197/1197 [==============================] - 0s 393us/step - loss: 0.1862 - acc: 0.9181\n",
      "Epoch 15/32\n",
      "1197/1197 [==============================] - 0s 379us/step - loss: 0.1821 - acc: 0.9206\n",
      "Epoch 16/32\n",
      "1197/1197 [==============================] - 0s 367us/step - loss: 0.1798 - acc: 0.9248\n",
      "Epoch 17/32\n",
      "1197/1197 [==============================] - 1s 448us/step - loss: 0.1771 - acc: 0.9282\n",
      "Epoch 18/32\n",
      "1197/1197 [==============================] - 0s 391us/step - loss: 0.1754 - acc: 0.9256\n",
      "Epoch 19/32\n",
      "1197/1197 [==============================] - 0s 385us/step - loss: 0.1736 - acc: 0.9273\n",
      "Epoch 20/32\n",
      "1197/1197 [==============================] - 0s 380us/step - loss: 0.1721 - acc: 0.9307\n",
      "Epoch 21/32\n",
      "1197/1197 [==============================] - 0s 360us/step - loss: 0.1719 - acc: 0.9315\n",
      "Epoch 22/32\n",
      "1197/1197 [==============================] - 0s 380us/step - loss: 0.1679 - acc: 0.9340\n",
      "Epoch 23/32\n",
      "1197/1197 [==============================] - 0s 406us/step - loss: 0.1665 - acc: 0.9256\n",
      "Epoch 24/32\n",
      "1197/1197 [==============================] - 0s 381us/step - loss: 0.1649 - acc: 0.9298\n",
      "Epoch 25/32\n",
      "1197/1197 [==============================] - 0s 367us/step - loss: 0.1628 - acc: 0.9323\n",
      "Epoch 26/32\n",
      "1197/1197 [==============================] - 0s 357us/step - loss: 0.1606 - acc: 0.9373 0s - loss: 0.1668 - acc: 0.9\n",
      "Epoch 27/32\n",
      "1197/1197 [==============================] - 0s 367us/step - loss: 0.1597 - acc: 0.9332\n",
      "Epoch 28/32\n",
      "1197/1197 [==============================] - 0s 349us/step - loss: 0.1592 - acc: 0.9390\n",
      "Epoch 29/32\n",
      "1197/1197 [==============================] - 0s 367us/step - loss: 0.1585 - acc: 0.9407\n",
      "Epoch 30/32\n",
      "1197/1197 [==============================] - 0s 393us/step - loss: 0.1558 - acc: 0.9373\n",
      "Epoch 31/32\n",
      "1197/1197 [==============================] - 0s 380us/step - loss: 0.1536 - acc: 0.9373\n",
      "Epoch 32/32\n",
      "1197/1197 [==============================] - 0s 386us/step - loss: 0.1522 - acc: 0.9424\n",
      "300/300 [==============================] - 1s 2ms/step\n",
      "Epoch 1/32\n",
      "1197/1197 [==============================] - 2s 2ms/step - loss: 0.6033 - acc: 0.8179\n",
      "Epoch 2/32\n",
      "1197/1197 [==============================] - 0s 394us/step - loss: 0.3639 - acc: 0.8939\n",
      "Epoch 3/32\n",
      "1197/1197 [==============================] - 1s 419us/step - loss: 0.2531 - acc: 0.9023\n",
      "Epoch 4/32\n",
      "1197/1197 [==============================] - 0s 370us/step - loss: 0.2264 - acc: 0.9123\n",
      "Epoch 5/32\n",
      "1197/1197 [==============================] - 0s 393us/step - loss: 0.2150 - acc: 0.9114\n",
      "Epoch 6/32\n",
      "1197/1197 [==============================] - 0s 393us/step - loss: 0.2097 - acc: 0.9165\n",
      "Epoch 7/32\n",
      "1197/1197 [==============================] - 0s 374us/step - loss: 0.2038 - acc: 0.9156\n",
      "Epoch 8/32\n",
      "1197/1197 [==============================] - 0s 393us/step - loss: 0.1986 - acc: 0.9181\n",
      "Epoch 9/32\n",
      "1197/1197 [==============================] - 0s 355us/step - loss: 0.1945 - acc: 0.9231\n",
      "Epoch 10/32\n",
      "1197/1197 [==============================] - 0s 367us/step - loss: 0.1910 - acc: 0.9198\n",
      "Epoch 11/32\n",
      "1197/1197 [==============================] - 0s 385us/step - loss: 0.1853 - acc: 0.9282\n",
      "Epoch 12/32\n",
      "1197/1197 [==============================] - 0s 363us/step - loss: 0.1828 - acc: 0.9273\n",
      "Epoch 13/32\n",
      "1197/1197 [==============================] - 0s 387us/step - loss: 0.1800 - acc: 0.9282\n",
      "Epoch 14/32\n",
      "1197/1197 [==============================] - 0s 393us/step - loss: 0.1784 - acc: 0.9290\n",
      "Epoch 15/32\n",
      "1197/1197 [==============================] - 0s 380us/step - loss: 0.1749 - acc: 0.9348\n",
      "Epoch 16/32\n",
      "1197/1197 [==============================] - 0s 393us/step - loss: 0.1703 - acc: 0.9357\n",
      "Epoch 17/32\n",
      "1197/1197 [==============================] - 0s 393us/step - loss: 0.1697 - acc: 0.9348\n",
      "Epoch 18/32\n",
      "1197/1197 [==============================] - 1s 433us/step - loss: 0.1669 - acc: 0.9348\n",
      "Epoch 19/32\n",
      "1197/1197 [==============================] - 0s 379us/step - loss: 0.1670 - acc: 0.9365\n",
      "Epoch 20/32\n",
      "1197/1197 [==============================] - 0s 389us/step - loss: 0.1646 - acc: 0.9390\n",
      "Epoch 21/32\n",
      "1197/1197 [==============================] - 0s 386us/step - loss: 0.1621 - acc: 0.9390\n",
      "Epoch 22/32\n",
      "1197/1197 [==============================] - 1s 432us/step - loss: 0.1600 - acc: 0.9424\n",
      "Epoch 23/32\n",
      "1197/1197 [==============================] - 0s 393us/step - loss: 0.1588 - acc: 0.9398\n",
      "Epoch 24/32\n",
      "1197/1197 [==============================] - 0s 403us/step - loss: 0.1568 - acc: 0.9424\n",
      "Epoch 25/32\n",
      "1197/1197 [==============================] - 0s 378us/step - loss: 0.1554 - acc: 0.9449\n",
      "Epoch 26/32\n",
      "1197/1197 [==============================] - 0s 393us/step - loss: 0.1530 - acc: 0.9432\n",
      "Epoch 27/32\n",
      "1197/1197 [==============================] - 0s 367us/step - loss: 0.1554 - acc: 0.9432\n",
      "Epoch 28/32\n",
      "1197/1197 [==============================] - 0s 380us/step - loss: 0.1514 - acc: 0.9432\n",
      "Epoch 29/32\n",
      "1197/1197 [==============================] - 0s 384us/step - loss: 0.1507 - acc: 0.9449\n",
      "Epoch 30/32\n",
      "1197/1197 [==============================] - 0s 406us/step - loss: 0.1505 - acc: 0.9474\n",
      "Epoch 31/32\n",
      "1197/1197 [==============================] - 0s 393us/step - loss: 0.1497 - acc: 0.9465\n",
      "Epoch 32/32\n",
      "1197/1197 [==============================] - 0s 393us/step - loss: 0.1458 - acc: 0.9457\n",
      "300/300 [==============================] - 1s 2ms/step\n",
      "Epoch 1/32\n",
      "1198/1198 [==============================] - 2s 2ms/step - loss: 0.6135 - acc: 0.8381\n",
      "Epoch 2/32\n",
      "1198/1198 [==============================] - 1s 419us/step - loss: 0.4235 - acc: 0.9065\n",
      "Epoch 3/32\n",
      "1198/1198 [==============================] - 0s 382us/step - loss: 0.2881 - acc: 0.9082\n",
      "Epoch 4/32\n",
      "1198/1198 [==============================] - 0s 379us/step - loss: 0.2328 - acc: 0.9124\n",
      "Epoch 5/32\n",
      "1198/1198 [==============================] - 0s 405us/step - loss: 0.2143 - acc: 0.9182\n",
      "Epoch 6/32\n",
      "1198/1198 [==============================] - 1s 419us/step - loss: 0.2064 - acc: 0.9165\n",
      "Epoch 7/32\n",
      "1198/1198 [==============================] - 0s 402us/step - loss: 0.1984 - acc: 0.9215\n",
      "Epoch 8/32\n",
      "1198/1198 [==============================] - 0s 406us/step - loss: 0.1933 - acc: 0.9274\n",
      "Epoch 9/32\n",
      "1198/1198 [==============================] - 1s 471us/step - loss: 0.1898 - acc: 0.9240\n",
      "Epoch 10/32\n",
      "1198/1198 [==============================] - 1s 419us/step - loss: 0.1865 - acc: 0.9282\n",
      "Epoch 11/32\n",
      "1198/1198 [==============================] - 0s 406us/step - loss: 0.1821 - acc: 0.9316\n",
      "Epoch 12/32\n",
      "1198/1198 [==============================] - 0s 380us/step - loss: 0.1815 - acc: 0.9299\n",
      "Epoch 13/32\n",
      "1198/1198 [==============================] - 1s 419us/step - loss: 0.1790 - acc: 0.9357\n",
      "Epoch 14/32\n",
      "1198/1198 [==============================] - 0s 393us/step - loss: 0.1764 - acc: 0.9332\n",
      "Epoch 15/32\n",
      "1198/1198 [==============================] - 0s 405us/step - loss: 0.1752 - acc: 0.9341\n",
      "Epoch 16/32\n",
      "1198/1198 [==============================] - 0s 406us/step - loss: 0.1751 - acc: 0.9349\n",
      "Epoch 17/32\n",
      "1198/1198 [==============================] - 0s 409us/step - loss: 0.1730 - acc: 0.9299\n",
      "Epoch 18/32\n",
      "1198/1198 [==============================] - 0s 393us/step - loss: 0.1721 - acc: 0.9349\n",
      "Epoch 19/32\n",
      "1198/1198 [==============================] - 0s 380us/step - loss: 0.1692 - acc: 0.9382\n",
      "Epoch 20/32\n",
      "1198/1198 [==============================] - 0s 387us/step - loss: 0.1684 - acc: 0.9332\n",
      "Epoch 21/32\n",
      "1198/1198 [==============================] - 0s 394us/step - loss: 0.1661 - acc: 0.9366\n",
      "Epoch 22/32\n",
      "1198/1198 [==============================] - 0s 393us/step - loss: 0.1650 - acc: 0.9391\n",
      "Epoch 23/32\n",
      "1198/1198 [==============================] - 0s 393us/step - loss: 0.1641 - acc: 0.9366\n",
      "Epoch 24/32\n",
      "1198/1198 [==============================] - 0s 393us/step - loss: 0.1627 - acc: 0.9399\n",
      "Epoch 25/32\n",
      "1198/1198 [==============================] - 0s 367us/step - loss: 0.1625 - acc: 0.9407\n",
      "Epoch 26/32\n",
      "1198/1198 [==============================] - 0s 396us/step - loss: 0.1612 - acc: 0.9391\n",
      "Epoch 27/32\n",
      "1198/1198 [==============================] - 0s 392us/step - loss: 0.1596 - acc: 0.9424\n",
      "Epoch 28/32\n",
      "1198/1198 [==============================] - 0s 405us/step - loss: 0.1590 - acc: 0.9407\n",
      "Epoch 29/32\n",
      "1198/1198 [==============================] - 0s 406us/step - loss: 0.1572 - acc: 0.9391\n",
      "Epoch 30/32\n",
      "1198/1198 [==============================] - 0s 376us/step - loss: 0.1574 - acc: 0.9424\n",
      "Epoch 31/32\n",
      "1198/1198 [==============================] - 0s 380us/step - loss: 0.1554 - acc: 0.9432\n",
      "Epoch 32/32\n",
      "1198/1198 [==============================] - 0s 366us/step - loss: 0.1547 - acc: 0.9432\n",
      "299/299 [==============================] - 1s 2ms/step\n",
      "Epoch 1/32\n",
      "1198/1198 [==============================] - 2s 2ms/step - loss: 0.6286 - acc: 0.7771\n",
      "Epoch 2/32\n",
      "1198/1198 [==============================] - 0s 388us/step - loss: 0.4476 - acc: 0.8865\n",
      "Epoch 3/32\n",
      "1198/1198 [==============================] - 0s 378us/step - loss: 0.3083 - acc: 0.8965\n",
      "Epoch 4/32\n",
      "1198/1198 [==============================] - 0s 367us/step - loss: 0.2530 - acc: 0.9023\n",
      "Epoch 5/32\n",
      "1198/1198 [==============================] - 0s 380us/step - loss: 0.2338 - acc: 0.9082\n",
      "Epoch 6/32\n",
      "1198/1198 [==============================] - 0s 364us/step - loss: 0.2224 - acc: 0.9149\n",
      "Epoch 7/32\n",
      "1198/1198 [==============================] - 0s 384us/step - loss: 0.2150 - acc: 0.9157\n",
      "Epoch 8/32\n",
      "1198/1198 [==============================] - 0s 366us/step - loss: 0.2073 - acc: 0.9182\n",
      "Epoch 9/32\n",
      "1198/1198 [==============================] - 0s 376us/step - loss: 0.2037 - acc: 0.9207\n",
      "Epoch 10/32\n",
      "1198/1198 [==============================] - 0s 392us/step - loss: 0.1995 - acc: 0.9157\n",
      "Epoch 11/32\n",
      "1198/1198 [==============================] - 0s 393us/step - loss: 0.1964 - acc: 0.9215\n",
      "Epoch 12/32\n",
      "1198/1198 [==============================] - 0s 405us/step - loss: 0.1947 - acc: 0.9174\n",
      "Epoch 13/32\n",
      "1198/1198 [==============================] - 0s 380us/step - loss: 0.1888 - acc: 0.9249 0s - loss: 0.2078 - acc: 0.\n",
      "Epoch 14/32\n",
      "1198/1198 [==============================] - 0s 417us/step - loss: 0.1875 - acc: 0.9274\n",
      "Epoch 15/32\n",
      "1198/1198 [==============================] - 0s 385us/step - loss: 0.1867 - acc: 0.9249\n",
      "Epoch 16/32\n",
      "1198/1198 [==============================] - 0s 405us/step - loss: 0.1849 - acc: 0.9249\n",
      "Epoch 17/32\n",
      "1198/1198 [==============================] - 0s 383us/step - loss: 0.1822 - acc: 0.9282\n",
      "Epoch 18/32\n",
      "1198/1198 [==============================] - 0s 369us/step - loss: 0.1801 - acc: 0.9249\n",
      "Epoch 19/32\n",
      "1198/1198 [==============================] - 0s 380us/step - loss: 0.1784 - acc: 0.9265\n",
      "Epoch 20/32\n",
      "1198/1198 [==============================] - 0s 380us/step - loss: 0.1749 - acc: 0.9316\n",
      "Epoch 21/32\n",
      "1198/1198 [==============================] - 0s 393us/step - loss: 0.1731 - acc: 0.9299\n",
      "Epoch 22/32\n",
      "1198/1198 [==============================] - 0s 384us/step - loss: 0.1706 - acc: 0.9290\n",
      "Epoch 23/32\n",
      "1198/1198 [==============================] - 0s 392us/step - loss: 0.1687 - acc: 0.9349\n",
      "Epoch 24/32\n",
      "1198/1198 [==============================] - 0s 391us/step - loss: 0.1662 - acc: 0.9332\n",
      "Epoch 25/32\n",
      "1198/1198 [==============================] - 0s 391us/step - loss: 0.1659 - acc: 0.9316\n",
      "Epoch 26/32\n",
      "1198/1198 [==============================] - 0s 387us/step - loss: 0.1616 - acc: 0.9332\n",
      "Epoch 27/32\n",
      "1198/1198 [==============================] - 0s 368us/step - loss: 0.1625 - acc: 0.9324\n",
      "Epoch 28/32\n",
      "1198/1198 [==============================] - 0s 367us/step - loss: 0.1596 - acc: 0.9382\n",
      "Epoch 29/32\n",
      "1198/1198 [==============================] - 0s 366us/step - loss: 0.1570 - acc: 0.9374\n",
      "Epoch 30/32\n",
      "1198/1198 [==============================] - 0s 398us/step - loss: 0.1561 - acc: 0.9407\n",
      "Epoch 31/32\n",
      "1198/1198 [==============================] - 0s 389us/step - loss: 0.1531 - acc: 0.9407\n",
      "Epoch 32/32\n",
      "1198/1198 [==============================] - 1s 445us/step - loss: 0.1514 - acc: 0.9441\n",
      "299/299 [==============================] - 1s 2ms/step\n",
      "Epoch 1/32\n",
      "1198/1198 [==============================] - 2s 2ms/step - loss: 0.6131 - acc: 0.7329\n",
      "Epoch 2/32\n",
      "1198/1198 [==============================] - 0s 393us/step - loss: 0.3998 - acc: 0.8823\n",
      "Epoch 3/32\n",
      "1198/1198 [==============================] - 1s 446us/step - loss: 0.2739 - acc: 0.9007\n",
      "Epoch 4/32\n",
      "1198/1198 [==============================] - 1s 424us/step - loss: 0.2329 - acc: 0.9065\n",
      "Epoch 5/32\n",
      "1198/1198 [==============================] - 0s 394us/step - loss: 0.2213 - acc: 0.9124\n",
      "Epoch 6/32\n",
      "1198/1198 [==============================] - 1s 419us/step - loss: 0.2140 - acc: 0.9115\n",
      "Epoch 7/32\n",
      "1198/1198 [==============================] - 0s 405us/step - loss: 0.2099 - acc: 0.9165\n",
      "Epoch 8/32\n",
      "1198/1198 [==============================] - 1s 432us/step - loss: 0.2046 - acc: 0.9199\n",
      "Epoch 9/32\n",
      "1198/1198 [==============================] - 1s 432us/step - loss: 0.2035 - acc: 0.9215\n",
      "Epoch 10/32\n",
      "1198/1198 [==============================] - 1s 419us/step - loss: 0.2005 - acc: 0.9215\n",
      "Epoch 11/32\n",
      "1198/1198 [==============================] - 0s 380us/step - loss: 0.1982 - acc: 0.9249\n",
      "Epoch 12/32\n",
      "1198/1198 [==============================] - ETA: 0s - loss: 0.1953 - acc: 0.924 - 0s 406us/step - loss: 0.1954 - acc: 0.9240\n",
      "Epoch 13/32\n",
      "1198/1198 [==============================] - 1s 444us/step - loss: 0.1938 - acc: 0.9282\n",
      "Epoch 14/32\n",
      "1198/1198 [==============================] - 1s 459us/step - loss: 0.1905 - acc: 0.9257\n",
      "Epoch 15/32\n",
      "1198/1198 [==============================] - 1s 432us/step - loss: 0.1878 - acc: 0.9299\n",
      "Epoch 16/32\n",
      "1198/1198 [==============================] - 1s 479us/step - loss: 0.1864 - acc: 0.9299\n",
      "Epoch 17/32\n",
      "1198/1198 [==============================] - 1s 425us/step - loss: 0.1844 - acc: 0.9299\n",
      "Epoch 18/32\n",
      "1198/1198 [==============================] - 0s 405us/step - loss: 0.1833 - acc: 0.9316\n",
      "Epoch 19/32\n",
      "1198/1198 [==============================] - 0s 406us/step - loss: 0.1811 - acc: 0.9316\n",
      "Epoch 20/32\n",
      "1198/1198 [==============================] - 0s 409us/step - loss: 0.1788 - acc: 0.9332\n",
      "Epoch 21/32\n",
      "1198/1198 [==============================] - 0s 378us/step - loss: 0.1776 - acc: 0.9316\n",
      "Epoch 22/32\n",
      "1198/1198 [==============================] - 0s 393us/step - loss: 0.1771 - acc: 0.9324\n",
      "Epoch 23/32\n",
      "1198/1198 [==============================] - 0s 389us/step - loss: 0.1748 - acc: 0.9316\n",
      "Epoch 24/32\n",
      "1198/1198 [==============================] - 0s 379us/step - loss: 0.1734 - acc: 0.9366\n",
      "Epoch 25/32\n",
      "1198/1198 [==============================] - 0s 380us/step - loss: 0.1710 - acc: 0.9382\n",
      "Epoch 26/32\n",
      "1198/1198 [==============================] - 0s 392us/step - loss: 0.1697 - acc: 0.9357\n",
      "Epoch 27/32\n",
      "1198/1198 [==============================] - 1s 420us/step - loss: 0.1685 - acc: 0.9341\n",
      "Epoch 28/32\n",
      "1198/1198 [==============================] - 1s 419us/step - loss: 0.1665 - acc: 0.9366\n",
      "Epoch 29/32\n",
      "1198/1198 [==============================] - 1s 482us/step - loss: 0.1667 - acc: 0.9349 0s - loss: 0.1824 - acc: \n",
      "Epoch 30/32\n",
      "1198/1198 [==============================] - 1s 433us/step - loss: 0.1654 - acc: 0.9349\n",
      "Epoch 31/32\n",
      "1198/1198 [==============================] - 1s 419us/step - loss: 0.1627 - acc: 0.9391\n",
      "Epoch 32/32\n",
      "1198/1198 [==============================] - 0s 406us/step - loss: 0.1632 - acc: 0.9391\n",
      "299/299 [==============================] - 1s 2ms/step\n",
      "Epoch 1/32\n",
      "1197/1197 [==============================] - 2s 2ms/step - loss: 0.6023 - acc: 0.8254\n",
      "Epoch 2/32\n",
      "1197/1197 [==============================] - 0s 359us/step - loss: 0.3942 - acc: 0.8889\n",
      "Epoch 3/32\n",
      "1197/1197 [==============================] - 0s 379us/step - loss: 0.2804 - acc: 0.8989\n",
      "Epoch 4/32\n",
      "1197/1197 [==============================] - 0s 367us/step - loss: 0.2445 - acc: 0.9039\n",
      "Epoch 5/32\n",
      "1197/1197 [==============================] - 0s 380us/step - loss: 0.2294 - acc: 0.9056\n",
      "Epoch 6/32\n",
      "1197/1197 [==============================] - 0s 357us/step - loss: 0.2219 - acc: 0.9064\n",
      "Epoch 7/32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1197/1197 [==============================] - 0s 368us/step - loss: 0.2172 - acc: 0.9131\n",
      "Epoch 8/32\n",
      "1197/1197 [==============================] - 0s 375us/step - loss: 0.2123 - acc: 0.9156\n",
      "Epoch 9/32\n",
      "1197/1197 [==============================] - 0s 366us/step - loss: 0.2094 - acc: 0.9165\n",
      "Epoch 10/32\n",
      "1197/1197 [==============================] - 0s 368us/step - loss: 0.2056 - acc: 0.9173\n",
      "Epoch 11/32\n",
      "1197/1197 [==============================] - 0s 366us/step - loss: 0.2028 - acc: 0.9165\n",
      "Epoch 12/32\n",
      "1197/1197 [==============================] - 0s 370us/step - loss: 0.1998 - acc: 0.9190\n",
      "Epoch 13/32\n",
      "1197/1197 [==============================] - 0s 380us/step - loss: 0.1976 - acc: 0.9173\n",
      "Epoch 14/32\n",
      "1197/1197 [==============================] - 0s 376us/step - loss: 0.1944 - acc: 0.9165\n",
      "Epoch 15/32\n",
      "1197/1197 [==============================] - 0s 367us/step - loss: 0.1920 - acc: 0.9256\n",
      "Epoch 16/32\n",
      "1197/1197 [==============================] - 0s 353us/step - loss: 0.1904 - acc: 0.9198\n",
      "Epoch 17/32\n",
      "1197/1197 [==============================] - 0s 355us/step - loss: 0.1883 - acc: 0.9215\n",
      "Epoch 18/32\n",
      "1197/1197 [==============================] - 0s 357us/step - loss: 0.1850 - acc: 0.9223\n",
      "Epoch 19/32\n",
      "1197/1197 [==============================] - 0s 381us/step - loss: 0.1843 - acc: 0.9223\n",
      "Epoch 20/32\n",
      "1197/1197 [==============================] - 0s 403us/step - loss: 0.1822 - acc: 0.9206\n",
      "Epoch 21/32\n",
      "1197/1197 [==============================] - 0s 363us/step - loss: 0.1807 - acc: 0.9215\n",
      "Epoch 22/32\n",
      "1197/1197 [==============================] - 0s 354us/step - loss: 0.1791 - acc: 0.9206\n",
      "Epoch 23/32\n",
      "1197/1197 [==============================] - 0s 367us/step - loss: 0.1773 - acc: 0.9298\n",
      "Epoch 24/32\n",
      "1197/1197 [==============================] - 0s 372us/step - loss: 0.1765 - acc: 0.9256\n",
      "Epoch 25/32\n",
      "1197/1197 [==============================] - 0s 377us/step - loss: 0.1745 - acc: 0.9256\n",
      "Epoch 26/32\n",
      "1197/1197 [==============================] - 0s 380us/step - loss: 0.1737 - acc: 0.9223\n",
      "Epoch 27/32\n",
      "1197/1197 [==============================] - 0s 375us/step - loss: 0.1725 - acc: 0.9290\n",
      "Epoch 28/32\n",
      "1197/1197 [==============================] - 0s 406us/step - loss: 0.1697 - acc: 0.9282\n",
      "Epoch 29/32\n",
      "1197/1197 [==============================] - 1s 459us/step - loss: 0.1692 - acc: 0.9290\n",
      "Epoch 30/32\n",
      "1197/1197 [==============================] - 0s 354us/step - loss: 0.1681 - acc: 0.9357\n",
      "Epoch 31/32\n",
      "1197/1197 [==============================] - 0s 380us/step - loss: 0.1665 - acc: 0.9323\n",
      "Epoch 32/32\n",
      "1197/1197 [==============================] - 0s 378us/step - loss: 0.1656 - acc: 0.9365\n",
      "300/300 [==============================] - 1s 2ms/step\n",
      "Epoch 1/32\n",
      "1197/1197 [==============================] - 2s 2ms/step - loss: 0.5506 - acc: 0.8329\n",
      "Epoch 2/32\n",
      "1197/1197 [==============================] - 0s 353us/step - loss: 0.3259 - acc: 0.8981\n",
      "Epoch 3/32\n",
      "1197/1197 [==============================] - 0s 355us/step - loss: 0.2404 - acc: 0.9039\n",
      "Epoch 4/32\n",
      "1197/1197 [==============================] - 0s 357us/step - loss: 0.2191 - acc: 0.9156\n",
      "Epoch 5/32\n",
      "1197/1197 [==============================] - 0s 367us/step - loss: 0.2110 - acc: 0.9181\n",
      "Epoch 6/32\n",
      "1197/1197 [==============================] - 0s 362us/step - loss: 0.2060 - acc: 0.9165\n",
      "Epoch 7/32\n",
      "1197/1197 [==============================] - 0s 367us/step - loss: 0.2024 - acc: 0.9148\n",
      "Epoch 8/32\n",
      "1197/1197 [==============================] - 0s 340us/step - loss: 0.2013 - acc: 0.9173\n",
      "Epoch 9/32\n",
      "1197/1197 [==============================] - 0s 354us/step - loss: 0.1987 - acc: 0.9198\n",
      "Epoch 10/32\n",
      "1197/1197 [==============================] - 0s 371us/step - loss: 0.1959 - acc: 0.9231\n",
      "Epoch 11/32\n",
      "1197/1197 [==============================] - 0s 367us/step - loss: 0.1945 - acc: 0.9223\n",
      "Epoch 12/32\n",
      "1197/1197 [==============================] - 0s 375us/step - loss: 0.1916 - acc: 0.9206\n",
      "Epoch 13/32\n",
      "1197/1197 [==============================] - 0s 353us/step - loss: 0.1929 - acc: 0.9240\n",
      "Epoch 14/32\n",
      "1197/1197 [==============================] - 0s 380us/step - loss: 0.1890 - acc: 0.9248\n",
      "Epoch 15/32\n",
      "1197/1197 [==============================] - 0s 380us/step - loss: 0.1873 - acc: 0.9307\n",
      "Epoch 16/32\n",
      "1197/1197 [==============================] - 0s 371us/step - loss: 0.1868 - acc: 0.9265\n",
      "Epoch 17/32\n",
      "1197/1197 [==============================] - 1s 495us/step - loss: 0.1844 - acc: 0.9256\n",
      "Epoch 18/32\n",
      "1197/1197 [==============================] - 0s 383us/step - loss: 0.1839 - acc: 0.9273\n",
      "Epoch 19/32\n",
      "1197/1197 [==============================] - 0s 406us/step - loss: 0.1804 - acc: 0.9290\n",
      "Epoch 20/32\n",
      "1197/1197 [==============================] - 0s 393us/step - loss: 0.1804 - acc: 0.9282\n",
      "Epoch 21/32\n",
      "1197/1197 [==============================] - 0s 363us/step - loss: 0.1778 - acc: 0.9307\n",
      "Epoch 22/32\n",
      "1197/1197 [==============================] - 0s 379us/step - loss: 0.1771 - acc: 0.9323\n",
      "Epoch 23/32\n",
      "1197/1197 [==============================] - 0s 381us/step - loss: 0.1752 - acc: 0.9323\n",
      "Epoch 24/32\n",
      "1197/1197 [==============================] - 0s 391us/step - loss: 0.1731 - acc: 0.9332\n",
      "Epoch 25/32\n",
      "1197/1197 [==============================] - 0s 382us/step - loss: 0.1742 - acc: 0.9332\n",
      "Epoch 26/32\n",
      "1197/1197 [==============================] - 0s 382us/step - loss: 0.1723 - acc: 0.9323\n",
      "Epoch 27/32\n",
      "1197/1197 [==============================] - 0s 380us/step - loss: 0.1708 - acc: 0.9332\n",
      "Epoch 28/32\n",
      "1197/1197 [==============================] - 0s 380us/step - loss: 0.1685 - acc: 0.9340\n",
      "Epoch 29/32\n",
      "1197/1197 [==============================] - 0s 376us/step - loss: 0.1688 - acc: 0.9323\n",
      "Epoch 30/32\n",
      "1197/1197 [==============================] - 0s 380us/step - loss: 0.1660 - acc: 0.9323\n",
      "Epoch 31/32\n",
      "1197/1197 [==============================] - 0s 380us/step - loss: 0.1652 - acc: 0.9348\n",
      "Epoch 32/32\n",
      "1197/1197 [==============================] - 0s 367us/step - loss: 0.1638 - acc: 0.9382\n",
      "300/300 [==============================] - 1s 2ms/step\n",
      "Epoch 1/32\n",
      "1198/1198 [==============================] - 2s 2ms/step - loss: 0.5964 - acc: 0.8489\n",
      "Epoch 2/32\n",
      "1198/1198 [==============================] - 0s 383us/step - loss: 0.4072 - acc: 0.9023\n",
      "Epoch 3/32\n",
      "1198/1198 [==============================] - 0s 367us/step - loss: 0.2853 - acc: 0.9098\n",
      "Epoch 4/32\n",
      "1198/1198 [==============================] - 0s 389us/step - loss: 0.2378 - acc: 0.9149\n",
      "Epoch 5/32\n",
      "1198/1198 [==============================] - 0s 379us/step - loss: 0.2199 - acc: 0.9182\n",
      "Epoch 6/32\n",
      "1198/1198 [==============================] - 0s 380us/step - loss: 0.2100 - acc: 0.9174\n",
      "Epoch 7/32\n",
      "1198/1198 [==============================] - 0s 367us/step - loss: 0.2039 - acc: 0.9190\n",
      "Epoch 8/32\n",
      "1198/1198 [==============================] - 0s 381us/step - loss: 0.1998 - acc: 0.9224\n",
      "Epoch 9/32\n",
      "1198/1198 [==============================] - 0s 382us/step - loss: 0.1964 - acc: 0.9190\n",
      "Epoch 10/32\n",
      "1198/1198 [==============================] - 0s 379us/step - loss: 0.1926 - acc: 0.9207\n",
      "Epoch 11/32\n",
      "1198/1198 [==============================] - 0s 394us/step - loss: 0.1903 - acc: 0.9240\n",
      "Epoch 12/32\n",
      "1198/1198 [==============================] - 0s 373us/step - loss: 0.1879 - acc: 0.9265\n",
      "Epoch 13/32\n",
      "1198/1198 [==============================] - 0s 393us/step - loss: 0.1847 - acc: 0.9240\n",
      "Epoch 14/32\n",
      "1198/1198 [==============================] - 0s 380us/step - loss: 0.1827 - acc: 0.9257\n",
      "Epoch 15/32\n",
      "1198/1198 [==============================] - 0s 380us/step - loss: 0.1806 - acc: 0.9290\n",
      "Epoch 16/32\n",
      "1198/1198 [==============================] - 0s 379us/step - loss: 0.1791 - acc: 0.9332\n",
      "Epoch 17/32\n",
      "1198/1198 [==============================] - 0s 396us/step - loss: 0.1766 - acc: 0.9316\n",
      "Epoch 18/32\n",
      "1198/1198 [==============================] - 0s 366us/step - loss: 0.1749 - acc: 0.9341\n",
      "Epoch 19/32\n",
      "1198/1198 [==============================] - 0s 402us/step - loss: 0.1728 - acc: 0.9366\n",
      "Epoch 20/32\n",
      "1198/1198 [==============================] - 1s 425us/step - loss: 0.1720 - acc: 0.9341\n",
      "Epoch 21/32\n",
      "1198/1198 [==============================] - 1s 440us/step - loss: 0.1702 - acc: 0.9391\n",
      "Epoch 22/32\n",
      "1198/1198 [==============================] - 1s 424us/step - loss: 0.1683 - acc: 0.9366\n",
      "Epoch 23/32\n",
      "1198/1198 [==============================] - 0s 411us/step - loss: 0.1676 - acc: 0.9391\n",
      "Epoch 24/32\n",
      "1198/1198 [==============================] - 0s 388us/step - loss: 0.1662 - acc: 0.9374\n",
      "Epoch 25/32\n",
      "1198/1198 [==============================] - 0s 354us/step - loss: 0.1635 - acc: 0.9399\n",
      "Epoch 26/32\n",
      "1198/1198 [==============================] - 0s 381us/step - loss: 0.1633 - acc: 0.9407\n",
      "Epoch 27/32\n",
      "1198/1198 [==============================] - 0s 356us/step - loss: 0.1623 - acc: 0.9432\n",
      "Epoch 28/32\n",
      "1198/1198 [==============================] - 0s 406us/step - loss: 0.1594 - acc: 0.9407\n",
      "Epoch 29/32\n",
      "1198/1198 [==============================] - 0s 379us/step - loss: 0.1609 - acc: 0.9441\n",
      "Epoch 30/32\n",
      "1198/1198 [==============================] - 0s 362us/step - loss: 0.1585 - acc: 0.9424\n",
      "Epoch 31/32\n",
      "1198/1198 [==============================] - 0s 368us/step - loss: 0.1572 - acc: 0.9432\n",
      "Epoch 32/32\n",
      "1198/1198 [==============================] - 0s 379us/step - loss: 0.1567 - acc: 0.9441\n",
      "299/299 [==============================] - 1s 2ms/step\n",
      "Epoch 1/32\n",
      "1198/1198 [==============================] - 2s 2ms/step - loss: 0.5906 - acc: 0.8589\n",
      "Epoch 2/32\n",
      "1198/1198 [==============================] - 0s 384us/step - loss: 0.4079 - acc: 0.8923\n",
      "Epoch 3/32\n",
      "1198/1198 [==============================] - 0s 366us/step - loss: 0.2966 - acc: 0.8940\n",
      "Epoch 4/32\n",
      "1198/1198 [==============================] - 0s 350us/step - loss: 0.2556 - acc: 0.8998\n",
      "Epoch 5/32\n",
      "1198/1198 [==============================] - 0s 393us/step - loss: 0.2395 - acc: 0.9057\n",
      "Epoch 6/32\n",
      "1198/1198 [==============================] - 0s 367us/step - loss: 0.2303 - acc: 0.9082\n",
      "Epoch 7/32\n",
      "1198/1198 [==============================] - 0s 378us/step - loss: 0.2228 - acc: 0.9115\n",
      "Epoch 8/32\n",
      "1198/1198 [==============================] - 0s 359us/step - loss: 0.2173 - acc: 0.9124\n",
      "Epoch 9/32\n",
      "1198/1198 [==============================] - 0s 340us/step - loss: 0.2120 - acc: 0.9107\n",
      "Epoch 10/32\n",
      "1198/1198 [==============================] - 0s 362us/step - loss: 0.2088 - acc: 0.9157\n",
      "Epoch 11/32\n",
      "1198/1198 [==============================] - 0s 354us/step - loss: 0.2043 - acc: 0.9190\n",
      "Epoch 12/32\n",
      "1198/1198 [==============================] - 0s 381us/step - loss: 0.2016 - acc: 0.9207\n",
      "Epoch 13/32\n",
      "1198/1198 [==============================] - 0s 366us/step - loss: 0.1965 - acc: 0.9224\n",
      "Epoch 14/32\n",
      "1198/1198 [==============================] - 0s 370us/step - loss: 0.1950 - acc: 0.9215\n",
      "Epoch 15/32\n",
      "1198/1198 [==============================] - 0s 366us/step - loss: 0.1911 - acc: 0.9274 0s - loss: 0.1974 - acc: 0.925\n",
      "Epoch 16/32\n",
      "1198/1198 [==============================] - 0s 363us/step - loss: 0.1891 - acc: 0.9257\n",
      "Epoch 17/32\n",
      "1198/1198 [==============================] - 0s 380us/step - loss: 0.1853 - acc: 0.9274\n",
      "Epoch 18/32\n",
      "1198/1198 [==============================] - 0s 392us/step - loss: 0.1826 - acc: 0.9249\n",
      "Epoch 19/32\n",
      "1198/1198 [==============================] - 0s 393us/step - loss: 0.1820 - acc: 0.9249\n",
      "Epoch 20/32\n",
      "1198/1198 [==============================] - 0s 366us/step - loss: 0.1797 - acc: 0.9290\n",
      "Epoch 21/32\n",
      "1198/1198 [==============================] - 0s 370us/step - loss: 0.1775 - acc: 0.9282\n",
      "Epoch 22/32\n",
      "1198/1198 [==============================] - 0s 380us/step - loss: 0.1761 - acc: 0.9282\n",
      "Epoch 23/32\n",
      "1198/1198 [==============================] - 0s 363us/step - loss: 0.1742 - acc: 0.9341\n",
      "Epoch 24/32\n",
      "1198/1198 [==============================] - 0s 379us/step - loss: 0.1725 - acc: 0.9290\n",
      "Epoch 25/32\n",
      "1198/1198 [==============================] - 0s 379us/step - loss: 0.1718 - acc: 0.9299\n",
      "Epoch 26/32\n",
      "1198/1198 [==============================] - 0s 393us/step - loss: 0.1698 - acc: 0.9316\n",
      "Epoch 27/32\n",
      "1198/1198 [==============================] - 0s 380us/step - loss: 0.1683 - acc: 0.9290\n",
      "Epoch 28/32\n",
      "1198/1198 [==============================] - 0s 369us/step - loss: 0.1670 - acc: 0.9349\n",
      "Epoch 29/32\n",
      "1198/1198 [==============================] - 0s 380us/step - loss: 0.1645 - acc: 0.9357\n",
      "Epoch 30/32\n",
      "1198/1198 [==============================] - 0s 403us/step - loss: 0.1651 - acc: 0.9341\n",
      "Epoch 31/32\n",
      "1198/1198 [==============================] - 0s 349us/step - loss: 0.1639 - acc: 0.9332\n",
      "Epoch 32/32\n",
      "1198/1198 [==============================] - 1s 419us/step - loss: 0.1622 - acc: 0.9332\n",
      "299/299 [==============================] - 1s 2ms/step\n",
      "Epoch 1/32\n",
      "1198/1198 [==============================] - 2s 2ms/step - loss: 0.5730 - acc: 0.8598\n",
      "Epoch 2/32\n",
      "1198/1198 [==============================] - 0s 391us/step - loss: 0.3590 - acc: 0.8982\n",
      "Epoch 3/32\n",
      "1198/1198 [==============================] - 0s 382us/step - loss: 0.2626 - acc: 0.9032\n",
      "Epoch 4/32\n",
      "1198/1198 [==============================] - 0s 379us/step - loss: 0.2338 - acc: 0.9115\n",
      "Epoch 5/32\n",
      "1198/1198 [==============================] - 0s 398us/step - loss: 0.2241 - acc: 0.9107\n",
      "Epoch 6/32\n",
      "1198/1198 [==============================] - 0s 392us/step - loss: 0.2173 - acc: 0.9115\n",
      "Epoch 7/32\n",
      "1198/1198 [==============================] - 0s 405us/step - loss: 0.2131 - acc: 0.9149\n",
      "Epoch 8/32\n",
      "1198/1198 [==============================] - 0s 404us/step - loss: 0.2084 - acc: 0.9157\n",
      "Epoch 9/32\n",
      "1198/1198 [==============================] - 0s 404us/step - loss: 0.2078 - acc: 0.9157\n",
      "Epoch 10/32\n",
      "1198/1198 [==============================] - 0s 391us/step - loss: 0.2042 - acc: 0.9165\n",
      "Epoch 11/32\n",
      "1198/1198 [==============================] - 1s 446us/step - loss: 0.2020 - acc: 0.9174\n",
      "Epoch 12/32\n",
      "1198/1198 [==============================] - 0s 393us/step - loss: 0.2007 - acc: 0.9240\n",
      "Epoch 13/32\n",
      "1198/1198 [==============================] - 1s 458us/step - loss: 0.1975 - acc: 0.9240\n",
      "Epoch 14/32\n",
      "1198/1198 [==============================] - 1s 445us/step - loss: 0.1975 - acc: 0.9249\n",
      "Epoch 15/32\n",
      "1198/1198 [==============================] - 1s 457us/step - loss: 0.1956 - acc: 0.9190\n",
      "Epoch 16/32\n",
      "1198/1198 [==============================] - 0s 392us/step - loss: 0.1931 - acc: 0.9249\n",
      "Epoch 17/32\n",
      "1198/1198 [==============================] - 0s 406us/step - loss: 0.1921 - acc: 0.9265\n",
      "Epoch 18/32\n",
      "1198/1198 [==============================] - 0s 381us/step - loss: 0.1910 - acc: 0.9290\n",
      "Epoch 19/32\n",
      "1198/1198 [==============================] - 0s 397us/step - loss: 0.1897 - acc: 0.9316\n",
      "Epoch 20/32\n",
      "1198/1198 [==============================] - 0s 392us/step - loss: 0.1891 - acc: 0.9299\n",
      "Epoch 21/32\n",
      "1198/1198 [==============================] - 0s 380us/step - loss: 0.1878 - acc: 0.9299\n",
      "Epoch 22/32\n",
      "1198/1198 [==============================] - 0s 374us/step - loss: 0.1873 - acc: 0.9290\n",
      "Epoch 23/32\n",
      "1198/1198 [==============================] - 0s 407us/step - loss: 0.1867 - acc: 0.9316\n",
      "Epoch 24/32\n",
      "1198/1198 [==============================] - 0s 393us/step - loss: 0.1859 - acc: 0.9290\n",
      "Epoch 25/32\n",
      "1198/1198 [==============================] - 0s 380us/step - loss: 0.1838 - acc: 0.9307\n",
      "Epoch 26/32\n",
      "1198/1198 [==============================] - 0s 405us/step - loss: 0.1836 - acc: 0.9316\n",
      "Epoch 27/32\n",
      "1198/1198 [==============================] - 0s 375us/step - loss: 0.1826 - acc: 0.9282\n",
      "Epoch 28/32\n",
      "1198/1198 [==============================] - 0s 373us/step - loss: 0.1812 - acc: 0.9290\n",
      "Epoch 29/32\n",
      "1198/1198 [==============================] - 0s 380us/step - loss: 0.1816 - acc: 0.9307\n",
      "Epoch 30/32\n",
      "1198/1198 [==============================] - 0s 376us/step - loss: 0.1796 - acc: 0.9349\n",
      "Epoch 31/32\n",
      "1198/1198 [==============================] - 0s 392us/step - loss: 0.1791 - acc: 0.9299\n",
      "Epoch 32/32\n",
      "1198/1198 [==============================] - 0s 392us/step - loss: 0.1790 - acc: 0.9341\n",
      "299/299 [==============================] - 1s 2ms/step\n",
      "Epoch 1/64\n",
      "1197/1197 [==============================] - 2s 2ms/step - loss: 0.6231 - acc: 0.7828\n",
      "Epoch 2/64\n",
      "1197/1197 [==============================] - 1s 515us/step - loss: 0.4105 - acc: 0.8855\n",
      "Epoch 3/64\n",
      "1197/1197 [==============================] - 1s 458us/step - loss: 0.2763 - acc: 0.9006\n",
      "Epoch 4/64\n",
      "1197/1197 [==============================] - 1s 432us/step - loss: 0.2345 - acc: 0.9048\n",
      "Epoch 5/64\n",
      "1197/1197 [==============================] - 1s 419us/step - loss: 0.2202 - acc: 0.9089\n",
      "Epoch 6/64\n",
      "1197/1197 [==============================] - 1s 420us/step - loss: 0.2120 - acc: 0.9106\n",
      "Epoch 7/64\n",
      "1197/1197 [==============================] - 1s 432us/step - loss: 0.2052 - acc: 0.9123\n",
      "Epoch 8/64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1197/1197 [==============================] - 0s 397us/step - loss: 0.2008 - acc: 0.9156\n",
      "Epoch 9/64\n",
      "1197/1197 [==============================] - 1s 420us/step - loss: 0.1946 - acc: 0.9148\n",
      "Epoch 10/64\n",
      "1197/1197 [==============================] - 1s 433us/step - loss: 0.1912 - acc: 0.9190\n",
      "Epoch 11/64\n",
      "1197/1197 [==============================] - 0s 393us/step - loss: 0.1865 - acc: 0.9240\n",
      "Epoch 12/64\n",
      "1197/1197 [==============================] - 0s 413us/step - loss: 0.1828 - acc: 0.9223\n",
      "Epoch 13/64\n",
      "1197/1197 [==============================] - 0s 406us/step - loss: 0.1796 - acc: 0.9240\n",
      "Epoch 14/64\n",
      "1197/1197 [==============================] - 1s 419us/step - loss: 0.1773 - acc: 0.9231\n",
      "Epoch 15/64\n",
      "1197/1197 [==============================] - 0s 406us/step - loss: 0.1727 - acc: 0.9240\n",
      "Epoch 16/64\n",
      "1197/1197 [==============================] - 0s 406us/step - loss: 0.1700 - acc: 0.9282\n",
      "Epoch 17/64\n",
      "1197/1197 [==============================] - 0s 380us/step - loss: 0.1672 - acc: 0.9348\n",
      "Epoch 18/64\n",
      "1197/1197 [==============================] - 0s 407us/step - loss: 0.1652 - acc: 0.9298\n",
      "Epoch 19/64\n",
      "1197/1197 [==============================] - 0s 393us/step - loss: 0.1629 - acc: 0.9298\n",
      "Epoch 20/64\n",
      "1197/1197 [==============================] - 0s 396us/step - loss: 0.1608 - acc: 0.9348\n",
      "Epoch 21/64\n",
      "1197/1197 [==============================] - 0s 393us/step - loss: 0.1578 - acc: 0.9365\n",
      "Epoch 22/64\n",
      "1197/1197 [==============================] - 0s 392us/step - loss: 0.1563 - acc: 0.9357\n",
      "Epoch 23/64\n",
      "1197/1197 [==============================] - 0s 388us/step - loss: 0.1527 - acc: 0.9390\n",
      "Epoch 24/64\n",
      "1197/1197 [==============================] - 0s 379us/step - loss: 0.1508 - acc: 0.9382\n",
      "Epoch 25/64\n",
      "1197/1197 [==============================] - 0s 380us/step - loss: 0.1479 - acc: 0.9407\n",
      "Epoch 26/64\n",
      "1197/1197 [==============================] - 0s 393us/step - loss: 0.1462 - acc: 0.9415\n",
      "Epoch 27/64\n",
      "1197/1197 [==============================] - 0s 393us/step - loss: 0.1429 - acc: 0.9474\n",
      "Epoch 28/64\n",
      "1197/1197 [==============================] - 0s 392us/step - loss: 0.1424 - acc: 0.9449\n",
      "Epoch 29/64\n",
      "1197/1197 [==============================] - 0s 397us/step - loss: 0.1404 - acc: 0.9449\n",
      "Epoch 30/64\n",
      "1197/1197 [==============================] - 0s 406us/step - loss: 0.1381 - acc: 0.9482\n",
      "Epoch 31/64\n",
      "1197/1197 [==============================] - 0s 407us/step - loss: 0.1373 - acc: 0.9482\n",
      "Epoch 32/64\n",
      "1197/1197 [==============================] - 0s 407us/step - loss: 0.1345 - acc: 0.9515\n",
      "Epoch 33/64\n",
      "1197/1197 [==============================] - 0s 399us/step - loss: 0.1325 - acc: 0.9507\n",
      "Epoch 34/64\n",
      "1197/1197 [==============================] - 0s 406us/step - loss: 0.1309 - acc: 0.9532\n",
      "Epoch 35/64\n",
      "1197/1197 [==============================] - 1s 432us/step - loss: 0.1306 - acc: 0.9557\n",
      "Epoch 36/64\n",
      "1197/1197 [==============================] - 0s 403us/step - loss: 0.1257 - acc: 0.9557\n",
      "Epoch 37/64\n",
      "1197/1197 [==============================] - 0s 395us/step - loss: 0.1256 - acc: 0.9549\n",
      "Epoch 38/64\n",
      "1197/1197 [==============================] - 0s 380us/step - loss: 0.1251 - acc: 0.9532\n",
      "Epoch 39/64\n",
      "1197/1197 [==============================] - 1s 419us/step - loss: 0.1235 - acc: 0.9566\n",
      "Epoch 40/64\n",
      "1197/1197 [==============================] - 1s 420us/step - loss: 0.1203 - acc: 0.9574\n",
      "Epoch 41/64\n",
      "1197/1197 [==============================] - 0s 414us/step - loss: 0.1188 - acc: 0.9607\n",
      "Epoch 42/64\n",
      "1197/1197 [==============================] - 0s 388us/step - loss: 0.1186 - acc: 0.9582\n",
      "Epoch 43/64\n",
      "1197/1197 [==============================] - 0s 392us/step - loss: 0.1167 - acc: 0.9616\n",
      "Epoch 44/64\n",
      "1197/1197 [==============================] - 0s 411us/step - loss: 0.1141 - acc: 0.9574\n",
      "Epoch 45/64\n",
      "1197/1197 [==============================] - 0s 394us/step - loss: 0.1136 - acc: 0.9574\n",
      "Epoch 46/64\n",
      "1197/1197 [==============================] - 0s 406us/step - loss: 0.1117 - acc: 0.9632\n",
      "Epoch 47/64\n",
      "1197/1197 [==============================] - 0s 393us/step - loss: 0.1105 - acc: 0.9607\n",
      "Epoch 48/64\n",
      "1197/1197 [==============================] - 0s 380us/step - loss: 0.1085 - acc: 0.9632\n",
      "Epoch 49/64\n",
      "1197/1197 [==============================] - 0s 407us/step - loss: 0.1082 - acc: 0.9632\n",
      "Epoch 50/64\n",
      "1197/1197 [==============================] - 0s 380us/step - loss: 0.1061 - acc: 0.9641\n",
      "Epoch 51/64\n",
      "1197/1197 [==============================] - 1s 419us/step - loss: 0.1062 - acc: 0.9632\n",
      "Epoch 52/64\n",
      "1197/1197 [==============================] - 0s 410us/step - loss: 0.1037 - acc: 0.9632\n",
      "Epoch 53/64\n",
      "1197/1197 [==============================] - 0s 393us/step - loss: 0.1016 - acc: 0.9624\n",
      "Epoch 54/64\n",
      "1197/1197 [==============================] - 1s 420us/step - loss: 0.1016 - acc: 0.9641\n",
      "Epoch 55/64\n",
      "1197/1197 [==============================] - 0s 407us/step - loss: 0.0991 - acc: 0.9666\n",
      "Epoch 56/64\n",
      "1197/1197 [==============================] - 1s 426us/step - loss: 0.0987 - acc: 0.9649\n",
      "Epoch 57/64\n",
      "1197/1197 [==============================] - 0s 374us/step - loss: 0.0972 - acc: 0.9641\n",
      "Epoch 58/64\n",
      "1197/1197 [==============================] - 1s 425us/step - loss: 0.0948 - acc: 0.9674\n",
      "Epoch 59/64\n",
      "1197/1197 [==============================] - 0s 393us/step - loss: 0.0945 - acc: 0.9683\n",
      "Epoch 60/64\n",
      "1197/1197 [==============================] - 1s 432us/step - loss: 0.0937 - acc: 0.9657\n",
      "Epoch 61/64\n",
      "1197/1197 [==============================] - 0s 406us/step - loss: 0.0932 - acc: 0.9657\n",
      "Epoch 62/64\n",
      "1197/1197 [==============================] - 1s 445us/step - loss: 0.0901 - acc: 0.9674\n",
      "Epoch 63/64\n",
      "1197/1197 [==============================] - 1s 419us/step - loss: 0.0883 - acc: 0.9683\n",
      "Epoch 64/64\n",
      "1197/1197 [==============================] - 0s 405us/step - loss: 0.0882 - acc: 0.9674\n",
      "300/300 [==============================] - 1s 2ms/step\n",
      "Epoch 1/64\n",
      "1197/1197 [==============================] - 2s 2ms/step - loss: 0.6319 - acc: 0.8221\n",
      "Epoch 2/64\n",
      "1197/1197 [==============================] - 1s 419us/step - loss: 0.4138 - acc: 0.8881\n",
      "Epoch 3/64\n",
      "1197/1197 [==============================] - 0s 392us/step - loss: 0.2658 - acc: 0.9023\n",
      "Epoch 4/64\n",
      "1197/1197 [==============================] - 0s 396us/step - loss: 0.2250 - acc: 0.9123\n",
      "Epoch 5/64\n",
      "1197/1197 [==============================] - 0s 406us/step - loss: 0.2108 - acc: 0.9123\n",
      "Epoch 6/64\n",
      "1197/1197 [==============================] - 1s 419us/step - loss: 0.2020 - acc: 0.9165\n",
      "Epoch 7/64\n",
      "1197/1197 [==============================] - 0s 393us/step - loss: 0.1963 - acc: 0.9223\n",
      "Epoch 8/64\n",
      "1197/1197 [==============================] - 0s 389us/step - loss: 0.1896 - acc: 0.9231\n",
      "Epoch 9/64\n",
      "1197/1197 [==============================] - 0s 380us/step - loss: 0.1872 - acc: 0.9273\n",
      "Epoch 10/64\n",
      "1197/1197 [==============================] - 0s 380us/step - loss: 0.1816 - acc: 0.9298\n",
      "Epoch 11/64\n",
      "1197/1197 [==============================] - 0s 366us/step - loss: 0.1778 - acc: 0.9315\n",
      "Epoch 12/64\n",
      "1197/1197 [==============================] - 0s 376us/step - loss: 0.1751 - acc: 0.9307\n",
      "Epoch 13/64\n",
      "1197/1197 [==============================] - 0s 346us/step - loss: 0.1726 - acc: 0.9340\n",
      "Epoch 14/64\n",
      "1197/1197 [==============================] - 0s 380us/step - loss: 0.1685 - acc: 0.9357\n",
      "Epoch 15/64\n",
      "1197/1197 [==============================] - 0s 376us/step - loss: 0.1664 - acc: 0.9373\n",
      "Epoch 16/64\n",
      "1197/1197 [==============================] - 1s 420us/step - loss: 0.1658 - acc: 0.9390\n",
      "Epoch 17/64\n",
      "1197/1197 [==============================] - 0s 393us/step - loss: 0.1626 - acc: 0.9415\n",
      "Epoch 18/64\n",
      "1197/1197 [==============================] - 1s 419us/step - loss: 0.1591 - acc: 0.9432\n",
      "Epoch 19/64\n",
      "1197/1197 [==============================] - 0s 393us/step - loss: 0.1580 - acc: 0.9398\n",
      "Epoch 20/64\n",
      "1197/1197 [==============================] - 0s 406us/step - loss: 0.1566 - acc: 0.9415\n",
      "Epoch 21/64\n",
      "1197/1197 [==============================] - 0s 357us/step - loss: 0.1549 - acc: 0.9407\n",
      "Epoch 22/64\n",
      "1197/1197 [==============================] - 0s 406us/step - loss: 0.1550 - acc: 0.9407\n",
      "Epoch 23/64\n",
      "1197/1197 [==============================] - 0s 393us/step - loss: 0.1534 - acc: 0.9398\n",
      "Epoch 24/64\n",
      "1197/1197 [==============================] - 1s 458us/step - loss: 0.1521 - acc: 0.9407\n",
      "Epoch 25/64\n",
      "1197/1197 [==============================] - 1s 419us/step - loss: 0.1488 - acc: 0.9482\n",
      "Epoch 26/64\n",
      "1197/1197 [==============================] - 0s 388us/step - loss: 0.1489 - acc: 0.9424\n",
      "Epoch 27/64\n",
      "1197/1197 [==============================] - 1s 480us/step - loss: 0.1462 - acc: 0.9440\n",
      "Epoch 28/64\n",
      "1197/1197 [==============================] - 0s 410us/step - loss: 0.1445 - acc: 0.9490\n",
      "Epoch 29/64\n",
      "1197/1197 [==============================] - 0s 392us/step - loss: 0.1448 - acc: 0.9465\n",
      "Epoch 30/64\n",
      "1197/1197 [==============================] - 0s 394us/step - loss: 0.1431 - acc: 0.9499\n",
      "Epoch 31/64\n",
      "1197/1197 [==============================] - 0s 367us/step - loss: 0.1414 - acc: 0.9465\n",
      "Epoch 32/64\n",
      "1197/1197 [==============================] - 0s 380us/step - loss: 0.1399 - acc: 0.9507\n",
      "Epoch 33/64\n",
      "1197/1197 [==============================] - 1s 445us/step - loss: 0.1396 - acc: 0.9457\n",
      "Epoch 34/64\n",
      "1197/1197 [==============================] - 0s 397us/step - loss: 0.1390 - acc: 0.9490\n",
      "Epoch 35/64\n",
      "1197/1197 [==============================] - 0s 366us/step - loss: 0.1383 - acc: 0.9507\n",
      "Epoch 36/64\n",
      "1197/1197 [==============================] - 0s 387us/step - loss: 0.1372 - acc: 0.9474\n",
      "Epoch 37/64\n",
      "1197/1197 [==============================] - 0s 341us/step - loss: 0.1358 - acc: 0.9490\n",
      "Epoch 38/64\n",
      "1197/1197 [==============================] - 0s 354us/step - loss: 0.1357 - acc: 0.9482\n",
      "Epoch 39/64\n",
      "1197/1197 [==============================] - 0s 366us/step - loss: 0.1348 - acc: 0.9507\n",
      "Epoch 40/64\n",
      "1197/1197 [==============================] - 0s 358us/step - loss: 0.1345 - acc: 0.9474\n",
      "Epoch 41/64\n",
      "1197/1197 [==============================] - 0s 366us/step - loss: 0.1337 - acc: 0.9482\n",
      "Epoch 42/64\n",
      "1197/1197 [==============================] - 0s 349us/step - loss: 0.1325 - acc: 0.9482\n",
      "Epoch 43/64\n",
      "1197/1197 [==============================] - 0s 354us/step - loss: 0.1312 - acc: 0.9507\n",
      "Epoch 44/64\n",
      "1197/1197 [==============================] - 0s 354us/step - loss: 0.1309 - acc: 0.9532\n",
      "Epoch 45/64\n",
      "1197/1197 [==============================] - 0s 371us/step - loss: 0.1287 - acc: 0.9507\n",
      "Epoch 46/64\n",
      "1197/1197 [==============================] - 0s 391us/step - loss: 0.1285 - acc: 0.9541\n",
      "Epoch 47/64\n",
      "1197/1197 [==============================] - 0s 392us/step - loss: 0.1275 - acc: 0.9541\n",
      "Epoch 48/64\n",
      "1197/1197 [==============================] - 0s 399us/step - loss: 0.1262 - acc: 0.9557\n",
      "Epoch 49/64\n",
      "1197/1197 [==============================] - 0s 381us/step - loss: 0.1264 - acc: 0.9566\n",
      "Epoch 50/64\n",
      "1197/1197 [==============================] - 0s 354us/step - loss: 0.1264 - acc: 0.9532\n",
      "Epoch 51/64\n",
      "1197/1197 [==============================] - 0s 366us/step - loss: 0.1271 - acc: 0.9574\n",
      "Epoch 52/64\n",
      "1197/1197 [==============================] - 0s 346us/step - loss: 0.1241 - acc: 0.9557\n",
      "Epoch 53/64\n",
      "1197/1197 [==============================] - 0s 418us/step - loss: 0.1232 - acc: 0.9582\n",
      "Epoch 54/64\n",
      "1197/1197 [==============================] - 1s 432us/step - loss: 0.1219 - acc: 0.9599\n",
      "Epoch 55/64\n",
      "1197/1197 [==============================] - 1s 420us/step - loss: 0.1211 - acc: 0.9557\n",
      "Epoch 56/64\n",
      "1197/1197 [==============================] - 0s 400us/step - loss: 0.1203 - acc: 0.9607\n",
      "Epoch 57/64\n",
      "1197/1197 [==============================] - 0s 391us/step - loss: 0.1183 - acc: 0.9607\n",
      "Epoch 58/64\n",
      "1197/1197 [==============================] - 0s 393us/step - loss: 0.1176 - acc: 0.9591\n",
      "Epoch 59/64\n",
      "1197/1197 [==============================] - 0s 393us/step - loss: 0.1166 - acc: 0.9599\n",
      "Epoch 60/64\n",
      "1197/1197 [==============================] - 0s 354us/step - loss: 0.1177 - acc: 0.9582\n",
      "Epoch 61/64\n",
      "1197/1197 [==============================] - 0s 377us/step - loss: 0.1147 - acc: 0.9599\n",
      "Epoch 62/64\n",
      "1197/1197 [==============================] - 0s 358us/step - loss: 0.1150 - acc: 0.9591\n",
      "Epoch 63/64\n",
      "1197/1197 [==============================] - 0s 336us/step - loss: 0.1120 - acc: 0.9616\n",
      "Epoch 64/64\n",
      "1197/1197 [==============================] - 0s 352us/step - loss: 0.1132 - acc: 0.9616\n",
      "300/300 [==============================] - 1s 2ms/step\n",
      "Epoch 1/64\n",
      "1198/1198 [==============================] - 2s 2ms/step - loss: 0.5612 - acc: 0.8339\n",
      "Epoch 2/64\n",
      "1198/1198 [==============================] - 0s 367us/step - loss: 0.3534 - acc: 0.9040\n",
      "Epoch 3/64\n",
      "1198/1198 [==============================] - 0s 367us/step - loss: 0.2519 - acc: 0.9082\n",
      "Epoch 4/64\n",
      "1198/1198 [==============================] - 0s 357us/step - loss: 0.2208 - acc: 0.9174\n",
      "Epoch 5/64\n",
      "1198/1198 [==============================] - 0s 380us/step - loss: 0.2077 - acc: 0.9190\n",
      "Epoch 6/64\n",
      "1198/1198 [==============================] - 1s 418us/step - loss: 0.2009 - acc: 0.9224\n",
      "Epoch 7/64\n",
      "1198/1198 [==============================] - 0s 376us/step - loss: 0.1980 - acc: 0.9232\n",
      "Epoch 8/64\n",
      "1198/1198 [==============================] - 0s 354us/step - loss: 0.1920 - acc: 0.9265\n",
      "Epoch 9/64\n",
      "1198/1198 [==============================] - 0s 367us/step - loss: 0.1892 - acc: 0.9290\n",
      "Epoch 10/64\n",
      "1198/1198 [==============================] - 0s 366us/step - loss: 0.1870 - acc: 0.9290\n",
      "Epoch 11/64\n",
      "1198/1198 [==============================] - 1s 484us/step - loss: 0.1849 - acc: 0.9249\n",
      "Epoch 12/64\n",
      "1198/1198 [==============================] - 0s 368us/step - loss: 0.1819 - acc: 0.9307\n",
      "Epoch 13/64\n",
      "1198/1198 [==============================] - 0s 366us/step - loss: 0.1797 - acc: 0.9290\n",
      "Epoch 14/64\n",
      "1198/1198 [==============================] - 0s 362us/step - loss: 0.1780 - acc: 0.9299\n",
      "Epoch 15/64\n",
      "1198/1198 [==============================] - 0s 354us/step - loss: 0.1757 - acc: 0.9299\n",
      "Epoch 16/64\n",
      "1198/1198 [==============================] - 0s 353us/step - loss: 0.1736 - acc: 0.9349\n",
      "Epoch 17/64\n",
      "1198/1198 [==============================] - 0s 351us/step - loss: 0.1715 - acc: 0.9332 0s - loss: 0.1724 - acc: 0.9\n",
      "Epoch 18/64\n",
      "1198/1198 [==============================] - 0s 331us/step - loss: 0.1718 - acc: 0.9357\n",
      "Epoch 19/64\n",
      "1198/1198 [==============================] - 0s 337us/step - loss: 0.1698 - acc: 0.9357\n",
      "Epoch 20/64\n",
      "1198/1198 [==============================] - 0s 367us/step - loss: 0.1662 - acc: 0.9349\n",
      "Epoch 21/64\n",
      "1198/1198 [==============================] - 0s 353us/step - loss: 0.1636 - acc: 0.9332\n",
      "Epoch 22/64\n",
      "1198/1198 [==============================] - 0s 355us/step - loss: 0.1622 - acc: 0.9341\n",
      "Epoch 23/64\n",
      "1198/1198 [==============================] - 0s 354us/step - loss: 0.1609 - acc: 0.9374\n",
      "Epoch 24/64\n",
      "1198/1198 [==============================] - 0s 389us/step - loss: 0.1575 - acc: 0.9374\n",
      "Epoch 25/64\n",
      "1198/1198 [==============================] - 0s 339us/step - loss: 0.1581 - acc: 0.9399\n",
      "Epoch 26/64\n",
      "1198/1198 [==============================] - 0s 354us/step - loss: 0.1551 - acc: 0.9407\n",
      "Epoch 27/64\n",
      "1198/1198 [==============================] - 0s 333us/step - loss: 0.1538 - acc: 0.9366\n",
      "Epoch 28/64\n",
      "1198/1198 [==============================] - 0s 311us/step - loss: 0.1512 - acc: 0.9424\n",
      "Epoch 29/64\n",
      "1198/1198 [==============================] - 0s 362us/step - loss: 0.1500 - acc: 0.9399\n",
      "Epoch 30/64\n",
      "1198/1198 [==============================] - 0s 354us/step - loss: 0.1488 - acc: 0.9432\n",
      "Epoch 31/64\n",
      "1198/1198 [==============================] - 0s 353us/step - loss: 0.1457 - acc: 0.9474\n",
      "Epoch 32/64\n",
      "1198/1198 [==============================] - 0s 344us/step - loss: 0.1448 - acc: 0.9432\n",
      "Epoch 33/64\n",
      "1198/1198 [==============================] - 0s 393us/step - loss: 0.1434 - acc: 0.9449\n",
      "Epoch 34/64\n",
      "1198/1198 [==============================] - 0s 393us/step - loss: 0.1419 - acc: 0.9482\n",
      "Epoch 35/64\n",
      "1198/1198 [==============================] - 0s 375us/step - loss: 0.1401 - acc: 0.9449\n",
      "Epoch 36/64\n",
      "1198/1198 [==============================] - 1s 432us/step - loss: 0.1401 - acc: 0.9424\n",
      "Epoch 37/64\n",
      "1198/1198 [==============================] - 1s 445us/step - loss: 0.1377 - acc: 0.9474\n",
      "Epoch 38/64\n",
      "1198/1198 [==============================] - 1s 458us/step - loss: 0.1367 - acc: 0.9482\n",
      "Epoch 39/64\n",
      "1198/1198 [==============================] - 0s 406us/step - loss: 0.1347 - acc: 0.9482\n",
      "Epoch 40/64\n",
      "1198/1198 [==============================] - 0s 366us/step - loss: 0.1318 - acc: 0.9499\n",
      "Epoch 41/64\n",
      "1198/1198 [==============================] - 0s 367us/step - loss: 0.1310 - acc: 0.9533\n",
      "Epoch 42/64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1198/1198 [==============================] - 0s 378us/step - loss: 0.1299 - acc: 0.9533\n",
      "Epoch 43/64\n",
      "1198/1198 [==============================] - 0s 357us/step - loss: 0.1281 - acc: 0.9541\n",
      "Epoch 44/64\n",
      "1198/1198 [==============================] - 0s 342us/step - loss: 0.1262 - acc: 0.9558\n",
      "Epoch 45/64\n",
      "1198/1198 [==============================] - 0s 347us/step - loss: 0.1257 - acc: 0.9516\n",
      "Epoch 46/64\n",
      "1198/1198 [==============================] - 0s 353us/step - loss: 0.1241 - acc: 0.9524\n",
      "Epoch 47/64\n",
      "1198/1198 [==============================] - 0s 368us/step - loss: 0.1233 - acc: 0.9583\n",
      "Epoch 48/64\n",
      "1198/1198 [==============================] - 0s 343us/step - loss: 0.1227 - acc: 0.9583\n",
      "Epoch 49/64\n",
      "1198/1198 [==============================] - 0s 337us/step - loss: 0.1228 - acc: 0.9541\n",
      "Epoch 50/64\n",
      "1198/1198 [==============================] - 0s 341us/step - loss: 0.1201 - acc: 0.9583\n",
      "Epoch 51/64\n",
      "1198/1198 [==============================] - 0s 328us/step - loss: 0.1179 - acc: 0.9599\n",
      "Epoch 52/64\n",
      "1198/1198 [==============================] - 0s 356us/step - loss: 0.1160 - acc: 0.9591\n",
      "Epoch 53/64\n",
      "1198/1198 [==============================] - 0s 330us/step - loss: 0.1176 - acc: 0.9583\n",
      "Epoch 54/64\n",
      "1198/1198 [==============================] - 0s 319us/step - loss: 0.1158 - acc: 0.9608\n",
      "Epoch 55/64\n",
      "1198/1198 [==============================] - 0s 341us/step - loss: 0.1143 - acc: 0.9566\n",
      "Epoch 56/64\n",
      "1198/1198 [==============================] - 0s 348us/step - loss: 0.1128 - acc: 0.9591\n",
      "Epoch 57/64\n",
      "1198/1198 [==============================] - 0s 323us/step - loss: 0.1146 - acc: 0.9591\n",
      "Epoch 58/64\n",
      "1198/1198 [==============================] - 0s 337us/step - loss: 0.1118 - acc: 0.9583\n",
      "Epoch 59/64\n",
      "1198/1198 [==============================] - 0s 328us/step - loss: 0.1109 - acc: 0.9599\n",
      "Epoch 60/64\n",
      "1198/1198 [==============================] - 0s 340us/step - loss: 0.1079 - acc: 0.9591\n",
      "Epoch 61/64\n",
      "1198/1198 [==============================] - 0s 332us/step - loss: 0.1098 - acc: 0.9624\n",
      "Epoch 62/64\n",
      "1198/1198 [==============================] - 0s 322us/step - loss: 0.1069 - acc: 0.9633\n",
      "Epoch 63/64\n",
      "1198/1198 [==============================] - 0s 355us/step - loss: 0.1063 - acc: 0.9641\n",
      "Epoch 64/64\n",
      "1198/1198 [==============================] - 0s 328us/step - loss: 0.1044 - acc: 0.9641\n",
      "299/299 [==============================] - 1s 2ms/step\n",
      "Epoch 1/64\n",
      "1198/1198 [==============================] - 2s 2ms/step - loss: 0.5642 - acc: 0.8606\n",
      "Epoch 2/64\n",
      "1198/1198 [==============================] - 0s 338us/step - loss: 0.3570 - acc: 0.8923\n",
      "Epoch 3/64\n",
      "1198/1198 [==============================] - 0s 320us/step - loss: 0.2669 - acc: 0.8982\n",
      "Epoch 4/64\n",
      "1198/1198 [==============================] - 0s 328us/step - loss: 0.2392 - acc: 0.9048\n",
      "Epoch 5/64\n",
      "1198/1198 [==============================] - 0s 338us/step - loss: 0.2246 - acc: 0.9107\n",
      "Epoch 6/64\n",
      "1198/1198 [==============================] - 0s 332us/step - loss: 0.2163 - acc: 0.9132\n",
      "Epoch 7/64\n",
      "1198/1198 [==============================] - 0s 350us/step - loss: 0.2092 - acc: 0.9182\n",
      "Epoch 8/64\n",
      "1198/1198 [==============================] - 0s 380us/step - loss: 0.2049 - acc: 0.9190\n",
      "Epoch 9/64\n",
      "1198/1198 [==============================] - 1s 483us/step - loss: 0.2000 - acc: 0.9240\n",
      "Epoch 10/64\n",
      "1198/1198 [==============================] - 0s 354us/step - loss: 0.1962 - acc: 0.9249\n",
      "Epoch 11/64\n",
      "1198/1198 [==============================] - 0s 341us/step - loss: 0.1937 - acc: 0.9249\n",
      "Epoch 12/64\n",
      "1198/1198 [==============================] - 0s 352us/step - loss: 0.1912 - acc: 0.9316\n",
      "Epoch 13/64\n",
      "1198/1198 [==============================] - 0s 350us/step - loss: 0.1892 - acc: 0.9290\n",
      "Epoch 14/64\n",
      "1198/1198 [==============================] - 0s 330us/step - loss: 0.1875 - acc: 0.9307\n",
      "Epoch 15/64\n",
      "1198/1198 [==============================] - 0s 341us/step - loss: 0.1875 - acc: 0.9265\n",
      "Epoch 16/64\n",
      "1198/1198 [==============================] - 0s 351us/step - loss: 0.1850 - acc: 0.9349\n",
      "Epoch 17/64\n",
      "1198/1198 [==============================] - 0s 345us/step - loss: 0.1842 - acc: 0.9316\n",
      "Epoch 18/64\n",
      "1198/1198 [==============================] - 0s 337us/step - loss: 0.1814 - acc: 0.9332\n",
      "Epoch 19/64\n",
      "1198/1198 [==============================] - 0s 341us/step - loss: 0.1814 - acc: 0.9357\n",
      "Epoch 20/64\n",
      "1198/1198 [==============================] - 0s 354us/step - loss: 0.1788 - acc: 0.9349\n",
      "Epoch 21/64\n",
      "1198/1198 [==============================] - 0s 343us/step - loss: 0.1763 - acc: 0.9366\n",
      "Epoch 22/64\n",
      "1198/1198 [==============================] - 0s 347us/step - loss: 0.1762 - acc: 0.9316\n",
      "Epoch 23/64\n",
      "1198/1198 [==============================] - 0s 354us/step - loss: 0.1733 - acc: 0.9357\n",
      "Epoch 24/64\n",
      "1198/1198 [==============================] - 0s 341us/step - loss: 0.1732 - acc: 0.9349\n",
      "Epoch 25/64\n",
      "1198/1198 [==============================] - 1s 420us/step - loss: 0.1716 - acc: 0.9357\n",
      "Epoch 26/64\n",
      "1198/1198 [==============================] - 0s 344us/step - loss: 0.1693 - acc: 0.9382\n",
      "Epoch 27/64\n",
      "1198/1198 [==============================] - 0s 350us/step - loss: 0.1688 - acc: 0.9382\n",
      "Epoch 28/64\n",
      "1198/1198 [==============================] - 0s 323us/step - loss: 0.1685 - acc: 0.9341\n",
      "Epoch 29/64\n",
      "1198/1198 [==============================] - 0s 341us/step - loss: 0.1664 - acc: 0.9374\n",
      "Epoch 30/64\n",
      "1198/1198 [==============================] - 0s 354us/step - loss: 0.1663 - acc: 0.9341\n",
      "Epoch 31/64\n",
      "1198/1198 [==============================] - 0s 330us/step - loss: 0.1644 - acc: 0.9416\n",
      "Epoch 32/64\n",
      "1198/1198 [==============================] - 0s 355us/step - loss: 0.1636 - acc: 0.9366\n",
      "Epoch 33/64\n",
      "1198/1198 [==============================] - 0s 349us/step - loss: 0.1622 - acc: 0.9332\n",
      "Epoch 34/64\n",
      "1198/1198 [==============================] - 0s 352us/step - loss: 0.1594 - acc: 0.9391\n",
      "Epoch 35/64\n",
      "1198/1198 [==============================] - 0s 381us/step - loss: 0.1589 - acc: 0.9399\n",
      "Epoch 36/64\n",
      "1198/1198 [==============================] - 0s 390us/step - loss: 0.1577 - acc: 0.9374\n",
      "Epoch 37/64\n",
      "1198/1198 [==============================] - 0s 344us/step - loss: 0.1564 - acc: 0.9391\n",
      "Epoch 38/64\n",
      "1198/1198 [==============================] - 0s 336us/step - loss: 0.1547 - acc: 0.9432\n",
      "Epoch 39/64\n",
      "1198/1198 [==============================] - 0s 367us/step - loss: 0.1577 - acc: 0.9382\n",
      "Epoch 40/64\n",
      "1198/1198 [==============================] - 0s 340us/step - loss: 0.1535 - acc: 0.9441\n",
      "Epoch 41/64\n",
      "1198/1198 [==============================] - 0s 344us/step - loss: 0.1520 - acc: 0.9416\n",
      "Epoch 42/64\n",
      "1198/1198 [==============================] - 0s 342us/step - loss: 0.1511 - acc: 0.9424\n",
      "Epoch 43/64\n",
      "1198/1198 [==============================] - 0s 348us/step - loss: 0.1499 - acc: 0.9407\n",
      "Epoch 44/64\n",
      "1198/1198 [==============================] - 0s 353us/step - loss: 0.1494 - acc: 0.9441\n",
      "Epoch 45/64\n",
      "1198/1198 [==============================] - 0s 342us/step - loss: 0.1483 - acc: 0.9407\n",
      "Epoch 46/64\n",
      "1198/1198 [==============================] - 0s 343us/step - loss: 0.1488 - acc: 0.9416\n",
      "Epoch 47/64\n",
      "1198/1198 [==============================] - 0s 336us/step - loss: 0.1464 - acc: 0.9449\n",
      "Epoch 48/64\n",
      "1198/1198 [==============================] - 0s 344us/step - loss: 0.1448 - acc: 0.9457\n",
      "Epoch 49/64\n",
      "1198/1198 [==============================] - 0s 351us/step - loss: 0.1454 - acc: 0.9466\n",
      "Epoch 50/64\n",
      "1198/1198 [==============================] - 0s 331us/step - loss: 0.1441 - acc: 0.9466\n",
      "Epoch 51/64\n",
      "1198/1198 [==============================] - 0s 354us/step - loss: 0.1421 - acc: 0.9449\n",
      "Epoch 52/64\n",
      "1198/1198 [==============================] - 0s 350us/step - loss: 0.1428 - acc: 0.9449\n",
      "Epoch 53/64\n",
      "1198/1198 [==============================] - 0s 327us/step - loss: 0.1412 - acc: 0.9508\n",
      "Epoch 54/64\n",
      "1198/1198 [==============================] - 0s 341us/step - loss: 0.1400 - acc: 0.9474\n",
      "Epoch 55/64\n",
      "1198/1198 [==============================] - 0s 332us/step - loss: 0.1390 - acc: 0.9474\n",
      "Epoch 56/64\n",
      "1198/1198 [==============================] - 0s 349us/step - loss: 0.1394 - acc: 0.9499\n",
      "Epoch 57/64\n",
      "1198/1198 [==============================] - 0s 338us/step - loss: 0.1364 - acc: 0.9474\n",
      "Epoch 58/64\n",
      "1198/1198 [==============================] - 0s 354us/step - loss: 0.1357 - acc: 0.9474\n",
      "Epoch 59/64\n",
      "1198/1198 [==============================] - 0s 360us/step - loss: 0.1336 - acc: 0.9491\n",
      "Epoch 60/64\n",
      "1198/1198 [==============================] - 0s 347us/step - loss: 0.1336 - acc: 0.9457\n",
      "Epoch 61/64\n",
      "1198/1198 [==============================] - 0s 323us/step - loss: 0.1302 - acc: 0.9533\n",
      "Epoch 62/64\n",
      "1198/1198 [==============================] - 0s 328us/step - loss: 0.1337 - acc: 0.9524\n",
      "Epoch 63/64\n",
      "1198/1198 [==============================] - 0s 324us/step - loss: 0.1312 - acc: 0.9491\n",
      "Epoch 64/64\n",
      "1198/1198 [==============================] - 0s 333us/step - loss: 0.1282 - acc: 0.9499\n",
      "299/299 [==============================] - 1s 2ms/step\n",
      "Epoch 1/64\n",
      "1198/1198 [==============================] - 2s 2ms/step - loss: 0.5832 - acc: 0.6945\n",
      "Epoch 2/64\n",
      "1198/1198 [==============================] - 0s 324us/step - loss: 0.4611 - acc: 0.8965\n",
      "Epoch 3/64\n",
      "1198/1198 [==============================] - 0s 327us/step - loss: 0.3852 - acc: 0.9115\n",
      "Epoch 4/64\n",
      "1198/1198 [==============================] - 0s 341us/step - loss: 0.3131 - acc: 0.9090\n",
      "Epoch 5/64\n",
      "1198/1198 [==============================] - 0s 345us/step - loss: 0.2621 - acc: 0.9115\n",
      "Epoch 6/64\n",
      "1198/1198 [==============================] - 0s 353us/step - loss: 0.2340 - acc: 0.9140\n",
      "Epoch 7/64\n",
      "1198/1198 [==============================] - 0s 336us/step - loss: 0.2224 - acc: 0.9115\n",
      "Epoch 8/64\n",
      "1198/1198 [==============================] - 0s 354us/step - loss: 0.2138 - acc: 0.9149\n",
      "Epoch 9/64\n",
      "1198/1198 [==============================] - 0s 354us/step - loss: 0.2061 - acc: 0.9182\n",
      "Epoch 10/64\n",
      "1198/1198 [==============================] - 0s 330us/step - loss: 0.2031 - acc: 0.9199\n",
      "Epoch 11/64\n",
      "1198/1198 [==============================] - 0s 336us/step - loss: 0.1997 - acc: 0.9207\n",
      "Epoch 12/64\n",
      "1198/1198 [==============================] - 0s 353us/step - loss: 0.1969 - acc: 0.9224\n",
      "Epoch 13/64\n",
      "1198/1198 [==============================] - 0s 354us/step - loss: 0.1931 - acc: 0.9207\n",
      "Epoch 14/64\n",
      "1198/1198 [==============================] - 0s 354us/step - loss: 0.1907 - acc: 0.9290\n",
      "Epoch 15/64\n",
      "1198/1198 [==============================] - 0s 344us/step - loss: 0.1869 - acc: 0.9265\n",
      "Epoch 16/64\n",
      "1198/1198 [==============================] - 0s 367us/step - loss: 0.1865 - acc: 0.9240\n",
      "Epoch 17/64\n",
      "1198/1198 [==============================] - 0s 360us/step - loss: 0.1840 - acc: 0.9282\n",
      "Epoch 18/64\n",
      "1198/1198 [==============================] - 0s 367us/step - loss: 0.1834 - acc: 0.9290\n",
      "Epoch 19/64\n",
      "1198/1198 [==============================] - 0s 353us/step - loss: 0.1813 - acc: 0.9282\n",
      "Epoch 20/64\n",
      "1198/1198 [==============================] - 0s 357us/step - loss: 0.1789 - acc: 0.9290\n",
      "Epoch 21/64\n",
      "1198/1198 [==============================] - 0s 368us/step - loss: 0.1785 - acc: 0.9282\n",
      "Epoch 22/64\n",
      "1198/1198 [==============================] - 0s 347us/step - loss: 0.1776 - acc: 0.9349\n",
      "Epoch 23/64\n",
      "1198/1198 [==============================] - 0s 367us/step - loss: 0.1747 - acc: 0.9299\n",
      "Epoch 24/64\n",
      "1198/1198 [==============================] - 0s 380us/step - loss: 0.1744 - acc: 0.9290\n",
      "Epoch 25/64\n",
      "1198/1198 [==============================] - 0s 368us/step - loss: 0.1727 - acc: 0.9324\n",
      "Epoch 26/64\n",
      "1198/1198 [==============================] - 0s 381us/step - loss: 0.1706 - acc: 0.9357\n",
      "Epoch 27/64\n",
      "1198/1198 [==============================] - 0s 367us/step - loss: 0.1697 - acc: 0.9374\n",
      "Epoch 28/64\n",
      "1198/1198 [==============================] - 0s 362us/step - loss: 0.1698 - acc: 0.9299\n",
      "Epoch 29/64\n",
      "1198/1198 [==============================] - 0s 367us/step - loss: 0.1689 - acc: 0.9349\n",
      "Epoch 30/64\n",
      "1198/1198 [==============================] - 1s 419us/step - loss: 0.1670 - acc: 0.9399\n",
      "Epoch 31/64\n",
      "1198/1198 [==============================] - 0s 354us/step - loss: 0.1649 - acc: 0.9399\n",
      "Epoch 32/64\n",
      "1198/1198 [==============================] - 0s 357us/step - loss: 0.1649 - acc: 0.9374\n",
      "Epoch 33/64\n",
      "1198/1198 [==============================] - 0s 341us/step - loss: 0.1639 - acc: 0.9391\n",
      "Epoch 34/64\n",
      "1198/1198 [==============================] - 0s 348us/step - loss: 0.1627 - acc: 0.9407\n",
      "Epoch 35/64\n",
      "1198/1198 [==============================] - 0s 354us/step - loss: 0.1618 - acc: 0.9416\n",
      "Epoch 36/64\n",
      "1198/1198 [==============================] - 0s 341us/step - loss: 0.1605 - acc: 0.9416\n",
      "Epoch 37/64\n",
      "1198/1198 [==============================] - 0s 358us/step - loss: 0.1606 - acc: 0.9399\n",
      "Epoch 38/64\n",
      "1198/1198 [==============================] - 0s 379us/step - loss: 0.1591 - acc: 0.9407\n",
      "Epoch 39/64\n",
      "1198/1198 [==============================] - 1s 427us/step - loss: 0.1585 - acc: 0.9416\n",
      "Epoch 40/64\n",
      "1198/1198 [==============================] - 0s 338us/step - loss: 0.1560 - acc: 0.9441\n",
      "Epoch 41/64\n",
      "1198/1198 [==============================] - 0s 354us/step - loss: 0.1587 - acc: 0.9399\n",
      "Epoch 42/64\n",
      "1198/1198 [==============================] - 0s 393us/step - loss: 0.1570 - acc: 0.9407\n",
      "Epoch 43/64\n",
      "1198/1198 [==============================] - 0s 344us/step - loss: 0.1574 - acc: 0.9441\n",
      "Epoch 44/64\n",
      "1198/1198 [==============================] - 0s 341us/step - loss: 0.1539 - acc: 0.9441\n",
      "Epoch 45/64\n",
      "1198/1198 [==============================] - 0s 349us/step - loss: 0.1537 - acc: 0.9474\n",
      "Epoch 46/64\n",
      "1198/1198 [==============================] - 0s 341us/step - loss: 0.1533 - acc: 0.9457\n",
      "Epoch 47/64\n",
      "1198/1198 [==============================] - 0s 341us/step - loss: 0.1519 - acc: 0.9457\n",
      "Epoch 48/64\n",
      "1198/1198 [==============================] - 0s 362us/step - loss: 0.1515 - acc: 0.9466\n",
      "Epoch 49/64\n",
      "1198/1198 [==============================] - 0s 361us/step - loss: 0.1496 - acc: 0.9474\n",
      "Epoch 50/64\n",
      "1198/1198 [==============================] - 0s 350us/step - loss: 0.1497 - acc: 0.9491\n",
      "Epoch 51/64\n",
      "1198/1198 [==============================] - 0s 366us/step - loss: 0.1501 - acc: 0.9482\n",
      "Epoch 52/64\n",
      "1198/1198 [==============================] - 0s 354us/step - loss: 0.1488 - acc: 0.9457\n",
      "Epoch 53/64\n",
      "1198/1198 [==============================] - 0s 406us/step - loss: 0.1465 - acc: 0.9508\n",
      "Epoch 54/64\n",
      "1198/1198 [==============================] - 0s 357us/step - loss: 0.1454 - acc: 0.9482\n",
      "Epoch 55/64\n",
      "1198/1198 [==============================] - 0s 361us/step - loss: 0.1472 - acc: 0.9466\n",
      "Epoch 56/64\n",
      "1198/1198 [==============================] - 0s 355us/step - loss: 0.1443 - acc: 0.9508\n",
      "Epoch 57/64\n",
      "1198/1198 [==============================] - 0s 353us/step - loss: 0.1433 - acc: 0.9524\n",
      "Epoch 58/64\n",
      "1198/1198 [==============================] - 0s 354us/step - loss: 0.1437 - acc: 0.9524\n",
      "Epoch 59/64\n",
      "1198/1198 [==============================] - 0s 358us/step - loss: 0.1414 - acc: 0.9482\n",
      "Epoch 60/64\n",
      "1198/1198 [==============================] - 0s 366us/step - loss: 0.1419 - acc: 0.9524\n",
      "Epoch 61/64\n",
      "1198/1198 [==============================] - 0s 349us/step - loss: 0.1418 - acc: 0.9499\n",
      "Epoch 62/64\n",
      "1198/1198 [==============================] - 0s 368us/step - loss: 0.1411 - acc: 0.9491\n",
      "Epoch 63/64\n",
      "1198/1198 [==============================] - 0s 353us/step - loss: 0.1394 - acc: 0.9524\n",
      "Epoch 64/64\n",
      "1198/1198 [==============================] - 0s 357us/step - loss: 0.1401 - acc: 0.9533\n",
      "299/299 [==============================] - 1s 2ms/step\n",
      "Epoch 1/64\n",
      "1197/1197 [==============================] - 2s 2ms/step - loss: 0.5807 - acc: 0.8413\n",
      "Epoch 2/64\n",
      "1197/1197 [==============================] - 0s 337us/step - loss: 0.4335 - acc: 0.8972\n",
      "Epoch 3/64\n",
      "1197/1197 [==============================] - 0s 328us/step - loss: 0.3448 - acc: 0.9039\n",
      "Epoch 4/64\n",
      "1197/1197 [==============================] - 0s 341us/step - loss: 0.2880 - acc: 0.9048\n",
      "Epoch 5/64\n",
      "1197/1197 [==============================] - 0s 331us/step - loss: 0.2560 - acc: 0.9048\n",
      "Epoch 6/64\n",
      "1197/1197 [==============================] - 0s 353us/step - loss: 0.2379 - acc: 0.9056\n",
      "Epoch 7/64\n",
      "1197/1197 [==============================] - 0s 348us/step - loss: 0.2279 - acc: 0.9089\n",
      "Epoch 8/64\n",
      "1197/1197 [==============================] - 0s 315us/step - loss: 0.2210 - acc: 0.9098\n",
      "Epoch 9/64\n",
      "1197/1197 [==============================] - 0s 367us/step - loss: 0.2163 - acc: 0.9106\n",
      "Epoch 10/64\n",
      "1197/1197 [==============================] - 0s 317us/step - loss: 0.2121 - acc: 0.9140\n",
      "Epoch 11/64\n",
      "1197/1197 [==============================] - 0s 337us/step - loss: 0.2103 - acc: 0.9173\n",
      "Epoch 12/64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1197/1197 [==============================] - 0s 314us/step - loss: 0.2085 - acc: 0.9173\n",
      "Epoch 13/64\n",
      "1197/1197 [==============================] - 0s 332us/step - loss: 0.2050 - acc: 0.9181\n",
      "Epoch 14/64\n",
      "1197/1197 [==============================] - 0s 328us/step - loss: 0.2046 - acc: 0.9165\n",
      "Epoch 15/64\n",
      "1197/1197 [==============================] - 0s 334us/step - loss: 0.2022 - acc: 0.9140\n",
      "Epoch 16/64\n",
      "1197/1197 [==============================] - 0s 328us/step - loss: 0.2015 - acc: 0.9181\n",
      "Epoch 17/64\n",
      "1197/1197 [==============================] - 0s 344us/step - loss: 0.1983 - acc: 0.9173\n",
      "Epoch 18/64\n",
      "1197/1197 [==============================] - 0s 328us/step - loss: 0.1979 - acc: 0.9165\n",
      "Epoch 19/64\n",
      "1197/1197 [==============================] - 0s 336us/step - loss: 0.1960 - acc: 0.9173\n",
      "Epoch 20/64\n",
      "1197/1197 [==============================] - 0s 328us/step - loss: 0.1954 - acc: 0.9223\n",
      "Epoch 21/64\n",
      "1197/1197 [==============================] - 0s 319us/step - loss: 0.1926 - acc: 0.9190\n",
      "Epoch 22/64\n",
      "1197/1197 [==============================] - 0s 340us/step - loss: 0.1925 - acc: 0.9198\n",
      "Epoch 23/64\n",
      "1197/1197 [==============================] - 0s 337us/step - loss: 0.1923 - acc: 0.9215\n",
      "Epoch 24/64\n",
      "1197/1197 [==============================] - 0s 341us/step - loss: 0.1910 - acc: 0.9215\n",
      "Epoch 25/64\n",
      "1197/1197 [==============================] - 0s 351us/step - loss: 0.1897 - acc: 0.9215\n",
      "Epoch 26/64\n",
      "1197/1197 [==============================] - 0s 333us/step - loss: 0.1882 - acc: 0.9240\n",
      "Epoch 27/64\n",
      "1197/1197 [==============================] - 0s 348us/step - loss: 0.1876 - acc: 0.9240\n",
      "Epoch 28/64\n",
      "1197/1197 [==============================] - 0s 354us/step - loss: 0.1862 - acc: 0.9273\n",
      "Epoch 29/64\n",
      "1197/1197 [==============================] - 0s 341us/step - loss: 0.1866 - acc: 0.9256\n",
      "Epoch 30/64\n",
      "1197/1197 [==============================] - 0s 331us/step - loss: 0.1845 - acc: 0.9231\n",
      "Epoch 31/64\n",
      "1197/1197 [==============================] - 0s 339us/step - loss: 0.1845 - acc: 0.9231\n",
      "Epoch 32/64\n",
      "1197/1197 [==============================] - 0s 337us/step - loss: 0.1827 - acc: 0.9223\n",
      "Epoch 33/64\n",
      "1197/1197 [==============================] - 0s 328us/step - loss: 0.1827 - acc: 0.9206\n",
      "Epoch 34/64\n",
      "1197/1197 [==============================] - 0s 359us/step - loss: 0.1806 - acc: 0.9248\n",
      "Epoch 35/64\n",
      "1197/1197 [==============================] - 0s 338us/step - loss: 0.1826 - acc: 0.9265\n",
      "Epoch 36/64\n",
      "1197/1197 [==============================] - 0s 337us/step - loss: 0.1784 - acc: 0.9273\n",
      "Epoch 37/64\n",
      "1197/1197 [==============================] - 0s 341us/step - loss: 0.1790 - acc: 0.9273\n",
      "Epoch 38/64\n",
      "1197/1197 [==============================] - 0s 327us/step - loss: 0.1789 - acc: 0.9273\n",
      "Epoch 39/64\n",
      "1197/1197 [==============================] - 0s 345us/step - loss: 0.1770 - acc: 0.9282\n",
      "Epoch 40/64\n",
      "1197/1197 [==============================] - 0s 335us/step - loss: 0.1771 - acc: 0.9265\n",
      "Epoch 41/64\n",
      "1197/1197 [==============================] - 0s 342us/step - loss: 0.1751 - acc: 0.9256\n",
      "Epoch 42/64\n",
      "1197/1197 [==============================] - 0s 340us/step - loss: 0.1747 - acc: 0.9315\n",
      "Epoch 43/64\n",
      "1197/1197 [==============================] - 0s 400us/step - loss: 0.1746 - acc: 0.9315\n",
      "Epoch 44/64\n",
      "1197/1197 [==============================] - 0s 337us/step - loss: 0.1735 - acc: 0.9298\n",
      "Epoch 45/64\n",
      "1197/1197 [==============================] - 0s 336us/step - loss: 0.1734 - acc: 0.9265\n",
      "Epoch 46/64\n",
      "1197/1197 [==============================] - 0s 341us/step - loss: 0.1716 - acc: 0.9298\n",
      "Epoch 47/64\n",
      "1197/1197 [==============================] - 0s 329us/step - loss: 0.1721 - acc: 0.9265\n",
      "Epoch 48/64\n",
      "1197/1197 [==============================] - 0s 331us/step - loss: 0.1700 - acc: 0.9282\n",
      "Epoch 49/64\n",
      "1197/1197 [==============================] - 0s 324us/step - loss: 0.1695 - acc: 0.9332\n",
      "Epoch 50/64\n",
      "1197/1197 [==============================] - 0s 328us/step - loss: 0.1695 - acc: 0.9307\n",
      "Epoch 51/64\n",
      "1197/1197 [==============================] - 0s 332us/step - loss: 0.1688 - acc: 0.9282\n",
      "Epoch 52/64\n",
      "1197/1197 [==============================] - 0s 326us/step - loss: 0.1669 - acc: 0.9282\n",
      "Epoch 53/64\n",
      "1197/1197 [==============================] - 0s 335us/step - loss: 0.1682 - acc: 0.9290\n",
      "Epoch 54/64\n",
      "1197/1197 [==============================] - 0s 328us/step - loss: 0.1663 - acc: 0.9307\n",
      "Epoch 55/64\n",
      "1197/1197 [==============================] - 0s 318us/step - loss: 0.1662 - acc: 0.9332\n",
      "Epoch 56/64\n",
      "1197/1197 [==============================] - 0s 341us/step - loss: 0.1661 - acc: 0.9315\n",
      "Epoch 57/64\n",
      "1197/1197 [==============================] - 0s 336us/step - loss: 0.1635 - acc: 0.9365\n",
      "Epoch 58/64\n",
      "1197/1197 [==============================] - 0s 341us/step - loss: 0.1642 - acc: 0.9323\n",
      "Epoch 59/64\n",
      "1197/1197 [==============================] - 0s 341us/step - loss: 0.1652 - acc: 0.9298\n",
      "Epoch 60/64\n",
      "1197/1197 [==============================] - 0s 319us/step - loss: 0.1635 - acc: 0.9348\n",
      "Epoch 61/64\n",
      "1197/1197 [==============================] - 0s 335us/step - loss: 0.1631 - acc: 0.9332\n",
      "Epoch 62/64\n",
      "1197/1197 [==============================] - 0s 328us/step - loss: 0.1623 - acc: 0.9298\n",
      "Epoch 63/64\n",
      "1197/1197 [==============================] - 0s 329us/step - loss: 0.1610 - acc: 0.9307\n",
      "Epoch 64/64\n",
      "1197/1197 [==============================] - 0s 330us/step - loss: 0.1611 - acc: 0.9273\n",
      "300/300 [==============================] - 1s 2ms/step\n",
      "Epoch 1/64\n",
      "1197/1197 [==============================] - 2s 2ms/step - loss: 0.5880 - acc: 0.8588\n",
      "Epoch 2/64\n",
      "1197/1197 [==============================] - 0s 309us/step - loss: 0.3827 - acc: 0.8989\n",
      "Epoch 3/64\n",
      "1197/1197 [==============================] - 0s 354us/step - loss: 0.2653 - acc: 0.9056\n",
      "Epoch 4/64\n",
      "1197/1197 [==============================] - 0s 341us/step - loss: 0.2277 - acc: 0.9089\n",
      "Epoch 5/64\n",
      "1197/1197 [==============================] - 0s 330us/step - loss: 0.2159 - acc: 0.9140\n",
      "Epoch 6/64\n",
      "1197/1197 [==============================] - 0s 337us/step - loss: 0.2087 - acc: 0.9148\n",
      "Epoch 7/64\n",
      "1197/1197 [==============================] - 0s 328us/step - loss: 0.2046 - acc: 0.9173\n",
      "Epoch 8/64\n",
      "1197/1197 [==============================] - 0s 354us/step - loss: 0.2003 - acc: 0.9181\n",
      "Epoch 9/64\n",
      "1197/1197 [==============================] - 0s 331us/step - loss: 0.1984 - acc: 0.9215\n",
      "Epoch 10/64\n",
      "1197/1197 [==============================] - 0s 336us/step - loss: 0.1957 - acc: 0.9198\n",
      "Epoch 11/64\n",
      "1197/1197 [==============================] - 0s 341us/step - loss: 0.1942 - acc: 0.9198\n",
      "Epoch 12/64\n",
      "1197/1197 [==============================] - 0s 328us/step - loss: 0.1908 - acc: 0.9240\n",
      "Epoch 13/64\n",
      "1197/1197 [==============================] - 0s 344us/step - loss: 0.1888 - acc: 0.9273\n",
      "Epoch 14/64\n",
      "1197/1197 [==============================] - 0s 324us/step - loss: 0.1875 - acc: 0.9290\n",
      "Epoch 15/64\n",
      "1197/1197 [==============================] - 0s 353us/step - loss: 0.1850 - acc: 0.9307\n",
      "Epoch 16/64\n",
      "1197/1197 [==============================] - 0s 328us/step - loss: 0.1827 - acc: 0.9298\n",
      "Epoch 17/64\n",
      "1197/1197 [==============================] - 0s 330us/step - loss: 0.1820 - acc: 0.9315\n",
      "Epoch 18/64\n",
      "1197/1197 [==============================] - 0s 354us/step - loss: 0.1783 - acc: 0.9340\n",
      "Epoch 19/64\n",
      "1197/1197 [==============================] - 0s 337us/step - loss: 0.1775 - acc: 0.9340\n",
      "Epoch 20/64\n",
      "1197/1197 [==============================] - 0s 341us/step - loss: 0.1758 - acc: 0.9340\n",
      "Epoch 21/64\n",
      "1197/1197 [==============================] - 0s 334us/step - loss: 0.1728 - acc: 0.9357\n",
      "Epoch 22/64\n",
      "1197/1197 [==============================] - 0s 322us/step - loss: 0.1724 - acc: 0.9357\n",
      "Epoch 23/64\n",
      "1197/1197 [==============================] - 0s 349us/step - loss: 0.1706 - acc: 0.9390\n",
      "Epoch 24/64\n",
      "1197/1197 [==============================] - 0s 328us/step - loss: 0.1689 - acc: 0.9373\n",
      "Epoch 25/64\n",
      "1197/1197 [==============================] - 0s 354us/step - loss: 0.1682 - acc: 0.9365\n",
      "Epoch 26/64\n",
      "1197/1197 [==============================] - 0s 332us/step - loss: 0.1668 - acc: 0.9373\n",
      "Epoch 27/64\n",
      "1197/1197 [==============================] - 0s 334us/step - loss: 0.1650 - acc: 0.9415\n",
      "Epoch 28/64\n",
      "1197/1197 [==============================] - 0s 341us/step - loss: 0.1642 - acc: 0.9357\n",
      "Epoch 29/64\n",
      "1197/1197 [==============================] - 0s 341us/step - loss: 0.1627 - acc: 0.9424\n",
      "Epoch 30/64\n",
      "1197/1197 [==============================] - 0s 344us/step - loss: 0.1618 - acc: 0.9390\n",
      "Epoch 31/64\n",
      "1197/1197 [==============================] - 0s 341us/step - loss: 0.1607 - acc: 0.9390\n",
      "Epoch 32/64\n",
      "1197/1197 [==============================] - 0s 348us/step - loss: 0.1586 - acc: 0.9373\n",
      "Epoch 33/64\n",
      "1197/1197 [==============================] - 0s 328us/step - loss: 0.1581 - acc: 0.9424\n",
      "Epoch 34/64\n",
      "1197/1197 [==============================] - 0s 331us/step - loss: 0.1566 - acc: 0.9465\n",
      "Epoch 35/64\n",
      "1197/1197 [==============================] - 0s 341us/step - loss: 0.1555 - acc: 0.9432\n",
      "Epoch 36/64\n",
      "1197/1197 [==============================] - 0s 323us/step - loss: 0.1543 - acc: 0.9424\n",
      "Epoch 37/64\n",
      "1197/1197 [==============================] - 0s 367us/step - loss: 0.1532 - acc: 0.9390\n",
      "Epoch 38/64\n",
      "1197/1197 [==============================] - 1s 550us/step - loss: 0.1528 - acc: 0.9398\n",
      "Epoch 39/64\n",
      "1197/1197 [==============================] - 1s 476us/step - loss: 0.1502 - acc: 0.9415\n",
      "Epoch 40/64\n",
      "1197/1197 [==============================] - 0s 397us/step - loss: 0.1501 - acc: 0.9457\n",
      "Epoch 41/64\n",
      "1197/1197 [==============================] - 0s 395us/step - loss: 0.1492 - acc: 0.9440\n",
      "Epoch 42/64\n",
      "1197/1197 [==============================] - 0s 367us/step - loss: 0.1485 - acc: 0.9390\n",
      "Epoch 43/64\n",
      "1197/1197 [==============================] - 0s 354us/step - loss: 0.1477 - acc: 0.9449\n",
      "Epoch 44/64\n",
      "1197/1197 [==============================] - 0s 344us/step - loss: 0.1454 - acc: 0.9440\n",
      "Epoch 45/64\n",
      "1197/1197 [==============================] - 0s 358us/step - loss: 0.1449 - acc: 0.9490\n",
      "Epoch 46/64\n",
      "1197/1197 [==============================] - 0s 358us/step - loss: 0.1449 - acc: 0.9457\n",
      "Epoch 47/64\n",
      "1197/1197 [==============================] - 0s 393us/step - loss: 0.1439 - acc: 0.9474\n",
      "Epoch 48/64\n",
      "1197/1197 [==============================] - 0s 380us/step - loss: 0.1414 - acc: 0.9490\n",
      "Epoch 49/64\n",
      "1197/1197 [==============================] - 0s 347us/step - loss: 0.1378 - acc: 0.9457\n",
      "Epoch 50/64\n",
      "1197/1197 [==============================] - 0s 338us/step - loss: 0.1387 - acc: 0.9499\n",
      "Epoch 51/64\n",
      "1197/1197 [==============================] - 0s 335us/step - loss: 0.1385 - acc: 0.9474\n",
      "Epoch 52/64\n",
      "1197/1197 [==============================] - 0s 345us/step - loss: 0.1374 - acc: 0.9474\n",
      "Epoch 53/64\n",
      "1197/1197 [==============================] - 0s 337us/step - loss: 0.1351 - acc: 0.9490\n",
      "Epoch 54/64\n",
      "1197/1197 [==============================] - 0s 331us/step - loss: 0.1334 - acc: 0.9499\n",
      "Epoch 55/64\n",
      "1197/1197 [==============================] - 0s 352us/step - loss: 0.1324 - acc: 0.9515\n",
      "Epoch 56/64\n",
      "1197/1197 [==============================] - 0s 325us/step - loss: 0.1325 - acc: 0.9515\n",
      "Epoch 57/64\n",
      "1197/1197 [==============================] - 0s 341us/step - loss: 0.1320 - acc: 0.9524\n",
      "Epoch 58/64\n",
      "1197/1197 [==============================] - 0s 350us/step - loss: 0.1299 - acc: 0.9532\n",
      "Epoch 59/64\n",
      "1197/1197 [==============================] - 0s 335us/step - loss: 0.1288 - acc: 0.9541\n",
      "Epoch 60/64\n",
      "1197/1197 [==============================] - 0s 348us/step - loss: 0.1277 - acc: 0.9507\n",
      "Epoch 61/64\n",
      "1197/1197 [==============================] - 0s 328us/step - loss: 0.1280 - acc: 0.9515\n",
      "Epoch 62/64\n",
      "1197/1197 [==============================] - 0s 329us/step - loss: 0.1263 - acc: 0.9557\n",
      "Epoch 63/64\n",
      "1197/1197 [==============================] - 0s 331us/step - loss: 0.1255 - acc: 0.9566\n",
      "Epoch 64/64\n",
      "1197/1197 [==============================] - 0s 337us/step - loss: 0.1236 - acc: 0.9566\n",
      "300/300 [==============================] - 1s 2ms/step\n",
      "Epoch 1/64\n",
      "1198/1198 [==============================] - 2s 2ms/step - loss: 0.6080 - acc: 0.8214\n",
      "Epoch 2/64\n",
      "1198/1198 [==============================] - 0s 326us/step - loss: 0.3915 - acc: 0.8932\n",
      "Epoch 3/64\n",
      "1198/1198 [==============================] - 0s 336us/step - loss: 0.2679 - acc: 0.9015\n",
      "Epoch 4/64\n",
      "1198/1198 [==============================] - 0s 342us/step - loss: 0.2293 - acc: 0.9057\n",
      "Epoch 5/64\n",
      "1198/1198 [==============================] - 0s 330us/step - loss: 0.2145 - acc: 0.9107\n",
      "Epoch 6/64\n",
      "1198/1198 [==============================] - 0s 354us/step - loss: 0.2057 - acc: 0.9157\n",
      "Epoch 7/64\n",
      "1198/1198 [==============================] - 0s 323us/step - loss: 0.2002 - acc: 0.9165\n",
      "Epoch 8/64\n",
      "1198/1198 [==============================] - 0s 328us/step - loss: 0.1965 - acc: 0.9182\n",
      "Epoch 9/64\n",
      "1198/1198 [==============================] - 0s 333us/step - loss: 0.1916 - acc: 0.9215\n",
      "Epoch 10/64\n",
      "1198/1198 [==============================] - 0s 311us/step - loss: 0.1899 - acc: 0.9249\n",
      "Epoch 11/64\n",
      "1198/1198 [==============================] - 0s 376us/step - loss: 0.1870 - acc: 0.9249\n",
      "Epoch 12/64\n",
      "1198/1198 [==============================] - 0s 341us/step - loss: 0.1845 - acc: 0.9249\n",
      "Epoch 13/64\n",
      "1198/1198 [==============================] - 0s 340us/step - loss: 0.1817 - acc: 0.9307\n",
      "Epoch 14/64\n",
      "1198/1198 [==============================] - 0s 331us/step - loss: 0.1810 - acc: 0.9290\n",
      "Epoch 15/64\n",
      "1198/1198 [==============================] - 0s 336us/step - loss: 0.1787 - acc: 0.9349\n",
      "Epoch 16/64\n",
      "1198/1198 [==============================] - 0s 314us/step - loss: 0.1757 - acc: 0.9382\n",
      "Epoch 17/64\n",
      "1198/1198 [==============================] - 0s 328us/step - loss: 0.1749 - acc: 0.9374\n",
      "Epoch 18/64\n",
      "1198/1198 [==============================] - 0s 317us/step - loss: 0.1735 - acc: 0.9374\n",
      "Epoch 19/64\n",
      "1198/1198 [==============================] - 0s 323us/step - loss: 0.1712 - acc: 0.9391\n",
      "Epoch 20/64\n",
      "1198/1198 [==============================] - 0s 340us/step - loss: 0.1710 - acc: 0.9407\n",
      "Epoch 21/64\n",
      "1198/1198 [==============================] - 0s 328us/step - loss: 0.1682 - acc: 0.9457\n",
      "Epoch 22/64\n",
      "1198/1198 [==============================] - 0s 332us/step - loss: 0.1681 - acc: 0.9357\n",
      "Epoch 23/64\n",
      "1198/1198 [==============================] - 0s 341us/step - loss: 0.1662 - acc: 0.9424\n",
      "Epoch 24/64\n",
      "1198/1198 [==============================] - 0s 334us/step - loss: 0.1666 - acc: 0.9407\n",
      "Epoch 25/64\n",
      "1198/1198 [==============================] - 0s 341us/step - loss: 0.1647 - acc: 0.9416\n",
      "Epoch 26/64\n",
      "1198/1198 [==============================] - 0s 330us/step - loss: 0.1638 - acc: 0.9432\n",
      "Epoch 27/64\n",
      "1198/1198 [==============================] - 0s 340us/step - loss: 0.1621 - acc: 0.9416\n",
      "Epoch 28/64\n",
      "1198/1198 [==============================] - 0s 323us/step - loss: 0.1621 - acc: 0.9449\n",
      "Epoch 29/64\n",
      "1198/1198 [==============================] - 0s 341us/step - loss: 0.1603 - acc: 0.9449\n",
      "Epoch 30/64\n",
      "1198/1198 [==============================] - 0s 334us/step - loss: 0.1593 - acc: 0.9441\n",
      "Epoch 31/64\n",
      "1198/1198 [==============================] - 0s 336us/step - loss: 0.1566 - acc: 0.9449\n",
      "Epoch 32/64\n",
      "1198/1198 [==============================] - 0s 337us/step - loss: 0.1565 - acc: 0.9491\n",
      "Epoch 33/64\n",
      "1198/1198 [==============================] - 0s 379us/step - loss: 0.1568 - acc: 0.9449\n",
      "Epoch 34/64\n",
      "1198/1198 [==============================] - 0s 341us/step - loss: 0.1545 - acc: 0.9441\n",
      "Epoch 35/64\n",
      "1198/1198 [==============================] - 0s 345us/step - loss: 0.1539 - acc: 0.9441\n",
      "Epoch 36/64\n",
      "1198/1198 [==============================] - 0s 379us/step - loss: 0.1520 - acc: 0.9457\n",
      "Epoch 37/64\n",
      "1198/1198 [==============================] - 0s 350us/step - loss: 0.1518 - acc: 0.9499\n",
      "Epoch 38/64\n",
      "1198/1198 [==============================] - 0s 341us/step - loss: 0.1505 - acc: 0.9499\n",
      "Epoch 39/64\n",
      "1198/1198 [==============================] - 0s 340us/step - loss: 0.1507 - acc: 0.9474\n",
      "Epoch 40/64\n",
      "1198/1198 [==============================] - 0s 345us/step - loss: 0.1480 - acc: 0.9482\n",
      "Epoch 41/64\n",
      "1198/1198 [==============================] - 0s 334us/step - loss: 0.1474 - acc: 0.9466\n",
      "Epoch 42/64\n",
      "1198/1198 [==============================] - 0s 340us/step - loss: 0.1466 - acc: 0.9457\n",
      "Epoch 43/64\n",
      "1198/1198 [==============================] - 0s 354us/step - loss: 0.1459 - acc: 0.9499\n",
      "Epoch 44/64\n",
      "1198/1198 [==============================] - 0s 350us/step - loss: 0.1444 - acc: 0.9457\n",
      "Epoch 45/64\n",
      "1198/1198 [==============================] - 0s 345us/step - loss: 0.1437 - acc: 0.9491\n",
      "Epoch 46/64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1198/1198 [==============================] - 0s 336us/step - loss: 0.1425 - acc: 0.9466\n",
      "Epoch 47/64\n",
      "1198/1198 [==============================] - 0s 327us/step - loss: 0.1403 - acc: 0.9491\n",
      "Epoch 48/64\n",
      "1198/1198 [==============================] - 0s 329us/step - loss: 0.1415 - acc: 0.9482\n",
      "Epoch 49/64\n",
      "1198/1198 [==============================] - 0s 330us/step - loss: 0.1388 - acc: 0.9508\n",
      "Epoch 50/64\n",
      "1198/1198 [==============================] - 0s 323us/step - loss: 0.1398 - acc: 0.9516\n",
      "Epoch 51/64\n",
      "1198/1198 [==============================] - 0s 328us/step - loss: 0.1388 - acc: 0.9508\n",
      "Epoch 52/64\n",
      "1198/1198 [==============================] - 0s 353us/step - loss: 0.1367 - acc: 0.9533\n",
      "Epoch 53/64\n",
      "1198/1198 [==============================] - 0s 399us/step - loss: 0.1355 - acc: 0.9466\n",
      "Epoch 54/64\n",
      "1198/1198 [==============================] - 0s 337us/step - loss: 0.1353 - acc: 0.9499\n",
      "Epoch 55/64\n",
      "1198/1198 [==============================] - 0s 361us/step - loss: 0.1329 - acc: 0.9516\n",
      "Epoch 56/64\n",
      "1198/1198 [==============================] - 0s 341us/step - loss: 0.1331 - acc: 0.9533\n",
      "Epoch 57/64\n",
      "1198/1198 [==============================] - 0s 341us/step - loss: 0.1314 - acc: 0.9524\n",
      "Epoch 58/64\n",
      "1198/1198 [==============================] - 0s 330us/step - loss: 0.1317 - acc: 0.9549\n",
      "Epoch 59/64\n",
      "1198/1198 [==============================] - 0s 336us/step - loss: 0.1294 - acc: 0.9541\n",
      "Epoch 60/64\n",
      "1198/1198 [==============================] - 0s 328us/step - loss: 0.1274 - acc: 0.9558\n",
      "Epoch 61/64\n",
      "1198/1198 [==============================] - 0s 341us/step - loss: 0.1280 - acc: 0.9524\n",
      "Epoch 62/64\n",
      "1198/1198 [==============================] - 0s 330us/step - loss: 0.1255 - acc: 0.9558\n",
      "Epoch 63/64\n",
      "1198/1198 [==============================] - 0s 355us/step - loss: 0.1248 - acc: 0.9574\n",
      "Epoch 64/64\n",
      "1198/1198 [==============================] - 0s 349us/step - loss: 0.1239 - acc: 0.9566\n",
      "299/299 [==============================] - 1s 3ms/step\n",
      "Epoch 1/64\n",
      "1198/1198 [==============================] - 2s 2ms/step - loss: 0.5801 - acc: 0.8539\n",
      "Epoch 2/64\n",
      "1198/1198 [==============================] - 0s 322us/step - loss: 0.3837 - acc: 0.8932\n",
      "Epoch 3/64\n",
      "1198/1198 [==============================] - 0s 341us/step - loss: 0.2835 - acc: 0.8973\n",
      "Epoch 4/64\n",
      "1198/1198 [==============================] - 0s 328us/step - loss: 0.2501 - acc: 0.9040\n",
      "Epoch 5/64\n",
      "1198/1198 [==============================] - 0s 330us/step - loss: 0.2362 - acc: 0.9057\n",
      "Epoch 6/64\n",
      "1198/1198 [==============================] - 0s 342us/step - loss: 0.2256 - acc: 0.9107\n",
      "Epoch 7/64\n",
      "1198/1198 [==============================] - 0s 321us/step - loss: 0.2190 - acc: 0.9174\n",
      "Epoch 8/64\n",
      "1198/1198 [==============================] - 0s 327us/step - loss: 0.2143 - acc: 0.9174\n",
      "Epoch 9/64\n",
      "1198/1198 [==============================] - 0s 332us/step - loss: 0.2101 - acc: 0.9165\n",
      "Epoch 10/64\n",
      "1198/1198 [==============================] - 0s 347us/step - loss: 0.2050 - acc: 0.9232\n",
      "Epoch 11/64\n",
      "1198/1198 [==============================] - 0s 327us/step - loss: 0.2043 - acc: 0.9174\n",
      "Epoch 12/64\n",
      "1198/1198 [==============================] - 0s 341us/step - loss: 0.2008 - acc: 0.9232\n",
      "Epoch 13/64\n",
      "1198/1198 [==============================] - 0s 330us/step - loss: 0.1972 - acc: 0.9232\n",
      "Epoch 14/64\n",
      "1198/1198 [==============================] - 0s 342us/step - loss: 0.1953 - acc: 0.9274\n",
      "Epoch 15/64\n",
      "1198/1198 [==============================] - 0s 335us/step - loss: 0.1940 - acc: 0.9249\n",
      "Epoch 16/64\n",
      "1198/1198 [==============================] - 0s 328us/step - loss: 0.1904 - acc: 0.9265\n",
      "Epoch 17/64\n",
      "1198/1198 [==============================] - 0s 335us/step - loss: 0.1880 - acc: 0.9290\n",
      "Epoch 18/64\n",
      "1198/1198 [==============================] - 0s 322us/step - loss: 0.1860 - acc: 0.9290\n",
      "Epoch 19/64\n",
      "1198/1198 [==============================] - 0s 323us/step - loss: 0.1848 - acc: 0.9282\n",
      "Epoch 20/64\n",
      "1198/1198 [==============================] - 0s 329us/step - loss: 0.1817 - acc: 0.9299\n",
      "Epoch 21/64\n",
      "1198/1198 [==============================] - 0s 344us/step - loss: 0.1800 - acc: 0.9324\n",
      "Epoch 22/64\n",
      "1198/1198 [==============================] - 0s 336us/step - loss: 0.1786 - acc: 0.9316\n",
      "Epoch 23/64\n",
      "1198/1198 [==============================] - 0s 336us/step - loss: 0.1760 - acc: 0.9349\n",
      "Epoch 24/64\n",
      "1198/1198 [==============================] - 0s 328us/step - loss: 0.1750 - acc: 0.9366\n",
      "Epoch 25/64\n",
      "1198/1198 [==============================] - 0s 341us/step - loss: 0.1736 - acc: 0.9349\n",
      "Epoch 26/64\n",
      "1198/1198 [==============================] - 0s 330us/step - loss: 0.1713 - acc: 0.9341\n",
      "Epoch 27/64\n",
      "1198/1198 [==============================] - 0s 337us/step - loss: 0.1717 - acc: 0.9366\n",
      "Epoch 28/64\n",
      "1198/1198 [==============================] - 0s 340us/step - loss: 0.1699 - acc: 0.9391\n",
      "Epoch 29/64\n",
      "1198/1198 [==============================] - 0s 328us/step - loss: 0.1692 - acc: 0.9382\n",
      "Epoch 30/64\n",
      "1198/1198 [==============================] - 0s 344us/step - loss: 0.1666 - acc: 0.9391\n",
      "Epoch 31/64\n",
      "1198/1198 [==============================] - 0s 345us/step - loss: 0.1661 - acc: 0.9407\n",
      "Epoch 32/64\n",
      "1198/1198 [==============================] - 0s 330us/step - loss: 0.1653 - acc: 0.9441\n",
      "Epoch 33/64\n",
      "1198/1198 [==============================] - 0s 340us/step - loss: 0.1632 - acc: 0.9432\n",
      "Epoch 34/64\n",
      "1198/1198 [==============================] - 0s 331us/step - loss: 0.1625 - acc: 0.9407\n",
      "Epoch 35/64\n",
      "1198/1198 [==============================] - 0s 341us/step - loss: 0.1610 - acc: 0.9407\n",
      "Epoch 36/64\n",
      "1198/1198 [==============================] - 0s 393us/step - loss: 0.1598 - acc: 0.9391\n",
      "Epoch 37/64\n",
      "1198/1198 [==============================] - 0s 335us/step - loss: 0.1593 - acc: 0.9441\n",
      "Epoch 38/64\n",
      "1198/1198 [==============================] - 0s 354us/step - loss: 0.1575 - acc: 0.9424\n",
      "Epoch 39/64\n",
      "1198/1198 [==============================] - 0s 330us/step - loss: 0.1564 - acc: 0.9432\n",
      "Epoch 40/64\n",
      "1198/1198 [==============================] - 1s 434us/step - loss: 0.1539 - acc: 0.9424\n",
      "Epoch 41/64\n",
      "1198/1198 [==============================] - 0s 347us/step - loss: 0.1527 - acc: 0.9441\n",
      "Epoch 42/64\n",
      "1198/1198 [==============================] - 0s 327us/step - loss: 0.1516 - acc: 0.9449\n",
      "Epoch 43/64\n",
      "1198/1198 [==============================] - 0s 342us/step - loss: 0.1504 - acc: 0.9441\n",
      "Epoch 44/64\n",
      "1198/1198 [==============================] - 0s 317us/step - loss: 0.1489 - acc: 0.9491\n",
      "Epoch 45/64\n",
      "1198/1198 [==============================] - 0s 354us/step - loss: 0.1481 - acc: 0.9441\n",
      "Epoch 46/64\n",
      "1198/1198 [==============================] - 0s 323us/step - loss: 0.1467 - acc: 0.9449\n",
      "Epoch 47/64\n",
      "1198/1198 [==============================] - 0s 340us/step - loss: 0.1449 - acc: 0.9441\n",
      "Epoch 48/64\n",
      "1198/1198 [==============================] - 0s 341us/step - loss: 0.1448 - acc: 0.9474\n",
      "Epoch 49/64\n",
      "1198/1198 [==============================] - 0s 331us/step - loss: 0.1428 - acc: 0.9491\n",
      "Epoch 50/64\n",
      "1198/1198 [==============================] - 0s 349us/step - loss: 0.1440 - acc: 0.9466\n",
      "Epoch 51/64\n",
      "1198/1198 [==============================] - 0s 328us/step - loss: 0.1410 - acc: 0.9457\n",
      "Epoch 52/64\n",
      "1198/1198 [==============================] - 0s 353us/step - loss: 0.1412 - acc: 0.9449\n",
      "Epoch 53/64\n",
      "1198/1198 [==============================] - 0s 370us/step - loss: 0.1394 - acc: 0.9441\n",
      "Epoch 54/64\n",
      "1198/1198 [==============================] - 0s 380us/step - loss: 0.1381 - acc: 0.9508\n",
      "Epoch 55/64\n",
      "1198/1198 [==============================] - 0s 349us/step - loss: 0.1376 - acc: 0.9491\n",
      "Epoch 56/64\n",
      "1198/1198 [==============================] - 0s 379us/step - loss: 0.1364 - acc: 0.9508\n",
      "Epoch 57/64\n",
      "1198/1198 [==============================] - 1s 433us/step - loss: 0.1369 - acc: 0.9491\n",
      "Epoch 58/64\n",
      "1198/1198 [==============================] - 0s 392us/step - loss: 0.1341 - acc: 0.9491\n",
      "Epoch 59/64\n",
      "1198/1198 [==============================] - 0s 367us/step - loss: 0.1360 - acc: 0.9457\n",
      "Epoch 60/64\n",
      "1198/1198 [==============================] - 0s 393us/step - loss: 0.1325 - acc: 0.9491\n",
      "Epoch 61/64\n",
      "1198/1198 [==============================] - 0s 413us/step - loss: 0.1330 - acc: 0.9474\n",
      "Epoch 62/64\n",
      "1198/1198 [==============================] - 0s 362us/step - loss: 0.1330 - acc: 0.9491\n",
      "Epoch 63/64\n",
      "1198/1198 [==============================] - 0s 350us/step - loss: 0.1298 - acc: 0.9508\n",
      "Epoch 64/64\n",
      "1198/1198 [==============================] - 0s 341us/step - loss: 0.1304 - acc: 0.9482\n",
      "299/299 [==============================] - 1s 3ms/step\n",
      "Epoch 1/64\n",
      "1198/1198 [==============================] - 2s 2ms/step - loss: 0.5818 - acc: 0.8748\n",
      "Epoch 2/64\n",
      "1198/1198 [==============================] - 0s 336us/step - loss: 0.3810 - acc: 0.8940\n",
      "Epoch 3/64\n",
      "1198/1198 [==============================] - 0s 328us/step - loss: 0.2784 - acc: 0.9040\n",
      "Epoch 4/64\n",
      "1198/1198 [==============================] - 0s 355us/step - loss: 0.2416 - acc: 0.9090\n",
      "Epoch 5/64\n",
      "1198/1198 [==============================] - 0s 369us/step - loss: 0.2296 - acc: 0.9132\n",
      "Epoch 6/64\n",
      "1198/1198 [==============================] - 0s 333us/step - loss: 0.2235 - acc: 0.9140\n",
      "Epoch 7/64\n",
      "1198/1198 [==============================] - 0s 343us/step - loss: 0.2192 - acc: 0.9165\n",
      "Epoch 8/64\n",
      "1198/1198 [==============================] - 0s 328us/step - loss: 0.2154 - acc: 0.9157\n",
      "Epoch 9/64\n",
      "1198/1198 [==============================] - 0s 330us/step - loss: 0.2138 - acc: 0.9199\n",
      "Epoch 10/64\n",
      "1198/1198 [==============================] - 0s 328us/step - loss: 0.2101 - acc: 0.9224\n",
      "Epoch 11/64\n",
      "1198/1198 [==============================] - 0s 350us/step - loss: 0.2087 - acc: 0.9224\n",
      "Epoch 12/64\n",
      "1198/1198 [==============================] - 0s 341us/step - loss: 0.2069 - acc: 0.9182 0s - loss: 0.1934 - acc: \n",
      "Epoch 13/64\n",
      "1198/1198 [==============================] - 0s 340us/step - loss: 0.2041 - acc: 0.9215\n",
      "Epoch 14/64\n",
      "1198/1198 [==============================] - 0s 332us/step - loss: 0.2030 - acc: 0.9215\n",
      "Epoch 15/64\n",
      "1198/1198 [==============================] - 0s 348us/step - loss: 0.2022 - acc: 0.9257\n",
      "Epoch 16/64\n",
      "1198/1198 [==============================] - 0s 341us/step - loss: 0.2005 - acc: 0.9207\n",
      "Epoch 17/64\n",
      "1198/1198 [==============================] - 0s 328us/step - loss: 0.1991 - acc: 0.9240\n",
      "Epoch 18/64\n",
      "1198/1198 [==============================] - 0s 330us/step - loss: 0.1978 - acc: 0.9257\n",
      "Epoch 19/64\n",
      "1198/1198 [==============================] - 0s 324us/step - loss: 0.1968 - acc: 0.9290\n",
      "Epoch 20/64\n",
      "1198/1198 [==============================] - 0s 327us/step - loss: 0.1958 - acc: 0.9265\n",
      "Epoch 21/64\n",
      "1198/1198 [==============================] - 0s 341us/step - loss: 0.1941 - acc: 0.9274\n",
      "Epoch 22/64\n",
      "1198/1198 [==============================] - 0s 318us/step - loss: 0.1929 - acc: 0.9316\n",
      "Epoch 23/64\n",
      "1198/1198 [==============================] - 0s 342us/step - loss: 0.1914 - acc: 0.9290\n",
      "Epoch 24/64\n",
      "1198/1198 [==============================] - 0s 319us/step - loss: 0.1906 - acc: 0.9316\n",
      "Epoch 25/64\n",
      "1198/1198 [==============================] - 0s 328us/step - loss: 0.1881 - acc: 0.9316\n",
      "Epoch 26/64\n",
      "1198/1198 [==============================] - 0s 345us/step - loss: 0.1878 - acc: 0.9349\n",
      "Epoch 27/64\n",
      "1198/1198 [==============================] - 0s 321us/step - loss: 0.1873 - acc: 0.9357\n",
      "Epoch 28/64\n",
      "1198/1198 [==============================] - 0s 341us/step - loss: 0.1853 - acc: 0.9324\n",
      "Epoch 29/64\n",
      "1198/1198 [==============================] - 0s 341us/step - loss: 0.1844 - acc: 0.9349\n",
      "Epoch 30/64\n",
      "1198/1198 [==============================] - 0s 331us/step - loss: 0.1842 - acc: 0.9341\n",
      "Epoch 31/64\n",
      "1198/1198 [==============================] - 0s 354us/step - loss: 0.1829 - acc: 0.9332\n",
      "Epoch 32/64\n",
      "1198/1198 [==============================] - 0s 323us/step - loss: 0.1812 - acc: 0.9357\n",
      "Epoch 33/64\n",
      "1198/1198 [==============================] - 0s 344us/step - loss: 0.1811 - acc: 0.9324\n",
      "Epoch 34/64\n",
      "1198/1198 [==============================] - 0s 350us/step - loss: 0.1802 - acc: 0.9349\n",
      "Epoch 35/64\n",
      "1198/1198 [==============================] - 0s 330us/step - loss: 0.1781 - acc: 0.9349\n",
      "Epoch 36/64\n",
      "1198/1198 [==============================] - 0s 350us/step - loss: 0.1788 - acc: 0.9316\n",
      "Epoch 37/64\n",
      "1198/1198 [==============================] - 0s 367us/step - loss: 0.1774 - acc: 0.9357\n",
      "Epoch 38/64\n",
      "1198/1198 [==============================] - 0s 341us/step - loss: 0.1758 - acc: 0.9324\n",
      "Epoch 39/64\n",
      "1198/1198 [==============================] - 0s 331us/step - loss: 0.1752 - acc: 0.9357\n",
      "Epoch 40/64\n",
      "1198/1198 [==============================] - 0s 340us/step - loss: 0.1740 - acc: 0.9357\n",
      "Epoch 41/64\n",
      "1198/1198 [==============================] - 0s 362us/step - loss: 0.1728 - acc: 0.9366\n",
      "Epoch 42/64\n",
      "1198/1198 [==============================] - 0s 341us/step - loss: 0.1715 - acc: 0.9432\n",
      "Epoch 43/64\n",
      "1198/1198 [==============================] - 0s 341us/step - loss: 0.1717 - acc: 0.9382\n",
      "Epoch 44/64\n",
      "1198/1198 [==============================] - 0s 343us/step - loss: 0.1704 - acc: 0.9407\n",
      "Epoch 45/64\n",
      "1198/1198 [==============================] - 0s 337us/step - loss: 0.1686 - acc: 0.9357\n",
      "Epoch 46/64\n",
      "1198/1198 [==============================] - 0s 351us/step - loss: 0.1694 - acc: 0.9382\n",
      "Epoch 47/64\n",
      "1198/1198 [==============================] - 0s 341us/step - loss: 0.1672 - acc: 0.9399\n",
      "Epoch 48/64\n",
      "1198/1198 [==============================] - 0s 368us/step - loss: 0.1667 - acc: 0.9424\n",
      "Epoch 49/64\n",
      "1198/1198 [==============================] - 0s 343us/step - loss: 0.1648 - acc: 0.9432\n",
      "Epoch 50/64\n",
      "1198/1198 [==============================] - 0s 336us/step - loss: 0.1655 - acc: 0.9416\n",
      "Epoch 51/64\n",
      "1198/1198 [==============================] - 0s 341us/step - loss: 0.1652 - acc: 0.9432\n",
      "Epoch 52/64\n",
      "1198/1198 [==============================] - 0s 340us/step - loss: 0.1629 - acc: 0.9416\n",
      "Epoch 53/64\n",
      "1198/1198 [==============================] - 0s 332us/step - loss: 0.1632 - acc: 0.9416\n",
      "Epoch 54/64\n",
      "1198/1198 [==============================] - 0s 354us/step - loss: 0.1619 - acc: 0.9441\n",
      "Epoch 55/64\n",
      "1198/1198 [==============================] - 0s 336us/step - loss: 0.1606 - acc: 0.9441\n",
      "Epoch 56/64\n",
      "1198/1198 [==============================] - 0s 341us/step - loss: 0.1601 - acc: 0.9457\n",
      "Epoch 57/64\n",
      "1198/1198 [==============================] - 0s 349us/step - loss: 0.1588 - acc: 0.9432\n",
      "Epoch 58/64\n",
      "1198/1198 [==============================] - 0s 346us/step - loss: 0.1581 - acc: 0.9441\n",
      "Epoch 59/64\n",
      "1198/1198 [==============================] - 0s 336us/step - loss: 0.1577 - acc: 0.9449\n",
      "Epoch 60/64\n",
      "1198/1198 [==============================] - 0s 380us/step - loss: 0.1573 - acc: 0.9466\n",
      "Epoch 61/64\n",
      "1198/1198 [==============================] - 0s 406us/step - loss: 0.1548 - acc: 0.9466\n",
      "Epoch 62/64\n",
      "1198/1198 [==============================] - 0s 341us/step - loss: 0.1555 - acc: 0.9474\n",
      "Epoch 63/64\n",
      "1198/1198 [==============================] - 0s 406us/step - loss: 0.1533 - acc: 0.9407\n",
      "Epoch 64/64\n",
      "1198/1198 [==============================] - 0s 357us/step - loss: 0.1543 - acc: 0.9474\n",
      "299/299 [==============================] - 1s 3ms/step\n",
      "Epoch 1/32\n",
      "1497/1497 [==============================] - 3s 2ms/step - loss: 0.5512 - acc: 0.8464A: 0s - loss: 0.5796 - acc: 0.83\n",
      "Epoch 2/32\n",
      "1497/1497 [==============================] - 1s 367us/step - loss: 0.3047 - acc: 0.9031\n",
      "Epoch 3/32\n",
      "1497/1497 [==============================] - 1s 356us/step - loss: 0.2383 - acc: 0.9125\n",
      "Epoch 4/32\n",
      "1497/1497 [==============================] - 1s 377us/step - loss: 0.2220 - acc: 0.9125\n",
      "Epoch 5/32\n",
      "1497/1497 [==============================] - 1s 377us/step - loss: 0.2118 - acc: 0.9172\n",
      "Epoch 6/32\n",
      "1497/1497 [==============================] - 1s 367us/step - loss: 0.2072 - acc: 0.9198\n",
      "Epoch 7/32\n",
      "1497/1497 [==============================] - 1s 366us/step - loss: 0.2026 - acc: 0.9178\n",
      "Epoch 8/32\n",
      "1497/1497 [==============================] - 1s 346us/step - loss: 0.1998 - acc: 0.9238\n",
      "Epoch 9/32\n",
      "1497/1497 [==============================] - 1s 356us/step - loss: 0.1951 - acc: 0.9265\n",
      "Epoch 10/32\n",
      "1497/1497 [==============================] - 1s 346us/step - loss: 0.1919 - acc: 0.9205\n",
      "Epoch 11/32\n",
      "1497/1497 [==============================] - 1s 367us/step - loss: 0.1890 - acc: 0.9238\n",
      "Epoch 12/32\n",
      "1497/1497 [==============================] - 1s 387us/step - loss: 0.1878 - acc: 0.9265\n",
      "Epoch 13/32\n",
      "1497/1497 [==============================] - 1s 367us/step - loss: 0.1844 - acc: 0.9292\n",
      "Epoch 14/32\n",
      "1497/1497 [==============================] - 1s 356us/step - loss: 0.1804 - acc: 0.9312\n",
      "Epoch 15/32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1497/1497 [==============================] - 1s 356us/step - loss: 0.1792 - acc: 0.9319\n",
      "Epoch 16/32\n",
      "1497/1497 [==============================] - 1s 356us/step - loss: 0.1787 - acc: 0.9305\n",
      "Epoch 17/32\n",
      "1497/1497 [==============================] - ETA: 0s - loss: 0.1729 - acc: 0.939 - 1s 356us/step - loss: 0.1746 - acc: 0.9379\n",
      "Epoch 18/32\n",
      "1497/1497 [==============================] - 1s 346us/step - loss: 0.1726 - acc: 0.9345\n",
      "Epoch 19/32\n",
      "1497/1497 [==============================] - 1s 356us/step - loss: 0.1704 - acc: 0.9372\n",
      "Epoch 20/32\n",
      "1497/1497 [==============================] - 1s 356us/step - loss: 0.1684 - acc: 0.9365\n",
      "Epoch 21/32\n",
      "1497/1497 [==============================] - 1s 346us/step - loss: 0.1657 - acc: 0.9372\n",
      "Epoch 22/32\n",
      "1497/1497 [==============================] - 1s 386us/step - loss: 0.1660 - acc: 0.9405\n",
      "Epoch 23/32\n",
      "1497/1497 [==============================] - 1s 336us/step - loss: 0.1625 - acc: 0.9405\n",
      "Epoch 24/32\n",
      "1497/1497 [==============================] - 1s 356us/step - loss: 0.1615 - acc: 0.9365\n",
      "Epoch 25/32\n",
      "1497/1497 [==============================] - 1s 356us/step - loss: 0.1596 - acc: 0.9446\n",
      "Epoch 26/32\n",
      "1497/1497 [==============================] - 1s 368us/step - loss: 0.1561 - acc: 0.9439\n",
      "Epoch 27/32\n",
      "1497/1497 [==============================] - 1s 345us/step - loss: 0.1546 - acc: 0.9432\n",
      "Epoch 28/32\n",
      "1497/1497 [==============================] - 1s 361us/step - loss: 0.1538 - acc: 0.9439\n",
      "Epoch 29/32\n",
      "1497/1497 [==============================] - 1s 383us/step - loss: 0.1525 - acc: 0.9412\n",
      "Epoch 30/32\n",
      "1497/1497 [==============================] - 1s 356us/step - loss: 0.1496 - acc: 0.9432\n",
      "Epoch 31/32\n",
      "1497/1497 [==============================] - 1s 376us/step - loss: 0.1488 - acc: 0.9466\n",
      "Epoch 32/32\n",
      "1497/1497 [==============================] - 1s 367us/step - loss: 0.1467 - acc: 0.9459\n"
     ]
    }
   ],
   "source": [
    "# Importing the Keras libraries and packages\n",
    "import numpy as np\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Create function returning a compiled network\n",
    "def create_network( optimizer):\n",
    "    \n",
    "    # Start neural network\n",
    "    network = models.Sequential()\n",
    "\n",
    "    # Add fully connected layer with a ReLU activation function\n",
    "    network.add(layers.Dense(units=16,kernel_initializer=\"uniform\", activation='relu', input_dim = 17))\n",
    "\n",
    "    # Add fully connected layer with a ReLU activation function\n",
    "    network.add(layers.Dense(units=16, activation='relu'))\n",
    "\n",
    "    # Add fully connected layer with a sigmoid activation function\n",
    "    network.add(layers.Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "    # Compile neural network\n",
    "    network.compile(loss='binary_crossentropy', # Cross-entropy\n",
    "                    optimizer=optimizer, # Root Mean Square Propagation\n",
    "                    metrics=['accuracy']) # Accuracy performance metric\n",
    "    \n",
    "    # Return compiled network\n",
    "    return network\n",
    "\n",
    "# Wrap Keras model so it can be used by scikit-learn\n",
    "neural_network = KerasClassifier(build_fn=create_network)\n",
    "\n",
    "\n",
    "# grid search epochs, batch size and optimizer\n",
    "optimizers = ['adam', 'rmsprop']\n",
    "epochs = [32,64]\n",
    "batches = [8, 16]\n",
    "param_grid = dict(optimizer=optimizers, epochs=epochs, batch_size=batches)\n",
    "grid = GridSearchCV(estimator=neural_network, param_grid=param_grid, cv=5)\n",
    "grid_result = grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.912492 using {'batch_size': 16, 'epochs': 32, 'optimizer': 'adam'}\n",
      "0.909820 (0.011015) with: {'batch_size': 8, 'epochs': 32, 'optimizer': 'adam'}\n",
      "0.912492 (0.017348) with: {'batch_size': 8, 'epochs': 32, 'optimizer': 'rmsprop'}\n",
      "0.907148 (0.015282) with: {'batch_size': 8, 'epochs': 64, 'optimizer': 'adam'}\n",
      "0.903808 (0.006530) with: {'batch_size': 8, 'epochs': 64, 'optimizer': 'rmsprop'}\n",
      "0.912492 (0.019880) with: {'batch_size': 16, 'epochs': 32, 'optimizer': 'adam'}\n",
      "0.911824 (0.017146) with: {'batch_size': 16, 'epochs': 32, 'optimizer': 'rmsprop'}\n",
      "0.907816 (0.006850) with: {'batch_size': 16, 'epochs': 64, 'optimizer': 'adam'}\n",
      "0.906480 (0.008962) with: {'batch_size': 16, 'epochs': 64, 'optimizer': 'rmsprop'}\n"
     ]
    }
   ],
   "source": [
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "\tprint(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the Keras libraries and packages\n",
    "import numpy as np\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "# Create function returning a compiled network\n",
    "def create_network():\n",
    "    \n",
    "    # Start neural network\n",
    "    network = models.Sequential()\n",
    "\n",
    "    # Add fully connected layer with a ReLU activation function\n",
    "    network.add(layers.Dense(units=16, activation='relu', input_dim = 17))\n",
    "\n",
    "    # Add fully connected layer with a ReLU activation function\n",
    "    network.add(layers.Dense(units=16, activation='relu'))\n",
    "\n",
    "    # Add fully connected layer with a sigmoid activation function\n",
    "    network.add(layers.Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "    # Compile neural network\n",
    "    network.compile(loss='binary_crossentropy', # Cross-entropy\n",
    "                    optimizer='adam', # Root Mean Square Propagation\n",
    "                    metrics=['accuracy']) # Accuracy performance metric\n",
    "    \n",
    "    # Return compiled network\n",
    "    return network\n",
    "\n",
    "# Wrap Keras model so it can be used by scikit-learn\n",
    "neural_network = KerasClassifier(build_fn=create_network, \n",
    "                                 epochs=32, \n",
    "                                 batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/32\n",
      "1497/1497 [==============================] - 3s 2ms/step - loss: 0.5628 - acc: 0.7629\n",
      "Epoch 2/32\n",
      "1497/1497 [==============================] - 0s 289us/step - loss: 0.3829 - acc: 0.8490\n",
      "Epoch 3/32\n",
      "1497/1497 [==============================] - 0s 305us/step - loss: 0.2962 - acc: 0.8824\n",
      "Epoch 4/32\n",
      "1497/1497 [==============================] - 0s 304us/step - loss: 0.2605 - acc: 0.8931\n",
      "Epoch 5/32\n",
      "1497/1497 [==============================] - 0s 304us/step - loss: 0.2413 - acc: 0.9071\n",
      "Epoch 6/32\n",
      "1497/1497 [==============================] - 0s 309us/step - loss: 0.2288 - acc: 0.9092\n",
      "Epoch 7/32\n",
      "1497/1497 [==============================] - 0s 299us/step - loss: 0.2204 - acc: 0.9092\n",
      "Epoch 8/32\n",
      "1497/1497 [==============================] - 0s 315us/step - loss: 0.2145 - acc: 0.9125\n",
      "Epoch 9/32\n",
      "1497/1497 [==============================] - 0s 300us/step - loss: 0.2086 - acc: 0.9132\n",
      "Epoch 10/32\n",
      "1497/1497 [==============================] - 0s 305us/step - loss: 0.2049 - acc: 0.9125\n",
      "Epoch 11/32\n",
      "1497/1497 [==============================] - 0s 304us/step - loss: 0.2004 - acc: 0.9165\n",
      "Epoch 12/32\n",
      "1497/1497 [==============================] - 0s 303us/step - loss: 0.1974 - acc: 0.9158\n",
      "Epoch 13/32\n",
      "1497/1497 [==============================] - 0s 304us/step - loss: 0.1936 - acc: 0.9165\n",
      "Epoch 14/32\n",
      "1497/1497 [==============================] - 0s 307us/step - loss: 0.1908 - acc: 0.9212\n",
      "Epoch 15/32\n",
      "1497/1497 [==============================] - 0s 293us/step - loss: 0.1899 - acc: 0.9212\n",
      "Epoch 16/32\n",
      "1497/1497 [==============================] - 0s 301us/step - loss: 0.1860 - acc: 0.9225\n",
      "Epoch 17/32\n",
      "1497/1497 [==============================] - 0s 293us/step - loss: 0.1844 - acc: 0.9265\n",
      "Epoch 18/32\n",
      "1497/1497 [==============================] - 0s 304us/step - loss: 0.1833 - acc: 0.9205\n",
      "Epoch 19/32\n",
      "1497/1497 [==============================] - 0s 304us/step - loss: 0.1816 - acc: 0.9259\n",
      "Epoch 20/32\n",
      "1497/1497 [==============================] - 0s 296us/step - loss: 0.1795 - acc: 0.9285\n",
      "Epoch 21/32\n",
      "1497/1497 [==============================] - 0s 303us/step - loss: 0.1786 - acc: 0.9238\n",
      "Epoch 22/32\n",
      "1497/1497 [==============================] - 0s 290us/step - loss: 0.1775 - acc: 0.9285\n",
      "Epoch 23/32\n",
      "1497/1497 [==============================] - 0s 304us/step - loss: 0.1753 - acc: 0.9252\n",
      "Epoch 24/32\n",
      "1497/1497 [==============================] - 0s 293us/step - loss: 0.1735 - acc: 0.9265\n",
      "Epoch 25/32\n",
      "1497/1497 [==============================] - 0s 314us/step - loss: 0.1723 - acc: 0.9319\n",
      "Epoch 26/32\n",
      "1497/1497 [==============================] - 0s 301us/step - loss: 0.1711 - acc: 0.9279\n",
      "Epoch 27/32\n",
      "1497/1497 [==============================] - 0s 287us/step - loss: 0.1694 - acc: 0.9312\n",
      "Epoch 28/32\n",
      "1497/1497 [==============================] - 0s 314us/step - loss: 0.1679 - acc: 0.9299\n",
      "Epoch 29/32\n",
      "1497/1497 [==============================] - 0s 290us/step - loss: 0.1666 - acc: 0.9305\n",
      "Epoch 30/32\n",
      "1497/1497 [==============================] - 0s 314us/step - loss: 0.1654 - acc: 0.9279\n",
      "Epoch 31/32\n",
      "1497/1497 [==============================] - 0s 283us/step - loss: 0.1640 - acc: 0.9339\n",
      "Epoch 32/32\n",
      "1497/1497 [==============================] - 0s 304us/step - loss: 0.1637 - acc: 0.9305\n",
      "Model: \"sequential_48\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_142 (Dense)            (None, 16)                288       \n",
      "_________________________________________________________________\n",
      "dense_143 (Dense)            (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_144 (Dense)            (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 577\n",
      "Trainable params: 577\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Evaluate neural network\n",
    "neural_network.fit(X_train, y_train)\n",
    "neural_network.model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/32\n",
      "1197/1197 [==============================] - 2s 2ms/step - loss: 0.5824 - acc: 0.8028\n",
      "Epoch 2/32\n",
      "1197/1197 [==============================] - 0s 311us/step - loss: 0.4531 - acc: 0.8730\n",
      "Epoch 3/32\n",
      "1197/1197 [==============================] - 0s 353us/step - loss: 0.3513 - acc: 0.8855\n",
      "Epoch 4/32\n",
      "1197/1197 [==============================] - 0s 329us/step - loss: 0.2866 - acc: 0.8906\n",
      "Epoch 5/32\n",
      "1197/1197 [==============================] - 0s 330us/step - loss: 0.2581 - acc: 0.8956\n",
      "Epoch 6/32\n",
      "1197/1197 [==============================] - 0s 323us/step - loss: 0.2420 - acc: 0.8997\n",
      "Epoch 7/32\n",
      "1197/1197 [==============================] - 0s 302us/step - loss: 0.2324 - acc: 0.8997\n",
      "Epoch 8/32\n",
      "1197/1197 [==============================] - 0s 305us/step - loss: 0.2250 - acc: 0.9031\n",
      "Epoch 9/32\n",
      "1197/1197 [==============================] - 0s 311us/step - loss: 0.2184 - acc: 0.9056\n",
      "Epoch 10/32\n",
      "1197/1197 [==============================] - 0s 301us/step - loss: 0.2132 - acc: 0.9089\n",
      "Epoch 11/32\n",
      "1197/1197 [==============================] - 0s 314us/step - loss: 0.2089 - acc: 0.9089\n",
      "Epoch 12/32\n",
      "1197/1197 [==============================] - 0s 304us/step - loss: 0.2039 - acc: 0.9123\n",
      "Epoch 13/32\n",
      "1197/1197 [==============================] - 0s 298us/step - loss: 0.1995 - acc: 0.9140\n",
      "Epoch 14/32\n",
      "1197/1197 [==============================] - 0s 315us/step - loss: 0.1964 - acc: 0.9140\n",
      "Epoch 15/32\n",
      "1197/1197 [==============================] - 0s 293us/step - loss: 0.1927 - acc: 0.9173\n",
      "Epoch 16/32\n",
      "1197/1197 [==============================] - 0s 308us/step - loss: 0.1894 - acc: 0.9198\n",
      "Epoch 17/32\n",
      "1197/1197 [==============================] - 0s 315us/step - loss: 0.1870 - acc: 0.9198\n",
      "Epoch 18/32\n",
      "1197/1197 [==============================] - 0s 306us/step - loss: 0.1851 - acc: 0.9231\n",
      "Epoch 19/32\n",
      "1197/1197 [==============================] - 0s 309us/step - loss: 0.1828 - acc: 0.9215\n",
      "Epoch 20/32\n",
      "1197/1197 [==============================] - 0s 315us/step - loss: 0.1797 - acc: 0.9248\n",
      "Epoch 21/32\n",
      "1197/1197 [==============================] - 0s 315us/step - loss: 0.1776 - acc: 0.9248\n",
      "Epoch 22/32\n",
      "1197/1197 [==============================] - 0s 305us/step - loss: 0.1758 - acc: 0.9265\n",
      "Epoch 23/32\n",
      "1197/1197 [==============================] - 0s 337us/step - loss: 0.1735 - acc: 0.9273\n",
      "Epoch 24/32\n",
      "1197/1197 [==============================] - 0s 327us/step - loss: 0.1714 - acc: 0.9273\n",
      "Epoch 25/32\n",
      "1197/1197 [==============================] - 0s 318us/step - loss: 0.1701 - acc: 0.9298\n",
      "Epoch 26/32\n",
      "1197/1197 [==============================] - 0s 322us/step - loss: 0.1677 - acc: 0.9323\n",
      "Epoch 27/32\n",
      "1197/1197 [==============================] - 0s 314us/step - loss: 0.1664 - acc: 0.9332\n",
      "Epoch 28/32\n",
      "1197/1197 [==============================] - 0s 328us/step - loss: 0.1647 - acc: 0.9398\n",
      "Epoch 29/32\n",
      "1197/1197 [==============================] - 0s 345us/step - loss: 0.1647 - acc: 0.9357\n",
      "Epoch 30/32\n",
      "1197/1197 [==============================] - 0s 353us/step - loss: 0.1618 - acc: 0.9365\n",
      "Epoch 31/32\n",
      "1197/1197 [==============================] - 0s 336us/step - loss: 0.1604 - acc: 0.9407\n",
      "Epoch 32/32\n",
      "1197/1197 [==============================] - 0s 341us/step - loss: 0.1591 - acc: 0.9424\n",
      "300/300 [==============================] - 1s 3ms/step\n",
      "Epoch 1/32\n",
      "1197/1197 [==============================] - 2s 2ms/step - loss: 0.7622 - acc: 0.5756\n",
      "Epoch 2/32\n",
      "1197/1197 [==============================] - 0s 354us/step - loss: 0.4528 - acc: 0.8379\n",
      "Epoch 3/32\n",
      "1197/1197 [==============================] - 0s 337us/step - loss: 0.3354 - acc: 0.8755\n",
      "Epoch 4/32\n",
      "1197/1197 [==============================] - 0s 353us/step - loss: 0.2862 - acc: 0.8864\n",
      "Epoch 5/32\n",
      "1197/1197 [==============================] - 0s 341us/step - loss: 0.2627 - acc: 0.8964\n",
      "Epoch 6/32\n",
      "1197/1197 [==============================] - 0s 370us/step - loss: 0.2479 - acc: 0.9014 0s - loss: 0.2401 - acc: 0.90\n",
      "Epoch 7/32\n",
      "1197/1197 [==============================] - 0s 354us/step - loss: 0.2360 - acc: 0.9073\n",
      "Epoch 8/32\n",
      "1197/1197 [==============================] - 0s 298us/step - loss: 0.2267 - acc: 0.9106\n",
      "Epoch 9/32\n",
      "1197/1197 [==============================] - 0s 315us/step - loss: 0.2201 - acc: 0.9148\n",
      "Epoch 10/32\n",
      "1197/1197 [==============================] - 0s 304us/step - loss: 0.2124 - acc: 0.9181\n",
      "Epoch 11/32\n",
      "1197/1197 [==============================] - 0s 323us/step - loss: 0.2070 - acc: 0.9206\n",
      "Epoch 12/32\n",
      "1197/1197 [==============================] - 0s 311us/step - loss: 0.2018 - acc: 0.9248\n",
      "Epoch 13/32\n",
      "1197/1197 [==============================] - 0s 296us/step - loss: 0.1985 - acc: 0.9282\n",
      "Epoch 14/32\n",
      "1197/1197 [==============================] - 0s 307us/step - loss: 0.1945 - acc: 0.9290\n",
      "Epoch 15/32\n",
      "1197/1197 [==============================] - 0s 342us/step - loss: 0.1913 - acc: 0.9282\n",
      "Epoch 16/32\n",
      "1197/1197 [==============================] - 0s 302us/step - loss: 0.1887 - acc: 0.9290\n",
      "Epoch 17/32\n",
      "1197/1197 [==============================] - 0s 305us/step - loss: 0.1853 - acc: 0.9298\n",
      "Epoch 18/32\n",
      "1197/1197 [==============================] - 0s 309us/step - loss: 0.1826 - acc: 0.9323\n",
      "Epoch 19/32\n",
      "1197/1197 [==============================] - 0s 303us/step - loss: 0.1801 - acc: 0.9315\n",
      "Epoch 20/32\n",
      "1197/1197 [==============================] - 0s 332us/step - loss: 0.1780 - acc: 0.9315\n",
      "Epoch 21/32\n",
      "1197/1197 [==============================] - 0s 324us/step - loss: 0.1749 - acc: 0.9323\n",
      "Epoch 22/32\n",
      "1197/1197 [==============================] - 0s 312us/step - loss: 0.1729 - acc: 0.9373\n",
      "Epoch 23/32\n",
      "1197/1197 [==============================] - 0s 315us/step - loss: 0.1711 - acc: 0.9373\n",
      "Epoch 24/32\n",
      "1197/1197 [==============================] - ETA: 0s - loss: 0.1739 - acc: 0.936 - 0s 305us/step - loss: 0.1697 - acc: 0.9382\n",
      "Epoch 25/32\n",
      "1197/1197 [==============================] - 0s 309us/step - loss: 0.1676 - acc: 0.9398\n",
      "Epoch 26/32\n",
      "1197/1197 [==============================] - 0s 328us/step - loss: 0.1659 - acc: 0.9398\n",
      "Epoch 27/32\n",
      "1197/1197 [==============================] - 0s 321us/step - loss: 0.1656 - acc: 0.9432\n",
      "Epoch 28/32\n",
      "1197/1197 [==============================] - 0s 311us/step - loss: 0.1628 - acc: 0.9382\n",
      "Epoch 29/32\n",
      "1197/1197 [==============================] - 0s 311us/step - loss: 0.1616 - acc: 0.9424\n",
      "Epoch 30/32\n",
      "1197/1197 [==============================] - 0s 328us/step - loss: 0.1585 - acc: 0.9398\n",
      "Epoch 31/32\n",
      "1197/1197 [==============================] - 0s 377us/step - loss: 0.1588 - acc: 0.9407\n",
      "Epoch 32/32\n",
      "1197/1197 [==============================] - 0s 320us/step - loss: 0.1563 - acc: 0.9432\n",
      "300/300 [==============================] - 1s 3ms/step\n",
      "Epoch 1/32\n",
      "1198/1198 [==============================] - 2s 2ms/step - loss: 0.6837 - acc: 0.5818\n",
      "Epoch 2/32\n",
      "1198/1198 [==============================] - 0s 315us/step - loss: 0.4519 - acc: 0.8698\n",
      "Epoch 3/32\n",
      "1198/1198 [==============================] - 0s 355us/step - loss: 0.3367 - acc: 0.8907\n",
      "Epoch 4/32\n",
      "1198/1198 [==============================] - 0s 314us/step - loss: 0.2802 - acc: 0.9057\n",
      "Epoch 5/32\n",
      "1198/1198 [==============================] - 0s 336us/step - loss: 0.2519 - acc: 0.9073\n",
      "Epoch 6/32\n",
      "1198/1198 [==============================] - 0s 341us/step - loss: 0.2345 - acc: 0.9140\n",
      "Epoch 7/32\n",
      "1198/1198 [==============================] - 0s 328us/step - loss: 0.2233 - acc: 0.9174\n",
      "Epoch 8/32\n",
      "1198/1198 [==============================] - 0s 331us/step - loss: 0.2140 - acc: 0.9190\n",
      "Epoch 9/32\n",
      "1198/1198 [==============================] - 0s 310us/step - loss: 0.2071 - acc: 0.9174\n",
      "Epoch 10/32\n",
      "1198/1198 [==============================] - 0s 341us/step - loss: 0.2022 - acc: 0.9190\n",
      "Epoch 11/32\n",
      "1198/1198 [==============================] - 0s 339us/step - loss: 0.1970 - acc: 0.9249\n",
      "Epoch 12/32\n",
      "1198/1198 [==============================] - 0s 320us/step - loss: 0.1928 - acc: 0.9240\n",
      "Epoch 13/32\n",
      "1198/1198 [==============================] - 0s 335us/step - loss: 0.1896 - acc: 0.9232\n",
      "Epoch 14/32\n",
      "1198/1198 [==============================] - 0s 341us/step - loss: 0.1871 - acc: 0.9240\n",
      "Epoch 15/32\n",
      "1198/1198 [==============================] - 0s 328us/step - loss: 0.1838 - acc: 0.9240\n",
      "Epoch 16/32\n",
      "1198/1198 [==============================] - 0s 330us/step - loss: 0.1820 - acc: 0.9232\n",
      "Epoch 17/32\n",
      "1198/1198 [==============================] - 0s 323us/step - loss: 0.1792 - acc: 0.9257\n",
      "Epoch 18/32\n",
      "1198/1198 [==============================] - 0s 327us/step - loss: 0.1772 - acc: 0.9240\n",
      "Epoch 19/32\n",
      "1198/1198 [==============================] - 0s 354us/step - loss: 0.1749 - acc: 0.9265\n",
      "Epoch 20/32\n",
      "1198/1198 [==============================] - 0s 332us/step - loss: 0.1719 - acc: 0.9274\n",
      "Epoch 21/32\n",
      "1198/1198 [==============================] - 0s 335us/step - loss: 0.1700 - acc: 0.9307\n",
      "Epoch 22/32\n",
      "1198/1198 [==============================] - 0s 327us/step - loss: 0.1681 - acc: 0.9282\n",
      "Epoch 23/32\n",
      "1198/1198 [==============================] - 0s 329us/step - loss: 0.1665 - acc: 0.9307\n",
      "Epoch 24/32\n",
      "1198/1198 [==============================] - 0s 317us/step - loss: 0.1639 - acc: 0.9307\n",
      "Epoch 25/32\n",
      "1198/1198 [==============================] - 0s 310us/step - loss: 0.1624 - acc: 0.9316\n",
      "Epoch 26/32\n",
      "1198/1198 [==============================] - 0s 328us/step - loss: 0.1610 - acc: 0.9349\n",
      "Epoch 27/32\n",
      "1198/1198 [==============================] - 0s 353us/step - loss: 0.1588 - acc: 0.9341\n",
      "Epoch 28/32\n",
      "1198/1198 [==============================] - 0s 318us/step - loss: 0.1570 - acc: 0.9382\n",
      "Epoch 29/32\n",
      "1198/1198 [==============================] - 0s 336us/step - loss: 0.1560 - acc: 0.9357\n",
      "Epoch 30/32\n",
      "1198/1198 [==============================] - 0s 354us/step - loss: 0.1540 - acc: 0.9374\n",
      "Epoch 31/32\n",
      "1198/1198 [==============================] - 0s 379us/step - loss: 0.1530 - acc: 0.9416\n",
      "Epoch 32/32\n",
      "1198/1198 [==============================] - 0s 333us/step - loss: 0.1504 - acc: 0.9407\n",
      "299/299 [==============================] - 1s 3ms/step\n",
      "Epoch 1/32\n",
      "1198/1198 [==============================] - 2s 2ms/step - loss: 0.7456 - acc: 0.4683\n",
      "Epoch 2/32\n",
      "1198/1198 [==============================] - 0s 332us/step - loss: 0.5535 - acc: 0.7997\n",
      "Epoch 3/32\n",
      "1198/1198 [==============================] - 0s 322us/step - loss: 0.4500 - acc: 0.8639\n",
      "Epoch 4/32\n",
      "1198/1198 [==============================] - 0s 353us/step - loss: 0.3590 - acc: 0.8731\n",
      "Epoch 5/32\n",
      "1198/1198 [==============================] - 0s 328us/step - loss: 0.3024 - acc: 0.8840\n",
      "Epoch 6/32\n",
      "1198/1198 [==============================] - 0s 331us/step - loss: 0.2743 - acc: 0.8932\n",
      "Epoch 7/32\n",
      "1198/1198 [==============================] - 0s 344us/step - loss: 0.2592 - acc: 0.8965\n",
      "Epoch 8/32\n",
      "1198/1198 [==============================] - 0s 318us/step - loss: 0.2463 - acc: 0.9023\n",
      "Epoch 9/32\n",
      "1198/1198 [==============================] - 0s 328us/step - loss: 0.2366 - acc: 0.9065\n",
      "Epoch 10/32\n",
      "1198/1198 [==============================] - 0s 344us/step - loss: 0.2283 - acc: 0.9098\n",
      "Epoch 11/32\n",
      "1198/1198 [==============================] - 0s 322us/step - loss: 0.2212 - acc: 0.9107\n",
      "Epoch 12/32\n",
      "1198/1198 [==============================] - 0s 341us/step - loss: 0.2144 - acc: 0.9132\n",
      "Epoch 13/32\n",
      "1198/1198 [==============================] - 0s 327us/step - loss: 0.2080 - acc: 0.9182\n",
      "Epoch 14/32\n",
      "1198/1198 [==============================] - 0s 320us/step - loss: 0.2034 - acc: 0.9174\n",
      "Epoch 15/32\n",
      "1198/1198 [==============================] - 0s 309us/step - loss: 0.1998 - acc: 0.9224\n",
      "Epoch 16/32\n",
      "1198/1198 [==============================] - 0s 302us/step - loss: 0.1955 - acc: 0.9232\n",
      "Epoch 17/32\n",
      "1198/1198 [==============================] - 0s 292us/step - loss: 0.1912 - acc: 0.9265\n",
      "Epoch 18/32\n",
      "1198/1198 [==============================] - 0s 327us/step - loss: 0.1890 - acc: 0.9282\n",
      "Epoch 19/32\n",
      "1198/1198 [==============================] - 0s 296us/step - loss: 0.1860 - acc: 0.9282\n",
      "Epoch 20/32\n",
      "1198/1198 [==============================] - 0s 315us/step - loss: 0.1832 - acc: 0.9290\n",
      "Epoch 21/32\n",
      "1198/1198 [==============================] - 0s 317us/step - loss: 0.1804 - acc: 0.9274\n",
      "Epoch 22/32\n",
      "1198/1198 [==============================] - 0s 297us/step - loss: 0.1784 - acc: 0.9282\n",
      "Epoch 23/32\n",
      "1198/1198 [==============================] - 0s 315us/step - loss: 0.1753 - acc: 0.9290\n",
      "Epoch 24/32\n",
      "1198/1198 [==============================] - 0s 305us/step - loss: 0.1741 - acc: 0.9290\n",
      "Epoch 25/32\n",
      "1198/1198 [==============================] - 0s 309us/step - loss: 0.1715 - acc: 0.9316\n",
      "Epoch 26/32\n",
      "1198/1198 [==============================] - 0s 328us/step - loss: 0.1703 - acc: 0.9332\n",
      "Epoch 27/32\n",
      "1198/1198 [==============================] - 0s 317us/step - loss: 0.1678 - acc: 0.9307\n",
      "Epoch 28/32\n",
      "1198/1198 [==============================] - 0s 316us/step - loss: 0.1660 - acc: 0.9349\n",
      "Epoch 29/32\n",
      "1198/1198 [==============================] - 0s 335us/step - loss: 0.1652 - acc: 0.9357\n",
      "Epoch 30/32\n",
      "1198/1198 [==============================] - 0s 355us/step - loss: 0.1640 - acc: 0.9366\n",
      "Epoch 31/32\n",
      "1198/1198 [==============================] - 0s 339us/step - loss: 0.1610 - acc: 0.9374\n",
      "Epoch 32/32\n",
      "1198/1198 [==============================] - 0s 319us/step - loss: 0.1601 - acc: 0.9399\n",
      "299/299 [==============================] - 1s 3ms/step\n",
      "Epoch 1/32\n",
      "1198/1198 [==============================] - 2s 2ms/step - loss: 0.5525 - acc: 0.8063\n",
      "Epoch 2/32\n",
      "1198/1198 [==============================] - 0s 315us/step - loss: 0.4094 - acc: 0.8681\n",
      "Epoch 3/32\n",
      "1198/1198 [==============================] - 0s 317us/step - loss: 0.3213 - acc: 0.8815\n",
      "Epoch 4/32\n",
      "1198/1198 [==============================] - 0s 328us/step - loss: 0.2774 - acc: 0.8957\n",
      "Epoch 5/32\n",
      "1198/1198 [==============================] - 0s 308us/step - loss: 0.2526 - acc: 0.9007\n",
      "Epoch 6/32\n",
      "1198/1198 [==============================] - 0s 328us/step - loss: 0.2377 - acc: 0.9048\n",
      "Epoch 7/32\n",
      "1198/1198 [==============================] - 0s 319us/step - loss: 0.2291 - acc: 0.9073\n",
      "Epoch 8/32\n",
      "1198/1198 [==============================] - 0s 309us/step - loss: 0.2209 - acc: 0.9107\n",
      "Epoch 9/32\n",
      "1198/1198 [==============================] - 0s 315us/step - loss: 0.2152 - acc: 0.9149\n",
      "Epoch 10/32\n",
      "1198/1198 [==============================] - 0s 323us/step - loss: 0.2094 - acc: 0.9140\n",
      "Epoch 11/32\n",
      "1198/1198 [==============================] - 0s 307us/step - loss: 0.2047 - acc: 0.9157\n",
      "Epoch 12/32\n",
      "1198/1198 [==============================] - 0s 336us/step - loss: 0.2024 - acc: 0.9174\n",
      "Epoch 13/32\n",
      "1198/1198 [==============================] - 0s 314us/step - loss: 0.1981 - acc: 0.9240\n",
      "Epoch 14/32\n",
      "1198/1198 [==============================] - 0s 306us/step - loss: 0.1958 - acc: 0.9240\n",
      "Epoch 15/32\n",
      "1198/1198 [==============================] - 0s 296us/step - loss: 0.1933 - acc: 0.9274\n",
      "Epoch 16/32\n",
      "1198/1198 [==============================] - 0s 315us/step - loss: 0.1903 - acc: 0.9299\n",
      "Epoch 17/32\n",
      "1198/1198 [==============================] - 0s 319us/step - loss: 0.1879 - acc: 0.9282\n",
      "Epoch 18/32\n",
      "1198/1198 [==============================] - 0s 304us/step - loss: 0.1860 - acc: 0.9290\n",
      "Epoch 19/32\n",
      "1198/1198 [==============================] - 0s 303us/step - loss: 0.1831 - acc: 0.9307\n",
      "Epoch 20/32\n",
      "1198/1198 [==============================] - 0s 302us/step - loss: 0.1825 - acc: 0.9316\n",
      "Epoch 21/32\n",
      "1198/1198 [==============================] - 0s 305us/step - loss: 0.1800 - acc: 0.9307\n",
      "Epoch 22/32\n",
      "1198/1198 [==============================] - 0s 297us/step - loss: 0.1787 - acc: 0.9316\n",
      "Epoch 23/32\n",
      "1198/1198 [==============================] - 0s 301us/step - loss: 0.1775 - acc: 0.9299\n",
      "Epoch 24/32\n",
      "1198/1198 [==============================] - 0s 318us/step - loss: 0.1750 - acc: 0.9349\n",
      "Epoch 25/32\n",
      "1198/1198 [==============================] - 0s 310us/step - loss: 0.1733 - acc: 0.9349\n",
      "Epoch 26/32\n",
      "1198/1198 [==============================] - 0s 301us/step - loss: 0.1717 - acc: 0.9324\n",
      "Epoch 27/32\n",
      "1198/1198 [==============================] - 0s 306us/step - loss: 0.1708 - acc: 0.9357\n",
      "Epoch 28/32\n",
      "1198/1198 [==============================] - 0s 295us/step - loss: 0.1689 - acc: 0.9349\n",
      "Epoch 29/32\n",
      "1198/1198 [==============================] - 0s 315us/step - loss: 0.1669 - acc: 0.9349\n",
      "Epoch 30/32\n",
      "1198/1198 [==============================] - 0s 306us/step - loss: 0.1655 - acc: 0.9374\n",
      "Epoch 31/32\n",
      "1198/1198 [==============================] - 0s 340us/step - loss: 0.1629 - acc: 0.9382\n",
      "Epoch 32/32\n",
      "1198/1198 [==============================] - 0s 310us/step - loss: 0.1624 - acc: 0.9357\n",
      "299/299 [==============================] - 1s 3ms/step\n",
      "[0.93       0.89333333 0.89966555 0.909699   0.92307692]\n",
      "0.9111549611809261\n"
     ]
    }
   ],
   "source": [
    "# Evaluate neural network using 5-fold cross-validation after optimization\n",
    "score=cross_val_score(neural_network, X_train, y_train, cv=5)\n",
    "print(score)\n",
    "print(score.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "499/499 [==============================] - 1s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9138276553106213"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Test Accuracy after optimization\n",
    "test_accuracy = neural_network.score(X_test, y_test)\n",
    "test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
